# 2506.18041v1.pdf

arXiv:2506.18041v1  [physics.optics]  22 Jun 2025
Fully analog end-to-end online training with real-time
adaptibility on integrated photonic platform
Zhimu Guo 1*, A. Aadhi 1,3, Adam N. McCaughan 2, Alexander N. Tait 3,
Nathan Youngblood 4, Sonia M. Buckley 2, Bhavin J. Shastri 1,3*
1*Centre for Nanophotonics, Department of Physics, Engineering Physics, and
Astronomy, Queen’s University, Kingston, K7L 3N6, ON, Canada.
2National Institute of Standards and Technology, Boulder, 80305, CO, USA.
3Smith Engineering, Department of Electrical and Computer Engineering, Queen’s
University, Kingston, K7L 3N6, ON, Canada.
4Department of Electrical and Computer Engineering, University of Pittsburgh,
Pittsburgh, 15261, PA, USA.
*Corresponding author(s). E-mail(s): 15zg11@queensu.ca; shastri@ieee.org;
Abstract
Neuromorphic hardware has emerged as a transformative platform for artificial intelligence and
machine learning by offering unprecedented speed and energy efficiency. Particularly, analog neuro-
morphic photonic processors are uniquely positioned to harness the ultrafast bandwidth and inherent
parallelism of light, enabling scalability, on-chip integration and significant improvement in compu-
tational performance. However, major challenges remain unresolved in state-of-the-art architectures,
especially in achieving real-time online training, efficient end-to-end anolog systems, and adaptive
learning for dynamical environmental changes. Here, we demonstrate an on-chip photonic analog
end-to-end adaptive learning system realized on a foundry-manufactured silicon photonic integrated
circuit. Our platform leverages a multiplexed gradient descent (MGD) algorithm to perform in-situ,
on-the-fly training, while maintaining robustness in online tracking and real-time adaptation—a crit-
ical step toward a practical neuromorphic hardware platform. At its core, the processor features
a monolithic integration of a microring resonator weight bank array and on-chip photodetectors,
enabling direct optical measurement of gradient signals. This eliminates the need for high-precision
digital matrix multiplications, significantly reducing computational overhead and latency, an essen-
tial requirement for effective online training. We experimentally demonstrate real-time, end-to-end
analog training for both linear and nonlinear classification tasks at gigabaud (GBaud) rates, achiev-
ing accuracies of over 90% and 80%, respectively. Our analog neuromorphic processor introduces
self-learning capabilities that dynamically adjust training parameters, setting the stage for truly
autonomous neuromorphic architectures capable of efficient, real-time processing in unpredictable
real-world environments. As a result, we showcase adaptive online tracking of dynamically changing
input datasets and achieve over 90% accuracy, alongside robustness to external temperature fluctua-
tions and internal thermal crosstalk—ensuring stable operation under varying environmental changes.
This demonstration marks a significant advancement toward self-adaptive, real-time photonic neu-
romorphic systems, learning bridging the longstanding gap between analog neuromorphic processing
and real-world deployment in next-generation artificial intelligence.
Keywords: Analog Training, Online Tracking, Adaptive Training, In-Situ Training, Online Learning
1 Introduction
The recent surge in artificial intelligence (AI) has triggered a paradigm shifts in computation, driving
rapid advancements across various scientific and technological fields, including protein folding, natu-
ral language processing, computer vision, and autonomous vehicles [1–4]. In particular, a wide range of
neural network (NN) architectures — such as deep neural networks, recurrent neural networks, convolu-
tional neural networks and several others — have been explored, each tailored to specific computational
tasks [5–7]. These architectures primarily rely on numerical computations performed on CPUs and GPUs
to train the networks by estimating gradients. Recently, several neuromorphic hardware architectures
have been developed to compute gradients directly, including variants of backpropagation, online prun-
ing, and other analog-friendly algorithms [8–11]. Among all these techniques, backpropagation remains
the most widely used algorithm in modern machine learning due to its effectiveness in gradient compu-
tation [12]. However, backpropagation requires gradient communication to propagate backward through
the network, layer by layer. Furthermore, it often relies heavily on digital platforms for offline train-
ing. As a result, training neural networks demands large datasets, intensive matrix multiplications, and
gradient computations—leading to high computational costs, bandwidth constraints, and memory bot-
tlenecks [13, 14]. A promising stepping stone towards autonomous training is computer-in-the-loop
1

training, which reduces hardware dependency but incurs significant latency in the training loop [15–18].
However, a fully autonomous online learning system—operating entirely without reliance on an exter-
nal CPU—represents a key future direction for achieving faster, more energy-efficient, high-performance
computing. As a result, various algorithms and architectures have been proposed to accelerate the online
training, including physical hardware-aware training, local learning, continuous learning and equilibrium
propagation [19, 20]. All these approaches demonstrate a transition toward autonomous online learn-
ing, known as in-situ training, which eliminates the need for an external computer [21]. Implementing
in-situ training on physical platforms such as photonics, nanoelectronics, or mechanical systems has the
potential to significantly enhance computational efficiency and widen the range of practical applications
[22, 23]. In this work, we demonstrate in-situ, fully end-to-end analog system with an analog algorithm
that is agnostic to hardware platforms, potentially including photonics, memristors, analog CMOS chips,
and spintronics. Our approach enables neuromorphic hardware systems to be trained as a black box,
moving one step closer to truly autonomous online learning.
In practice, signals natively generated by sensors, spectroscopy, astronomy, high-energy physics, and
medical applications need to be processed directly in the analog domain. Our analog neuromorphic pho-
tonic processors are uniquely positioned to harness the ultrafast bandwidth and energy efficient, enabling
direct processing of analog signals in the optical domain [24–26]. Analog optical computing architectures
eliminate the need for high-precision digital multiplications and offer low latency, inherent parallelism,
and scalability. As a result, recent advancements in integrated photonic architectures—such as Mach-
Zehnder interferometric meshes, microring resonator arrays, metamaterials, and nanostructures—have
enabled a wide range of applications, including low-latency signal processing of radio and optical signals
[27–30], fast matrix multiplications [17, 31], and image processing [32, 33]. Furthermore, the adoption of
analog photonic hardware for training—incorporating backpropagation, forward propagation, and per-
turbative approaches—has spurred efforts to develop effective in-situ training methods to fully harness
its potential [34–36]. Despite their excellent inference performance, several challenges remain unre-
solved in state-of-the-art analog photonic architectures [28, 37]. These challenges include limited training
precision, the lack of on-the-fly training with dynamic data, the need for frequent analog-to-digital con-
versions, and the inadaptibility to crosstalk and environmental variations in real-time. In addition, most
of the in-situ training algorithms are highly hardware-dependent, unsuitable for high-speed operation,
and are difficult to implement across a broad range of neural network platforms. Therefore, unlocking the
full potential of photonic neuromorphic hardware requires the development of training techniques that
accommodate diverse device models while remaining robust to device-to-device variations and noise.
Fig. 1 Artificial intelligence training approaches and the analog end-to-end adaptive training system: a)
Widely adopted training methods implemented on analog learning hardware platforms include error propagation and
perturbative approaches. b) Demonstrated by the multiplexed gradient descent algorithm [38], perturbative approaches
can be applied to a wide range of machine learning models, including feedforward neural networks and recurrent neural
networks. c) These models give rise to a variety of real-life applications, enabling hardware-agnostic analog learning directly
using analog signals. This further enables our analog hardware to use its high bandwidth and low latency in online tracking
tasks, and creates the flexibility to adapt to various system- and platform-level parameter changes such as crosstalk.
Here, we experimentally demonstrate in-situ, fully end-to-end analog and on-the-fly training on an
integrated photonic platform using the multiplexed gradient descent (MGD) algorithm [38]. In this
approach, the gradient of the signal is directly measured at the output, eliminating the need for dig-
ital gradient calculations using matrix multiplications. The end-to-end analog architecture physically
measures the gradient and locally updates weights, so the entire training pipeline remains within the ana-
log domain. Gradient measurement is achieved by injecting small perturbative signals into the network
2

parameters and monitoring variations in the loss function based on device dynamics [38]. The flexibil-
ity and hardware-compatible nature of the algorithm enable the implementation of on-chip photonic
analog end-to-end adaptive training on a foundry-manufactured and CMOS-compatible silicon photonic
integrated circuit (PIC). Our architecture efficiently classifies both linear and nonlinear tasks, achieving
accuracy rates exceeding 90% and 80%, respectively. Additionally, our adaptive system can dynamically
track environmental changes, such as temperature variations and internal thermal crosstalk, by adjust-
ing training parameters in real time without external monitoring or downtime. We further demonstrate
adaptive online tracking at a Giga inference-per-second (GBaud rate), achieving over 90% accuracy with
rapid training convergence. This high-speed, low-latency in-situ, on-the-fly training enables real-time
adaptation and online tracking, overcoming the limitations typically encountered in other photonic archi-
tectures. In addition, we performed a simulation using a 4−30 −3 deep network of the Yin-Yang dataset,
consisting of a total of 210 weights [39], achieving an accuracy of over 97%, demonstrating the scalability
of the proposed method at larger scales. Our demonstration is hardware-agnostic, robust against sys-
tem noise and fabrication variations, and does not require sophisticated calibration routines [40]. These
characteristics mark a significant advancement toward self-adaptive, real-time photonic neuromorphic
systems capable of efficient online learning in complex, real-world scenarios. In addition, our proposed
analog end-to-end training system lays the foundation for scalable, high-speed, and energy-efficient pho-
tonic machine learning platforms, bridging the longstanding gap between analog neuromorphic processing
and real-world deployment in next-generation artificial intelligence.
2 Hardware implementation
The schematic illustration of the analog end-to-end training is implemented on a wavelength division
multiplexing (WDM) platform within a fully integrated on-chip system is shown in Fig. 2(a). The chip
consists of tunable filters, each independently tuned to a specific wavelength channel. The photonic
neural network illustrated in Figure 2(a) comprises an input modulator for encoding optical signals, a
weight bank array, balanced photodetectors (PDs), and PN-junction-based modulators for the nonlinear
activation function. Both the input-output modulators and weight bank arrays are implemented using
an array of compact circular waveguides known as microring resonator (MRR). The micrograph of the
fabricated WDM photonic neural network, including the microring resonator weight bank and balanced
photodetectors, is shown in Figure 2(b). The drop responses of the microring weight bank array and
the measured bandwidth of the PD are shown in Fig. 2 (c) and (d), respectively. The input signals are
amplitude-encoded across n wavelengths in an m×n network array. The microring weights are controlled
by source measurement units (SMUs), which set the voltage for each MRR. These voltages actuate
MRR resonances via in-resonator photoconductive heaters (IRPHs) using the thermo-optic effect [41].
The weighted input values are summed at the balanced photodetector, resulting in efficient matrix
multiplication. This process converts the analog output signals independently into the electrical domain
using m balanced photodetectors. The incoherent WDM broadcast and weight architecture eliminates the
need for precise control of phase shifters, mitigating interference and instability commonly encountered
in architectures based on coherent matrix multiplications. To enable fast data encoding, weight updates,
and gradient detection, we employ digital-to-analog converters (DACs) and analog-to-digital converters
(ADCs) integrated into an RFSoC FPGA. The DAC operates at a baud rate of 1 GBaud with 8 samples
per symbol, while the ADC samples at 4 GS/s. Further details of the experimental setup are provided
in the Methods section. Figure 2(e) presents a schematic of the implemented experimental setup.
The instantaneous loss function variations, ew(t), consists of a perturbation-free baseline loss function
L0, and a perturbed loss function eLi(t) with a variation component ∆Li(t), generated by the weight per-
turbation, ewi(t), at each neuron. Although the weight perturbations can take any pairwise-uncorrelated
time-varying function, we use a randomly generated binary perturbation for simplicity. The perturbation
ewi(t) follows a random binary sequence of ( −1, 1), with an amplitude of ∆ wi. Each weight is imple-
mented as a voltage signal applied to the MRRs in the weight bank, with perturbations introduced as
the sum of both the weight and its perturbation. The binary choices in the random sequence are unique
for each batch during every training epoch. As training progresses, this random sequence generates a
time-varying perturbation signal, causing corresponding variations in the loss function measurements.
The loss function is computed using the network output, y(t), and the training target ˆy(t). The weight
update wi incorporates the instantaneous measurements of the variation component of the loss function
and its corresponding weight perturbation. More details on the derivation of the MGD algorithm for
directly measuring the gradient are provided in the Supplementary Section 1.1 . Our chip performs
analog gradient approximations with perturbative training techniques [42], eliminating the need for con-
ventional large-scale matrix multiplications typically used for gradient calculations in digital learning
algorithms.
3 Results
3.1 Analog end-to-end training
First, we demonstrate our analog end-to-end adaptive training system by solving a linear classification
problem, where the classification rule is defined by an arbitrary line ( a · x1 − b · x2 = 0), where a and
b are real numbers. In the experiment, all the network parameters are initialized to random values,
and the gradient is measured by comparing baseline and perturbed loss function values — without and
with perturbations to the network parameters, respectively. These parameters are updated after each
batch, and training continues until convergence is reached. As shown in Fig 3(a), our system achieves
convergence in under 100 seconds, which is comparable to the calibration time in other calibration-based
3

Fig. 2 Schematics for experiment setup and device characterizations: a) Our vision for a wavelength-muliplexed
integrated neuromorphic photonic hardware that uses microring resonator (MRR) weight bank and on-chip balanced
photodetectors (BPDs). The inputs xi are amplitude-encoded on respective wavelength channels using ith microring mod-
ulators, all of which are broadcast to all neurons in the same layer. Each weight bank implements all the weights wN N
for the particular neuron plus the corresponding perturbations ewN N, and the balanced photodetector BPD N signals are
sent to N microring modulators. The biasing of the microring modulator determine the types of the nonlinear activation
function and produces output yi for that neuron. b) Micrographs of the electrically-packaged integrated photonic chip, and
the device-under-test, with labels for the electrical connections for the weights and photodetector bias. c) Spectrum of the
MRR weight bank. d) Bandwidth measurement of the integrated BPDs. e) The experimental setup used in this paper: a
single-layer, 2-input and 2-weight system consists of two optical input channels, x1 and x2, each modulated by a DAC on
the RFSoC FPGA via a Mach-Zehnder modulator (MZM). A WDM arrayed-waveguide grating (WDM AWG) multiplexes
both channels into a single waveguide, which is fed to the add-drop MRR weight bank integrated on chip. The MRRs are
controlled using two SMU channels, which communicate with the RFSoC FPGA to actuate the weights w1, and w2, as
well as perturbations ew1 and ew2. The weight bank optical output is detected through a pair of integrated BPDs, and the
output signals L0 and eL are measured with an ADC channel on the RFSoC FPGA.
approaches. We train the system for 200 epochs, achieving a prediction accuracy exceeding 90% with no
significant fluctuations. As a result, the standard deviations of the prediction accuracy and loss function
are 0.259 and 0 .00312, respectively.
Furthermore, we have trained the system for a nonlinear classification task using the same approach.
Figure 3(b) shows a demonstration of a nonlinear classification problem that introduces an arbitrary
quadratic nonlinearity ((a·x1+b·x2)2−0.05 = 0) at the photodetector output. Unlike linear classification,
the output of the quadratic function exists in the third dimension, where it intersects the original 2D
plane to form a band that defines class separation, as illustrated in Fig. 3(b) insets. For the experiment,
we follow the same procedure used in the linear classification case, with the addition of the quadratic
nonlinearity programmed on the RFSoC FPGA. As shown in Fig. 3(b), our system reaches convergence
within 100 training epochs, achieving a maximum accuracy above 80%. After convergence, the prediction
accuracy remains stable, with a standard deviation of 1.06%.
4

Fig. 3 Analog end-to-end training results: experimentally measured training accuracy values in both linear and
nonlinear classification problems, plus the system stability validation results. a) Linear classification of two sets of data
trained over 200 epochs, and both the initial and the optimal accuracy results are shown in the inset scatter plots.
The classification rule is defined by an arbitrary line (0 .0137 · x1 − 1 · x2 = 0). The background colors indicate the
correct classification results, and the color of the data points represents the results produced by the network. b) Nonlinear
classification with a quadratic separation of two sets of data, also trained over 200 epochs. The nonlinear classification
rule is defined by an arbitrary parameter ((0 · x1 + 1 · x2)2 − 0.05 = 0), which can be visualized as the projection of a
parabola onto a 2D plane as shown in the inset. The classification results are shown in the two scatter plot insets, where
the background colors indicate the correct classification results, and the color of the data points represents the results
produced by the network.
3.2 Online tracking
Online tracking is a time-sensitive task; consequently, real-time forecasting, anomaly detection, object
tracking, and adaptive control systems require continuous monitoring of dynamically evolving data [43–
45]. Adapting to such data necessitates rapid and continuous parameter updates, dynamic learning rules,
and operation across varying conditions—all while ensuring timely decision-making. Implementing a
hardware-agnostic algorithm capable of adapting to environmental variations typically involves updating
samples, modifying learning rules, and/or adjusting operating conditions. Existing photonic computing
hardware struggles to perform fully online real-time tracking due to (1) the need to simultaneously execute
training and inference, and (2) the requirement to achieve faster convergence and parameter update.
Therefore, to successfully implement online tracking, the hardware must update network weights on-the-
fly as soon as new data arrives. Here, we address the online tracking problem by enabling simultaneous
training and inference with fast convergence, while the learning rule for classification continuously adapts.
The dataset consists of 2,000 samples uniformly distributed in a 2D space, with the correct separation
between two classes evolving over time as reflected by updates in the learning rule signal.
For the online tracking task, we varied the classification criteria every 800 seconds — equivalent
to 200 training epochs — without providing any additional information to our analog system during
training. Initially, the separation between the two classes was set at a 55◦ angle relative to the horizontal
axis. Subsequently, the separation between the two classes was rotated through 13 randomly shuffled
configurations, with angles ranging from 15 ◦ to 255◦ in 20◦ increments. The sequence of shuffled angles
is illustrated in the subplot of Fig. 4(a). At the beginning of each angle change, there is an initial drop
in prediction accuracy, as seen in Fig 4(a). However, the system quickly recovers to the new problem,
achieving a prediction accuracy of approximately >85% within a few epochs ( <10) for most angles. We
also measure the training time in real-time, and this performance corresponds to a recovery time of
approximately 20 seconds whenever the learning rule is updated. More specifically, a zoomed-in plot of the
13 epochs around the transition from 255◦ to 95◦, shown in Fig 4(b), validates that our system restores its
former performance within just 4 epochs, corresponding to a training time within 20 seconds. Figure 4(c)
shows the best prediction accuracy achieved at every angle, plotted with the corresponding standard
deviation recorded. However, we occasionally observe a momentary decrease in prediction accuracy after
the system has reached convergence, primarily as a byproduct of the perturbations used in our analog
training method. While such fluctuations can be mitigated through fine-tuning hyperparameters—such as
perturbation amplitude and learning rate—they cannot be entirely eliminated due to the inherent nature
of the perturbation-based approach. Notably, such brief moments of instability only occur sporadically
and have a negligible impact on overall system performance.
3.3 Real-time adaptation
Analog computing hardware is typically sensitive to both external and internal variations—such as
environmental temperature changes and thermal crosstalk—which can significantly affect system perfor-
mance [28, 41, 46]. For example, environmental temperature fluctuations and thermal crosstalk between
neighboring heat-actuated weights degrade reliability. While some performance gains have been achieved
using error correction and hybrid analog-digital architectures, our analog system continuously adapts and
readjusts in real time, maintaining stable performance during simultaneous training and inference. As
a result, the photonic analog system offers fully integrated self-learning and self-correction capabilities,
enabling dynamic adaptation to both external non-idealities (e.g., platform temperature changes) and
on-chip non-idealities (e.g., thermal crosstalk) in real time, using the MGD algorithm for simultaneous
inference and training.
5

Fig. 4 Online tracking results: the separation rule rotates through a sequence of three different angles calculated with
respect to the x-axis, and we demonstrate our system successfully adapts to the logical changes. a) Training accuracy values
measured experimentally at thirteen unique angles ranging from 15◦ to 255◦ with a step size of 20◦, updated after every 200
epochs. The thirteen different angles are randomly shuffled, and are plotted against time in the subplot here. b) Zoomed-
in plot of the epochs near the transition from 255 ◦ to 95 ◦, together with three scatter plots showing the system output
before, at, and after the angle change. c) Best prediction accuracy achieved at every angle, plotted with the corresponding
standard deviation recorded.
Our photonic chip is placed on a temperature-controlled stage that maintains the operating temper-
ature within ±0.25°C of the target set value. Typically, a temperature variation of just 2 °C can result
in up to a 50% change in the effective weights. As a proof of concept, we first trained the system at
25◦C for 200 epochs. At this temperature, optical weight values of 1 and -1 correspond to actuation
voltages of 0 V and 2 V, respectively. Within this range, the mapping between the applied voltage and
the resulting optical weight is approximately linear. We then increase the platform temperature to 27 ◦C
and continue training for another 200 epochs. Subsequently, we adjust the temperature to 25 ◦C, then to
23◦C, and back to 25 ◦C, changing the temperature every 200 epochs. The training accuracy per epoch
is shown in Fig. 5(a), demonstrating that our system can accommodate platform temperature variations
up to ∆ T (±2◦C) and quickly recover its performance after each temperature change, as confirmed in
the zoomed-in plot in Fig. 5(a).
To better explain the effect of a temperature change ∆ T on the weights, we introduce the concept
for the rate of equivalent weight change which can be calculated as rate of equivalent weight change =
∆wo/tT , where ∆ wo is the equivalent percentage change in the optimal weight value as a result of the
temperature change, and tT is the amount of time between temperature change measured in minutes.
Because the target problem is constant, the optimal weights should have the same numerical values
despite the changes to the physical parameters. Here, the average time between temperature change
is approximately 4.8 minutes, and we find that the rate of equivalent weight change to be around
23.7% · min−1 for weight 1 and around 5 .48% · min−1 for weight 2. This indicates that our system is
capable of accommodating environmental temperature changes that translate to a weight change of more
than 20% per minute. This rate could be adapted by varying the learning rate. To assess system stability
against thermal crosstalk, we steadily increase the bias voltages two neighboring channels from 0 V to 5
V over 200 epochs, as shown in Fig. 5(b). This adjustments occur after the initial 200 epochs, with the
bias voltage increasing by 25 mV per epoch. Following this, we introduce sustained thermal crosstalk
by maintaining a 5 V bias voltage on both neighboring channels for the final 200 epochs. As shown in
Fig. 5(b), brief moments of instability occur as the bias voltages ramp up; however, our system quickly
recovers and remains resilient against the effects of thermal crosstalk.
4 Discussion
Our system demonstrates in situ, on-the-fly training capabilities while addressing key challenges in
neuromorphic hardware, such as stability in online tracking and real-time adaptation. We validated
the effectiveness of the MGD method on a foundry-manufactured silicon photonic integrated circuit.
Additionally, we evaluated system performance metrics, including scalability, latency, convergence time,
and energy efficiency. The estimated key metrics and performance comparison with state-of-the-art
architectures are summarized in Table 1.
6

Fig. 5 Real-time adaptation results: we demonstrate the excellent stability of our system against two major envi-
ronmental variations. a) we apply temperature changes to the test platform by varying the target temperature set by the
temperature controller every 200 training epochs. The temperature starts at 25 ◦C, and goes to 27 ◦C, 25 ◦C, 23 ◦C, and
25◦C subsequently. We record training accuracy after each epoch and provide a zoomed-in plot of the epochs near the
first temperature transition from 25 ◦C to 27 ◦C. At 25 ◦C, the actuated weight voltage range of [0 , 2] V corresponds to a
measured optical weight range of [ −1, 1]. b) we introduce on-chip thermal crosstalk by injecting a steadily increasing bias
voltage to the channels neighboring the ones under test. Starting from the 200 th epoch, the bias voltages to the neighbor-
ing two channels are increased from 0 V to 5 V over a period of 200 epochs, with a step size of 25 mV per epoch. The
thermal crosstalk persists after the bias voltages reach the maximum value for the rest of the trial. c) Weight voltage val-
ues recorded throughout the thermal crosstalk demonstration, together with the bias voltage supplied to the neighboring
channels to generate thermal crosstalk.
The MGD algorithm has shown excellent scalability in digital electronic hardware [47]. Extending
this concept, we simulate the MGD training of a multi-layer network implemented on an analog end-
to-end adaptive photonic training system. The network is trained to classify the Yin-Yang dataset [39]
comprising an input layer of four nodes, a hidden layer of 30 nodes, and an output layer of three nodes,
totaling 37 neurons in a fully connected configuration, as shown in Fig. 6(a). In the hardware architec-
ture, each node would be mapped to four MRRs, resulting in a total of 210 MRRs. Furthermore, we
incorporated a rectified linear unit (ReLU) nonlinearity in the simulation to enhance the training effi-
ciency. This nonlinearity can be realized by appropriately biasing the microring modulator neurons [48].
Our large-scale multi-layer network simulation follows the procedure outlined in Algorithm 1, where
weight and bias perturbations are simultaneously introduced in each batch. The training progress is
depicted in Fig. 6(b), where the system achieves over 80% accuracy around 1,000 epochs and reaches
97.9% accuracy after 8,000 epochs. The classification results and the corresponding confusion matrix at
the end of training are shown in Fig. 6(c) and Fig. 6(d), respectively. For comparison, a CMOS-based
7

implementation trained using the ADAM optimizer in PyTorch achieved 97 .6 ± 1.5% accuracy, demon-
strating parity with our photonic approach. These findings validate the scalability and effectiveness of
perturbative training techniques for photonic circuits in larger-scale networks.
Fig. 6 Yin-yang classification with multi-layer networks: we simulated our analog end-to-end adaptive training
system with a feedforward network containing one input layer with 4 neurons, one hidden layer with 30 neurons, and one
output layer with 3 neurons, all fully connected as shown in a). All neurons in both the hidden layer and the output layer
feature a ReLU nonlinearity, and include a trainable bias for each node. b) Training accuracy results obtained from our
simulation over 10,000 epochs, reaching a maximum accuracy of 97.9%. c) Snapshots of the classification outputs at the
beginning of the training and at the epoch with the best accuracy value. d) Confusion matrix at the end of the training
simulation.
Furthermore, we analyze the system latency of our analog photonic platform. The time delay between
the input vector and the output classification is 11.7 ps. When accounting for the response time of
high-speed ADCs, DACs, and photodetectors, the total end-to-end classification latency remains low
at 74.2 ps (see the Supplementary Section). Convergence time is another critical metric for training.
We experimentally measured convergence times across different tasks under a fixed operating condition.
For classification tasks, the total convergence time is ∼15s. The frequency and abrupt variations in
internal parameters significantly influence the time required to exceed 80% accuracy. The system takes
longer to converge for slower processes, such as temperature variations. In the current configuration,
the N×N network has N 2 control parameters for matrix multiplication, with weight elements currently
being temperature-controlled, contributing to the observed convergence time. However, our photonic
chip also supports carrier-depletion PN junction for electro-optic weight tuning, which provides a typical
bandwidth of 17 GHz [49]. This enables rapid weight adjustments, reducing convergence times by a
factor of 1,000 from microseconds to milliseconds depending on the application.
Table 1 Comparisons with other contemporary works.
Analog
inference
latency
Analog
training
latency
Energy efficiency Online
tracking 1
Real-time
adapta-
tion 2
This work 11.7 ps 22 ms 3,000 GOPS/W Yes Yes
Momeni, A. et al. [50] 192 ps Not given 0.12 GOPS/W No No
Bandyopadhyay, S. et al. [51] 410 ps Not given 13 GOPS/W No No
Pai, S et al. [34] 1 ns Offline
training
5,000 GOPS/W No No
Xue, Z et al. [36] Not given 64 ms 5.4 × 109 GOPS/W No No
Ashtiani, F. et al. [52] 570 ps Digital
training
71.4 GOPS/W No No
1Online tracking of updates to the training problem or learning rule.
2Real-time adaptation to external and internal parameter changes, including environmental temperature variations and
neighboring channel thermal crosstalk.
Our work underscores the energy efficiency of the monolithically integrated photonic chip. The system
has a total power consumption of 27.4 mW— including photonics, drivers, and readout electronics,
resulting in an energy efficiency of 853 fJ/Op, equivalent to 1.2 TOPS/W at a 16 GBaud operational
speed. The photodetector bandwidth of 16 GHz is currently the limiting factor for higher inference
rates in our setup. See the Supplementary section for a detailed breakdown of the power budget and
8

energy efficiency of individual components. For the 4 ×30×3 neural network architecture (see Fig.6(a)),
each neuron is implemented with four MRRs, performing 243 operations (5 ×30+31×3) per inference
cycle, yielding an energy efficiency of 3.4 fJ/Ops, corresponding to 291 TOPS/W. A comparison of
on-chip and free-space optical computing architectures is presented in Table 1. Moreover, we highlight
that integrating phase-change materials (PCMs) in our architecture could push energy efficiency to the
PetaOPs/W range while significantly enhancing information density. This capability paves the way for
ultrafast, power-efficient, and low-cost neuromorphic computing platforms, addressing both scalability
and real-time adaptability in photonic machine learning.
5 Conclusion
We have proposed and experimentally demonstrated an analog end-to-end adaptive neuromorphic hard-
ware system that physically measures and locally updates the gradient of the dynamical system directly
in the optical domain. Unlike conventional digital implementations, which are constrained by the limita-
tions of digital matrix multiplications, our platform achieves fully analog gradient measurement through
multiplexing and perturbative updates at the output. This approach effectively bypasses digital precision
bottlenecks and high-accuracy inference while maintaining robust real-time adaptability. Our demon-
stration addresses critical, longstanding challenges that have limited the practicality of neuromorphic
hardware architectures, particularly the inability to perform on-the-fly training with dynamic data and
the lack of real-time adaptation to crosstalk and environmental fluctuations. Implemented on an inte-
grated photonic platform, our system achieves favorable performance in online tracking tasks, reaching
86.5% accuracy while dynamically adapting to learning rules. Notably, our system ensures stability even
when training continues past convergence, eliminating the need for manual calibration or active stabi-
lization. This intrinsic stability allows our photonic processor to self-adapt to changing conditions with
fast convergence, effectively mitigating the impact of system noise. We further evaluated our system’s
performance in terms of scalability, latency, and energy efficiency. Our photonic system achieves an ultra-
low latency of 11.7 ps and an energy efficiency of 853 fJ/Op, highlighting its potential for large-scale
neuromorphic networks. Our platform’s fully analog processing significantly reduces the complexity asso-
ciated with training neuromorphic hardware, paving the way for scalable implementations in integrated
photonics. This work represents a significant advancement toward practical, energy-efficient, high-speed,
and noise-resilient analog neuromorphic hardware. The demonstrated online adaptive training approach
is versatile and broadly applicable across a spectrum of machine learning platforms. Crucially, it lays the
groundwork for real-time learning in analog hardware, with transformative implications for applications
in sensing, autonomous driving, telecommunications, and beyond.
6 Methods
6.1 Device fabrication
The device-under-test here is fabricated on a silicon-on-insulator (SOI) wafer with a silicon thickness of
220 nm and a buried oxide thickness of 2 µm. The bus waveguides have a width of 500 nm. The MRRs
have radii of 8 .0 µm, 8.01213 µm, 8.02426 µm, 8.03639 µm, 8.04852 µm. The gap between the ring and
the bus waveguide is 200 nm, yielding a Q factor of ∼ 6000, and the free spectral range is around 12
nm for an MRR with 8 µm radius. The MRRs have in-resonantor photoconductive heaters [41] that
can actuate the weight by thermally tuning the MRR resonance. To implement the N-doped heater,
each MRR consists of a circular waveguide etched to a 90 nm thick pedestal that hosts the phosphorous
dopants. A 10 µm wide N doping section is patterned to follow the MRR, outside of which heavy N++
doping is used to make ohmic contacts. The phosphorous dopant concentrations are N: 5 × 1017 cm−3
and N++: 5 × 1020 cm−3. Metal vias and traces are deposited to connect the heater contacts of the
MRR weight bank to electrical metal pads. An integrated balanced photodetector sums up the difference
between the drop and through ports without the need for a differential amplifier, giving weighted addition
of all the input signals. On-chip detection also removes the need to couple the light off-chip, reducing
round-trip coupling loss by half. The BPD implements two germanium-based photodetectors connected
in series with the n-contact of one PD connected to the p-contact of the second PD [53] and has been
benchmarked to reach 16 GHz bandwidth.
6.2 Experiments
In our experimental setup we use an RFSoC FPGA (Xilinx RFSoC 4 × 2) to modulate the inputs and
measure the outputs from our integrated photonic weight bank, whose weights are controlled using 4
SMU channels (Keithley 2606B). RF amplifiers (Mini-Circuits ZX60-14012L-S+) are also used to boost
the output photocurrent, and we also use bias-tees to split off the DC bias which is measured with
another SMU channel.
The dataset used in both online tracking and stability validation contains 20,000 samples, which are
divided into batches each consisting of 100 samples. Every sample has two parameters representing its
coordinates in the 2D domain, and each parameter is modulated by a DAC on the RFSoC FPGA.As
shown in Fig 2(b), every training epoch iterates through all the batches in the dataset, and every batch
starts by instantiating all input samples within a batch using the two DACs on the RFSoC FPGA.
First we measure the output signal which gives us the baseline loss function values. After perturbing the
weights, we measure again the loss function with variations, and the difference between the perturbed
and unperturbed loss function corresponds to the gradient.
9

Acknowledgements. The U.S. Government is authorized to reproduce and distribute reprints for
governmental purposes notwithstanding any copyright annotation thereon. This research was funded by
Queen’s University (https://ror.org/02y72wh86), University of Pittsburgh (https://ror.org/01an3r305),
and NIST (https://ror.org/05xpvk416).
Thanks to Nathanael Eddy for his assistance taking the micrographs using a modified Nikon-E
microscope (Centre for Nanophotonics, Department of Physics, Engineering Physics, and Astronomy,
Queen’s University).
References
[1] Bywater, R.: Solving the protein folding problems. Nature Precedings (2010) https://doi.org/10.
1038/npre.2010.4730.1
[2] Zhou, L., Schellaert, W., Mart´ ınez-Plumed, F., Moros-Daval, Y., Ferri, C., Hern´ andez-Orallo, J.:
Larger and more instructable language models become less reliable. Nature 634(8032), 61–68 (2024)
https://doi.org/10.1038/s41586-024-07930-y
[3] Chen, Y., Nazhamaiti, M., Xu, H., Meng, Y., Zhou, T., Li, G., Fan, J., Wei, Q., Wu, J., Qiao, F.,
Fang, L., Dai, Q.: All-analog photoelectronic chip for high-speed vision tasks. Nature 623(7985),
48–57 (2023) https://doi.org/10.1038/s41586-023-06558-8
[4] Bishop, C.M.: Neural networks and their applications. Review of Scientific Instruments
65(6), 1803–1832 (1994) https://doi.org/10.1063/1.1144830 https://pubs.aip.org/aip/rsi/article-
pdf/65/6/1803/19141715/1803 1 online.pdf
[5] LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. Nature 521(7553), 436–444 (2015) https://doi.
org/10.1038/nature14539
[6] Bengio, Y., Boulanger-Lewandowski, N., Pascanu, R.: Advances in optimizing recurrent networks.
In: 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 8624–8628
(2013). https://doi.org/10.1109/ICASSP.2013.6639349
[7] Krogh, A.: What are artificial neural networks? Nature Biotechnology 26(2), 195–197 (2008) https:
//doi.org/10.1038/nbt1386
[8] Scellier, B., Bengio, Y.: Equilibrium propagation: Bridging the gap between energy-based models
and backpropagation. Frontiers in Computational Neuroscience 11 (2017) https://doi.org/10.3389/
fncom.2017.00024
[9] Xu, T., Zhang, W., Zhang, J., Luo, Z., Xiao, Q., Wang, B., Luo, M., Xu, X., Shastri, B.J., Prucnal,
P.R., Huang, C.: Control-free and efficient integrated photonic neural networks via hardware-aware
training and pruning. Optica 11(8), 1039–1049 (2024) https://doi.org/10.1364/OPTICA.523225
[10] Zhao, G., Shu, X., Zhou, R.: High-performance real-world optical computing trained by in
situ gradient-based model-free optimization. IEEE transactions on pattern analysis and machine
intelligence PP (2024) https://doi.org/10.1109/TPAMI.2024.3466853
[11] Lin, H., Ou, J., Fan, Z., Yan, X., Hu, W., Cui, B., Xu, J., Li, W., Chen, Z., Yang, B., Liu, K.,
Mo, L., Li, M., Lu, X., Zhou, G., Gao, X., Liu, J.-M.: In situ training of an in-sensor artificial
neural network based on ferroelectric photosensors. Nature Communications16(1), 421 (2025) https:
//doi.org/10.1038/s41467-024-55508-z
[12] Wright, L.G., Onodera, T., Stein, M.M., Wang, T., Schachter, D.T., Hu, Z., McMahon, P.L.: Deep
physical neural networks trained with backpropagation. Nature 601(7894), 549–555 (2022) https:
//doi.org/10.1038/s41586-021-04223-6
[13] Fu, T., Zhang, J., Sun, R., Huang, Y., Xu, W., Yang, S., Zhu, Z., Chen, H.: Optical neural networks:
progress and challenges. Light: Science & Applications 13(1), 263 (2024) https://doi.org/10.1038/
s41377-024-01590-3
[14] Wetzstein, G., Ozcan, A., Gigan, S., Fan, S., Englund, D., Soljaˇ ci´ c, M., Denz, C., Miller, D.A.B.,
Psaltis, D.: Inference in artificial intelligence with deep optics and photonics. Nature 588(7836),
39–47 (2020) https://doi.org/10.1038/s41586-020-2973-6
[15] Filipovich, M.J., Guo, Z., Al-Qadasi, M., Marquez, B.A., Morison, H.D., Sorger, V.J., Prucnal, P.R.,
Shekhar, S., Shastri, B.J.: Silicon photonic architecture for training deep neural networks with direct
feedback alignment. Optica 9(12), 1323–1332 (2022) https://doi.org/10.1364/OPTICA.475493
[16] Dalgaty, T., Castellani, N., Turck, C., Harabi, K.-E., Querlioz, D., Vianello, E.: In situ learning
using intrinsic memristor variability via markov chain monte carlo sampling. Nature Electronics
4(2), 151–161 (2021) https://doi.org/10.1038/s41928-020-00523-3
[17] Lin, Z., Shastri, B.J., Yu, S., Song, J., Zhu, Y., Safarnejadian, A., Cai, W., Lin, Y., Ke, W., Ham-
mood, M., Wang, T., Xu, M., Zheng, Z., Al-Qadasi, M., Esmaeeli, O., Rahim, M., Pakulski, G.,
10

Schmid, J., Barrios, P., Jiang, W., Morison, H., Mitchell, M., Guan, X., Jaeger, N.A.F., Rusch,
L.A., Shekhar, S., Shi, W., Yu, S., Cai, X., Chrostowski, L.: 120 gops photonic tensor core in thin-
film lithium niobate for inference and in situ training. Nature Communications 15(1), 9081 (2024)
https://doi.org/10.1038/s41467-024-53261-x
[18] Dohare, S., Hernandez-Garcia, J.F., Lan, Q., Rahman, P., Mahmood, A.R., Sutton, R.S.: Loss of
plasticity in deep continual learning. Nature 632(8026), 768–774 (2024) https://doi.org/10.1038/
s41586-024-07711-7
[19] Lillicrap, T.P., Santoro, A., Marris, L., Akerman, C.J., Hinton, G.: Backpropagation and the brain.
Nature Reviews Neuroscience 21(6), 335–346 (2020) https://doi.org/10.1038/s41583-020-0277-3
[20] Momeni, A., Rahmani, B., Scellier, B., Wright, L.G., McMahon, P.L., Wanjura, C.C., Li, Y., Skalli,
A., Berloff, N.G., Onodera, T., Oguz, I., Morichetti, F., Hougne, P., Gallo, M.L., Sebastian, A.,
Mirhoseini, A., Zhang, C., Markovi´ c, D., Brunner, D., Moser, C., Gigan, S., Marquardt, F., Ozcan,
A., Grollier, J., Liu, A.J., Psaltis, D., Al` u, A., Fleury, R.: Training of Physical Neural Networks
(2024). https://arxiv.org/abs/2406.03372
[21] Buckley, S.M., Tait, A.N., McCaughan, A.N., Shastri, B.J.: Photonic online learning: a perspective.
Nanophotonics 12(5), 833–845 (2023) https://doi.org/10.1515/nanoph-2022-0553
[22] Wang, Z., M¨ uller, K., Filipovich, M., Launay, J., Ohana, R., Pariente, G., Mokaadi, S., Brossollet,
C., Moreau, F., Cappelli, A., Poli, I., Carron, I., Daudet, L., Krzakala, F., Gigan, S.: Optical training
of large-scale Transformers and deep neural networks with direct feedback alignment (2024). https:
//arxiv.org/abs/2409.12965
[23] Br¨ uckerhoff-Pl¨ uckelmann, F., Bente, I., Becker, M., Vollmar, N., Farmakidis, N., Lomonte, E.,
Lenzini, F., Wright, C.D., Bhaskaran, H., Salinga, M., Risse, B., Pernice, W.H.P.: Event-driven adap-
tive optical neural network. Science Advances 9(42), 9127 (2023) https://doi.org/10.1126/sciadv.
adi9127 https://www.science.org/doi/pdf/10.1126/sciadv.adi9127
[24] Marpaung, D., Yao, J., Capmany, J.: Integrated microwave photonics. Nature Photonics 13(2),
80–90 (2019) https://doi.org/10.1038/s41566-018-0310-5
[25] Shastri, B.J., Tait, A.N., Lima, T., Pernice, W.H.P., Bhaskaran, H., Wright, C.D., Prucnal, P.R.:
Photonics for artificial intelligence and neuromorphic computing. Nature Photonics 15(2), 102–114
(2021) https://doi.org/10.1038/s41566-020-00754-y
[26] Querlioz, D.: Physics solves a training problem for artificial neural networks. Nature (London)
632(8024), 264–265 (2024)
[27] Huang, C., Fujisawa, S., Lima, T.F., Tait, A.N., Blow, E.C., Tian, Y., Bilodeau, S., Jha, A., Yaman,
F., Peng, H.-T., Batshon, H.G., Shastri, B.J., Inada, Y., Wang, T., Prucnal, P.R.: A silicon photonic–
electronic neural network for fibre nonlinearity compensation. Nature Electronics 4(11), 837–844
(2021) https://doi.org/10.1038/s41928-021-00661-2
[28] Zhang, W., Tait, A., Huang, C., Lima, T., Bilodeau, S., Blow, E.C., Jha, A., Shastri, B.J.,
Prucnal, P.: Broadband physical layer cognitive radio with an integrated photonic processor
for blind source separation. Nature Communications 14(1), 1107 (2023) https://doi.org/10.1038/
s41467-023-36814-4
[29] Lederman, J.C., Zhang, W., Lima, T.F., Blow, E.C., Bilodeau, S., Shastri, B.J., Prucnal, P.R.: Real-
time photonic blind interference cancellation. Nature Communications 14(1), 8197 (2023) https:
//doi.org/10.1038/s41467-023-43982-w
[30] Zhang, W., Lederman, J.C., Lima, T., Zhang, J., Bilodeau, S., Hudson, L., Tait, A., Shastri, B.J.,
Prucnal, P.R.: A system-on-chip microwave photonic processor solves dynamic rf interference in real
time with picosecond latency. Light: Science & Applications 13(1), 14 (2024) https://doi.org/10.
1038/s41377-023-01362-5
[31] Totovic, A., Giamougiannis, G., Tsakyridis, A., Lazovsky, D., Pleros, N.: Programmable photonic
neural networks combining wdm with coherent linear optics. Scientific Reports 12(1), 5605 (2022)
https://doi.org/10.1038/s41598-022-09370-y
[32] Xu, X., Tan, M., Corcoran, B., Wu, J., Boes, A., Nguyen, T.G., Chu, S.T., Little, B.E., Hicks, D.G.,
Morandotti, R., Mitchell, A., Moss, D.J.: 11 tops photonic convolutional accelerator for optical
neural networks. Nature 589(7840), 44–51 (2021) https://doi.org/10.1038/s41586-020-03063-0
[33] Feldmann, J., Youngblood, N., Karpov, M., Gehring, H., Li, X., Stappers, M., Le Gallo, M., Fu,
X., Lukashchuk, A., Raja, A.S., Liu, J., Wright, C.D., Sebastian, A., Kippenberg, T.J., Pernice,
W.H.P., Bhaskaran, H.: Parallel convolutional processing using an integrated photonic tensor core.
Nature 589(7840), 52–58 (2021) https://doi.org/10.1038/s41586-020-03070-1
[34] Pai, S., Sun, Z., Hughes, T.W., Park, T., Bartlett, B., Williamson, I.A.D., Minkov, M.,
11

Milanizadeh, M., Abebe, N., Morichetti, F., Melloni, A., Fan, S., Solgaard, O., Miller,
D.A.B.: Experimentally realized in situ backpropagation for deep learning in photonic
neural networks. Science 380(6643), 398–404 (2023) https://doi.org/10.1126/science.ade8450
https://www.science.org/doi/pdf/10.1126/science.ade8450
[35] Zheng, Z., Duan, Z., Chen, H., Yang, R., Gao, S., Zhang, H., Xiong, H., Lin, X.: Dual adaptive
training of photonic neural networks. Nature Machine Intelligence 5(10), 1119–1129 (2023) https:
//doi.org/10.1038/s42256-023-00723-4
[36] Xue, Z., Zhou, T., Xu, Z., Yu, S., Dai, Q., Fang, L.: Fully forward mode training for optical neural
networks. Nature 632(8024), 280–286 (2024) https://doi.org/10.1038/s41586-024-07687-4
[37] Mourgias-Alexandris, G., Moralis-Pegios, M., Tsakyridis, A., Simos, S., Dabos, G., Totovic, A.,
Passalis, N., Kirtas, M., Rutirawut, T., Gardes, F.Y., Tefas, A., Pleros, N.: Noise-resilient and high-
speed deep learning with coherent silicon photonics. Nature Communications 13(1), 5572 (2022)
https://doi.org/10.1038/s41467-022-33259-z
[38] McCaughan, A.N., Oripov, B.G., Ganesh, N., Nam, S.W., Dienstfrey, A., Buck-
ley, S.M.: Multiplexed gradient descent: Fast online training of modern datasets on
hardware neural networks without backpropagation. APL Machine Learning 1(2),
026118 (2023) https://doi.org/10.1063/5.0157645 https://pubs.aip.org/aip/aml/article-
pdf/doi/10.1063/5.0157645/18017061/026118 1 5.0157645.pdf
[39] Kriener, L., G¨ oltz, J., Petrovici, M.A.: The Yin-Yang dataset (2022). https://arxiv.org/abs/2102.
08211
[40] Guo, Z., Tait, A.N., Marquez, B.A., Filipovich, M., Morison, H., Prucnal, P.R., Chrostowski, L.,
Shekhar, S., Shastri, B.J.: Multi-level encoding and decoding in a scalable photonic tensor processor
with a photonic general matrix multiply (gemm) compiler. IEEE Journal of Selected Topics in
Quantum Electronics 28(6: High Density Integr. Multipurpose Photon. Circ.), 1–14 (2022) https:
//doi.org/10.1109/JSTQE.2022.3196884
[41] Jayatilleka, H., Murray, K., Guill´ en-Torres, M., Caverley, M., Hu, R., Jaeger, N.A.F., Chrostowski,
L., Shekhar, S.: Wavelength tuning and stabilization of microring-based filters using silicon in-
resonator photoconductive heaters. Opt. Express 23(19), 25084–25097 (2015) https://doi.org/10.
1364/OE.23.025084
[42] Dembo, A., Kailath, T.: Model-free distributed learning. IEEE Transactions on Neural Networks
1(1), 58–70 (1990) https://doi.org/10.1109/72.80205
[43] Yang, C., Li, Y., Zhou, S., Guo, Y., Jia, C., Liu, Z., Houk, K.N., Dubi, Y., Guo, X.: Author correction:
Real-time monitoring of reaction stereochemistry through single-molecule observations of chirality-
induced spin selectivity. Nature Chemistry (2024) https://doi.org/10.1038/s41557-024-01670-2
[44] Blaser, E., Pylyshyn, Z.W., Holcombe, A.O.: Tracking an object through feature space. Nature
408(6809), 196–199 (2000) https://doi.org/10.1038/35041567
[45] Lale, S., Renn, P.I., Azizzadenesheli, K., Hassibi, B., Gharib, M., Anandkumar, A.: Falcon: Fourier
adaptive learning and control for disturbance rejection under extreme turbulence. npj Robotics2(1),
6 (2024) https://doi.org/10.1038/s44182-024-00013-0
[46] Zhang, W., Huang, C., Peng, H.-T., Bilodeau, S., Jha, A., Blow, E., Lima, T.F., Shastri, B.J.,
Prucnal, P.: Silicon microring synapses enable photonic deep learning beyond 9-bit precision. Optica
9(5), 579–584 (2022) https://doi.org/10.1364/OPTICA.446100
[47] Oripov, B.G., Dienstfrey, A., McCaughan, A.N., Buckley, S.M.: Scaling of
hardware-compatible perturbative training algorithms. APL Machine Learning 3(2),
026107 (2025) https://doi.org/10.1063/5.0258271 https://pubs.aip.org/aip/aml/article-
pdf/doi/10.1063/5.0258271/20492805/026107 1 5.0258271.pdf
[48] Tait, A.N., Lima, T., Nahmias, M.A., Miller, H.B., Peng, H.-T., Shastri, B.J., Prucnal, P.R.: Sil-
icon photonic modulator neuron. Phys. Rev. Appl. 11, 064043 (2019) https://doi.org/10.1103/
PhysRevApplied.11.064043
[49] Hagan, D.E., Ye, M., Wang, P., Cartledge, J.C., Knights, A.P.: High-speed performance of a tdfa-
band micro-ring resonator modulator and detector. Optics express 28(11), 16845–16856 (2020)
[50] Momeni, A., Rahmani, B., Mall´ ejac, M., Hougne, P., Fleury, R.: Backpropagation-free training
of deep physical neural networks. Science 382(6676), 1297–1303 (2023) https://doi.org/10.1126/
science.adi8474 https://www.science.org/doi/pdf/10.1126/science.adi8474
[51] Bandyopadhyay, S., Sludds, A., Krastanov, S., Hamerly, R., Harris, N., Bunandar, D., Streshin-
sky, M., Hochberg, M., Englund, D.: Single-chip photonic deep neural network with forward-only
training. Nature Photonics (2024) https://doi.org/10.1038/s41566-024-01567-z
12

[52] Ashtiani, F., Geers, A.J., Aflatouni, F.: An on-chip photonic deep neural network for image
classification. Nature 606(7914), 501–506 (2022) https://doi.org/10.1038/s41586-022-04714-0
[53] Hai, M.S., Sakib, M.N., Liboiron-Ladouceur, O.: A 16 GHz silicon-based monolithic balanced
photodetector with on-chip capacitors for 25 GBaud front-end receivers. Opt. Express 21(26),
32680–32689 (2013) https://doi.org/10.1364/OE.21.032680
13
