# 2502.06309v3.pdf

Analog In-memory Training on General Non-ideal
Resistive Elements: The Impact of Response Functions
Zhaoxian Wu∗, Quan Xiao∗, Tayfun Gokmen♯, Omobayode Fagbohungbe♯,
Tianyi Chen∗
∗Cornell University, New York, NY
♯IBM T. J. Watson Research Center, Yorktown Heights, NY
{zw868, qx232}@cornell.edu,
{tgokmen, Omobayode.Fagbohungbe}@us.ibm.com,
tianyi.chen@cornell.edu
Abstract
As the economic and environmental costs of training and deploying large vision
or language models increase dramatically, analog in-memory computing (AIMC)
emerges as a promising energy-efficient solution. However, the training perspective,
especially its training dynamic, is underexplored. In AIMC hardware, the trainable
weights are represented by the conductance of resistive elements and updated using
consecutive electrical pulses. While the conductance changes by a constant in
response to each pulse, in reality, the change is scaled by asymmetric and non-linear
response functions, leading to a non-ideal training dynamic. This paper provides a
theoretical foundation for gradient-based training on AIMC hardware with non-
ideal response functions. We demonstrate that asymmetric response functions
negatively impact Analog SGD by imposing an implicit penalty on the objective. To
overcome the issue, we propose residual learning algorithm, which provably
converges exactly to a critical point by solving a bilevel optimization problem. We
demonstrate that the proposed method can be extended to address other hardware
imperfections, such as limited response granularity. As we know, it is the first
paper to investigate the impact of a class of generic non-ideal response functions.
The conclusion is supported by simulations validating our theoretical insights.
1 Introduction
The remarkable success of large vision and language models is underpinned by advances in modern
hardware accelerators, such as GPU, TPU [ 1], NPU [ 2], and NorthPole chip [ 3]. However, the
computational demands of training these models are staggering. For instance, training LLaMA
[4] cost $2.4 million, while training GPT-3 [5] required $4.6 million, highlighting the urgent need
for more efficient computing hardware. Current mainstream hardware relies on the V on Neumann
architecture, where the physical separation of memory and processing units creates a bottleneck due
to frequent and costly data movement between them.
In this context, the industry has turned its attention toanalog in-memory computing (AIMC) accel-
eratorsbased on resistive crossbar arrays [ 6–10], which excel at accelerating the ubiquitous and
computationally intensive matrix-vector multiplications (MVMs) operations. In AIMC hardware,
the weights (matrices) are represented by the conductance states of theresistive elementsin analog
crossbar arrays [11, 12], while the input and output of MVM are analog signals like voltage and
∗The work was done when the authors were at Rensselaer Polytechnic Institute, and was supported by IBM
through the IBM-Rensselaer Future of Computing Research Collaboration.
39th Conference on Neural Information Processing Systems (NeurIPS 2025).
arXiv:2502.06309v3  [cs.LG]  19 Sep 2025

+ -
# of pulse cycles
weight      (conductance)
pos.
 neg.
+ -
# of pulse cycles
weight      (conductance)
pos.
 neg.
Figure 1: The weight’s response curve. Positive and negative pulses are fired continuously on the
left and right halves, respectively. One pulse is fired per cycle. Given w, the weight becomes w+
or w− after one positive and negative pulse, respectively. The response factors q+(w) and q−(w)
are approximately the slope of the curve at w, and ∆wmin is the response granularity.(Left)Ideal
response functions q+(w)≡q −(w). Every point is a symmetric point.(Right)Asymmetric response
functionsq +(w)̸=q −(w)almost everywhere expect for the symmetric pointw ⋄.
current. Leveraging Kirchhoff’s and Ohm’s laws, AIMC hardware achieves 10×-10,000× energy
efficiency than GPU [13–15] in model inference.
Despite its high efficiency,analog trainingis considerably more challenging thaninferencesince
it involves frequent weight updates. Unlike digital hardware, where the weight increment can be
applied to the original weight in the memory cell, the weights in AIMC hardware are changed by the
so-calledpulse update.Pulse update.When receiving electrical pulses from its peripheral circuits,
the resistive elements change their conductance in response to the pulse polarity [16]. Receiving a
pulse at each pulse cycle, the conductance is updated by a small amount around ∆wmin, which is
calledresponse granularity. ∆wmin is scaled by aresponse functions q+(w) or q−(w) depending on
its polarity. Geometrically, q+(w) and q−(w) are the slopes ofresponse curves; see Figure 1. All
∆wmin, q+(w), and q−(w) are element-specific parameters or functions that are set before training
and hence remain fixed during training. Typically,∆wmin is known while q+(w) and q−(w) are not.
Gradient-based training implemented by analog update.Supported by pulse update, the gradient-
based training algorithms are used to optimize the weights. Consider a standard training problem
with objectivef(·) :R D →Rand a model parameterized byW∈R D
W ∗ := arg min
W∈R D
f(W) :=E ξ[f(W;ξ)](1)
where ξ is a random data sample. Similar to stochastic gradient descent (SGD) in digital training
(Digital SGD), the gradient-based training algorithm on AIMC hardware, Analog SGD, updates
the weights by stochastic gradients ∇f(W k;ξ k). Digital SGD updates the weight by Wk+1 =
Wk −α∇f(W k;ξ k) with learning rate α. Given adesired update ∆W=−α∇f(W k;ξ k), AIMC
hardware implements Analog SGD by sending about |[∆W] i|/∆wmin pulses to the i-th element.
With each pulse updating[W k]i by∆w min,[W k]i is ultimately updated by about[∆W] i.
Challenges of analog training.Despite its ultra-efficiency, gradient-based training on AIMC
hardware is challenging. First, the generic response functions areasymmetric(i.e. q+(w)̸≡q −(w)),
andnon-linear[ 17–19]. Due to the variation of response functions and conductance states, gradients
are scaled by different magnitudes (i.e., qs([Wk]i) for s=± ) across different coordinates, leading to
biased gradients. Furthermore, the response granularity ∆wmin is a constant. When the gradients or
the learning rate decay below ∆wmin, pulse update no longer provides sufficient precision to perform
gradient descent [20]. Other imperfections include, but are not limited to, input/output (IO) of MVM
operations and analog-digital conversion error [ 18]. This paper aims to investigate the impact of
non-ideal response functions and develop a method to mitigate their negative effects. We also discuss
extending the proposed method to deal with other hardware imperfections.
1.1 Main results
Complementing existing empirical studies in analog in-memory computing, this paper aims to build a
rigorous theoretical foundation of analog training. By introducing bias to the gradient, the asymmetric
response function plays a central role in differentiating digital and analog training. In contrast,
the other non-idealities hinder the training process by causing precision-related issues. Therefore,
2

we approach the problem progressively, beginning with a simplified case that involves only the
asymmetric response functions, and extending the proposed methods to more general scenarios.
As a warm-up, building upon the pulse update mechanism, we propose the following discrete-time
mathematical model to characterize the trajectory ofAnalog SGD
Analog SGDW k+1 =W k −α∇f(W k;ξ k)⊙F(W k)−α|∇f(W k;ξ k)| ⊙G(W k)(2)
where α >0 is the learning rate and ξk is the data sample of iteration k; | · | and ⊙ represent the
element-wise absolute value and multiplication, respectively; andF(·) and G(·) are hardware-specific
matrix which are defined by q+(·) and q−(·). In Section 2, we will explain the underlying rationale of
(2). Compared with the standard Digital SGD, the gradients in (2) are scaled by F(·) and an extra
bias term is introduced. Typically, hardware imperfections lead to non-ideal response functions, i.e.,
F(·)̸≡1andG(·)̸≡0. Thus, we ask a natural question that
Q1)What is the impact of non-ideal response functions and how to alleviate it?
Recently, [21] partially answers the question by showing Analog SGD suffers from a convergence
issue due to the asymmetric update, and a heuristic algorithm,Tiki-Taka [22–24], converges exactly
by reducing the weight drift. However, their work is limited to a special case oflinear response,
which are in the form of q+(w) = 1−w/τ, q −(w) = 1 +w/τ with hardware-specific parameter
τ >0 . Given more general q+(w) and q−(w), the convergence of Tiki-Taka does not trivially
holds, even though the response functions are still linear.
0 200 400 600 800 1000
Number of Gradient Computation (k)
10 5
10 4
10 3
10 2
10 1
100
f(Wk)
 cLin = 0.0
cLin = 0.1
cLin = 0.2
cLin = 0.3
Tiki-T aka
Analog SGD
Figure 2: Comparison of Analog SGD and
Tiki-Taka under different parameter cLin. The
error plateau in the order 10−5 comes from the
limited response granularity∆w min = 10−4.
Gap between theory for special linear and
generic response.Consider a more generic lin-
ear response setting q+(w) = (1 +c Lin)(1−
w/τ), q −(w) = (1−c Lin)(1 +w/τ) with a
parameter cLin, which reduces to the setting in
[21] when cLin = 0. Figure 2 shows the damage
from a non-zero cLin to Tiki-Taka. Consistent
with the conclusion in [21], Tiki-Taka signifi-
cantly outperforms Analog SGD when cLin = 0.
However, whencLin is perturbed from0.1 to 0.3,
Tiki-Taka degrades dramatically and even be-
comes worse than Analog SGD does. The mod-
ification is slight, but the convergence guarantee
in [21] fails, and the convergence ofTiki-Taka
is harmed significantly. This counter-example indicates a gap between the theory with special linear
response and generic response, and necessitates the study of the analog training with generic response
functions and the exploration of exact convergence conditions.
Ignoring other imperfections temporarily, we first analyze the impact of response functions. We
show that Analog SGD suffers from asymptotic error due to the mismatch between the algorithmic
stationary pointand physicalsymmetric point. Inspired by that, we propose a novel algorithm
framework that aligns two points, overcoming the asymmetric issues. Building on that, we endeavor
to extend the proposed algorithm to more practical scenarios that involve other imperfections like
limited granularity and noisy readings, prompting a second critical question:
Q2)How to extend the framework to address the limited response granularity and noisy IO issues?
To answer this question, we propose two mechanisms to further overcome these two issues.
Our contributions.This paper makes the following contributions:
C1) Building upon the equation of pulse update, we propose an approximated discrete-time
dynamics of analog update. Enabled by it, we study the impact of response functions directly
without being limited to concrete element candidates.
C2) Based on that, we show that instead of optimizing f(·), Analog SGD optimizes another
penalized objective implicitly. An implicit penalty is introduced by the asymmetric response
functions and attracts the weights towards symmetric points. Consequently, Analog SGD
can only converge to the optimal point inexactly.
C3) We propose a novel Residual Learning algorithm framework to alleviate the asymmetric
update and implicit penalty issues. Residual Learning explicitly introduces another
3

residual array, which has a stationary point0. By properly zero-shifting so that the stationary
and symmetric points overlap,Residual Learningprovably converges to a critical point.
C4) Building on C3), we propose a variant, Residual Learning v2 , tailored for more practical
training scenarios. We propose introducing a digital buffer to filter out the reading error due
to the IO noise. Furthermore, we propose a threshold-based transfer rule to alleviate the
instability due to the limited granularity.
1.2 Prior art
AIMC training.Analog training has shown promising early successes with tremendous energy
advantage [25, 26]. Among them, on-chip training, which performs forward, backward, and update
directly on analog chips [ 22–24, 27, 28] is considered to be the most efficient paradigm, but it
is more sensitive to hardware imperfections. Sacrificing energy efficiency for robustness, hybrid
digital-analog off-chip training is proposed [ 29–32], which offloads some computation burden to
digital components. This paper focuses on the more challenging on-chip training setting.
Energy-based model and equilibrium propagation.AIMC training leverages back-propagation
to compute the gradient signals. Recently, a class of energy-based models has been studied, which
performs equilibrium propagation to compute gradient signals [ 33–37]. Focusing on the training
dynamics instead of concrete gradient computing, our work is orthogonal to them and is expected to
provide insight for algorithm designs of energy-based model training.
2 Analog Training with Generic Response Functions
This section examines the discrete-time dynamics of analog training and introduces the challenges
posed by generic response functions. After that, we introduce a family of response functions that
reflect crucial physical properties that interest us.
Compact formulations of analog update.We first investigate the dynamics of one element w in
W∈R D. This paper adopts w to represent the element of the weight Wk without specifying its
index. The notation makes the formulations more concise and indicates that all elements are updated
in parallel. As we discuss in Section 1, the response granularity ∆wmin is scaled by the response
function qs(w). Naturally, given a desired update ∆w, the increment is approximately scaled by
qs(w) as well. Accordingly, we propose that an approximate dynamics of analog update is given by
w′ ≈U q(w,∆w), whereU q(w,∆w)is defined by
Uq(w,∆w) :=
w+ ∆w·q +(w),∆w≥0,
w+ ∆w·q −(w),∆w <0. (3)
The update (3) holds at each resistive element, while the model W contains D resistive elements
with different response functions q+(·) and q−(·). We stack all the weights wk and expected
increment ∆wk together into vectors Wk,∆W k ∈R D, where k is the iteration index Similarly, the
response functions q+(·) and q−(·) are stacked into Q+(·) and Q−(·), respectively. Let the notation
UQ(Wk,∆W) on matrices Wk and ∆W denote the element-wise operation on Wk and ∆W , i.e.
[UQ(Wk,∆W)] i :=U [Q]i([Wk]i,[∆w] i),∀i∈[D] with [D] :={1,2,· · ·, D} denoting the index
set. The element-wise update (3) can be expressed as Wk+1 =U Q(Wk,∆W k). Leveraging the
symmetric decomposition [22, 21], we decompose Q−(W) and Q+(W) into symmetric component
F(·)and asymmetric componentG(·)
F(W) := (Q −(W) +Q +(W))/2,andG(W) := (Q −(W)−Q +(W))/2,(4)
which leads to a compact form of theAnalog Update
Analog UpdateW k+1 =W k + ∆Wk ⊙F(W k)− |∆W k| ⊙G(W k).(5)
Gradient-based training algorithms on AIMC hardware.In (5), the desired update ∆Wk varies
based on different algorithms. Replacing ∆Wk with the stochastic gradient ∇f(W k;ξ k), we obtain
the dynamics of Analog SGD shown in (2). This update is reduced to the mathematical form for
linear response functions in [21] as a special case; see Appendix B for details.Response function
class.Before proceeding to the study of response functions, we first define the response function
4

Response func. Response func.
 Response func.
Figure 3: Examples of response functions from Definition 1;w ⋄ is the symmetric point.
class that interests us. Since the behavior of resistive elements is always governed by physical laws,
the function class should reflect certain crucial physical properties.
We first introduce a commonly observedsaturationproperty across a wide range of resistive elements.
Resistive elements getsaturatedwhen they keep receiving the same pulses to avoid reaching arbitrarily
high or low conductance states. Constrained by that, the conductance of the resistive element with
q+(·) and q−(·) is bounded inside adynamic range [τ min, τmax] where τ min and τ max are the
saturation points with zero responses, i.e. q+(τ max) =q −(τ min) = 0. Near the saturation points,
the asymmetric issue is significant, and thus, the update in one direction is suppressed, considerably
impacting the convergence. On the contrary, if a point w⋄ satisfies q−(w⋄) =q +(w⋄), the analog
update behaves like a digital update. We refer to w⋄ assymmetric point. Symmetric points are
typically located in the interior of the dynamic range and are far from saturation.
Stacking all w⋄ into a vector W ⋄ ∈R D. Observe that the function G(W) is large near the saturation
points while almost zero around W ⋄, implying it can reflect the saturation degree. At the same time,
F(W) is the average of the response functions in two directions. As we will see in Sections 3.2 and
4, the ratio G(W)√
F(W)
plays a critical role in the convergence behaviors.
Besides saturation, the function class should also enjoy other properties. First, the conductance ends
up increasing when receiving a positive pulse and vice versa, leading to positive response functions.
On top of that, we also assume the response functions are differentiable (and hence continuous) for
mathematical tractability. Taking all into account, we define the following response function class.
Definition 1(Response function class).q +(·)andq −(·)with dynamic range[τ min, τmax]satisfy
•(Positive-definiteness)q +(w)>0,∀w < τ max andq −(w)>0,∀w > τ min;
•(Differentiable)q +(·)andq −(·)are differentiable;
•(Saturation)q +(τ max) =q −(τ min) = 0.
Definition 1 covers a wide range of response functions, including but not limited to PCM, ReRAM,
ECRAM, and others mention in Section A. Figure 3 showcases three examples from the response
functions class, including linear, non-linear but monotonic, and even non-monotonic functions.
3 Implicit Penalty and Inexact Convergence ofAnalog SGD
This section introduces a critical impact of the response functions,implicit penalized objective.
Affected by itAnalog SGDcan only converge inexactly with a non-diminishing asymptotic error.
3.1 Implicit penalty
We first give an intuition through a situation where Wk is already a critical point, i.e.,
Eξ[∇f(W k;ξ)] = 0 . Recall that stochastic gradient descent on digital hardware (Digital SGD) is
stable in expectation, i.e. Eξk[Wk+1] =W k −E ξk[α∇f(W k;ξ k)] =W k. However, this does not
work forAnalog SGD
Eξk[Wk+1] =W k −E ξk[α∇f(W k;ξ k)⊙F(W k)−α|∇f(W k;ξ k)| ⊙G(W k)](6)
=W k −αE ξk[|∇f(W k;ξ k)| ⊙G(W k)]̸=W k.
Consider a simplified version that the weight is a scalar (D= 1 ) and the function G(W) is strictly
monotonically decreasing2 to help us gain intuition on the impact of the drift in(6). Recall G(W ⋄) =
2It happens when bothq +(·)andq −(·)are strictly monotonic.
5

0 at the symmetric point W ⋄. G(W)>0 when W > W ⋄ and G(W)<0 otherwise. Consequently,
(6) indicates that Eξk[Wk+1]< W k when Wk > W ⋄ and Eξk[Wk+1]> W k otherwise. It implies
that Wk suffers from a drift tendency towards W ⋄. In addition, the penalty coefficient proportional
to the noise level since the drift is proportional to Eξk[|∇f(W k;ξ k)|], which is the first moment of
noiseE ξk[|∇f(W k;ξ k)−E ξ[∇f(W k;ξ)]|]in essence.
The following theorem formalizes the implicit penalty effect. Before that, we define an accumulated
asymmetric function Rc(·) :R D →R D, whose derivative is R(W) := G(W)
F(W) , i.e. d[Rc(W)] d
d[W] d
=
[R(W)] d = [G(W)] d
[F(W)] d
. If R(W) is strictly monotonic, Rc(W) reaches its minimum at the symmetric
pointW ⋄ whereR(W ⋄) = 0, so that it penalizes the weight away from the symmetric point.
Theorem 1(Implicit penalty, short version).Suppose Eξk[|∇f(W k;ξ k)−E ξ[∇f(W k;ξ)]|] is a
constant Σ∈R D and let D= 1 . Analog SGD implicitly optimizes the following penalized objective
min
W
fΣ(W) :=f(W) +⟨Σ, R c(W)⟩.(7)
The full version of Theorem 1 and its proof are deferred to Appendix G. In Theorem 1, Rc(W)
plays the role of a penalty to force the weight toward a symmetric point. As shown in Appendix
G, Rc(W) has a simple expression on linear response functions when cLin = 0 , leading (7) to
minW fΣ(W) :=f(W) + Σ
2τ ∥W∥ 2 which is an ℓ2 regularized objective. In addition, the implicit
penalty has a coefficient proportional to the noise levelΣ and inversely proportional to the dynamic
range τ. It implies that the implicit penalty becomes active only when gradients are noisy, and the
noise amplifies the effect.
With noisy gradients, animplicit penaltyattractsAnalog SGDtowards symmetric points.
3.2 Inexact Convergence ofAnalog SGDunder generic devices
Due to the implicit penalty, Analog SGD only converges to a critical point inexactly. Before showing
that, We introduce a series of assumptions on the objective, as well as noise.
Assumption 1(Objective).The objectivef(W)isL-smooth and is lower bounded byf ∗.
Assumption 2(Unbiasness and bounded variance).The stochastic gradient is unbiased and has
bounded varianceσ 2.
Assumption 1–2 are standard in non-convex optimization [38, 21]. Additionally, similar to the setting
in [21], we also assume that the saturation degree is bounded, i.e., all response functions are positive.
Assumption 3(Bounded saturation).There exists a constant Rmin >0 such that min{Q+(W)⊙
Q−(W)}> R min.
Assumption 3 requires that Wk remains far from saturation points, which is a mild assumption in
actual training. This paper considers the average gradient square norm as the convergence metric,
given byE K := 1
K
PK−1
k=0 ∥∇f(W k)∥2. Now, we establish the convergence ofAnalog SGD.
Theorem 2(Inexact convergence of Analog SGD).Under Assumption 1–3, if the learning rate is set
asα=O(1/
√
K), it holds that
EK ≤O
p
σ2/K+σ 2SASGD
K

(8)
whereS ASGD
K denotes the amplification factor given byS ASGD
K := 1
K
PK−1
k=0

G(Wk)√
F(W k)

2
∞
.
The proof of Theorem 2 is deferred to Appendix H. Theorem 2 suggests that the convergence
metric EK is upper bounded by two terms: the first term vanishes at a rate of O(
p
σ2/K), which
matches the Digital SGD’s convergence rate [38] up to a constant; the second term contributes to
theasymptotic errorofAnalog SGD, which does not vanish with the number of iterationsK.
Impact of saturation/asymmetric update.The exact expression of SASGD
K depends on the specific
noise distribution and thus is difficult to reach. However, SASGD
K reflects the saturation degree near the
critical point W ∗ when Wk converges to a neighborhood of W ∗. If W ∗ is far from the symmetric
point W ⋄, SASGD
K becomes large, leading to a large EASGD
K and a large asymptotic error. In contrast, if
W ∗ remains close to the symmetric pointW ⋄, the asymptotic error is small.
6

4 Mitigating Implicit Penalty by Residual Learning
The asymptotic error in Analog SGD is a fundamental issue that arises from the mismatch between the
symmetric point and the critical point. An idealistic remedy for the inexact convergence is carefully
shifting the weights to ensure the stationary point is close to a symmetric point. However, determining
the appropriate adjustment is always challenging, as the critical point is difficult to pinpoint before
the actual training. Therefore, an ideal solution to address this issue is to jointly construct a sequence
with a predictable stationary point and a proper shift of the symmetric point.
Residual learning.Our solution overlaps the algorithmic stationary point and physical symmetric
point on the special point 0. Besides the main analog array, Wk, we maintain another array, Pk,
whose stationary point should be 0. A natural choice is theresidualof the weight, P ∗(W) , defined by
the P that minimizes the objective f(W+γP) with a non-zero γ. Additionally, the goal of the main
array is to minimize the residual so that the model Wk is approaching optimal. This process can be
formulated as the following bilevel problem whose optimal points can be proved to be that of f(W)
Residual Learningarg min
W∈R D
∥P ∗(W)∥ 2,s.t. P ∗(W)∈arg min
P∈R D
f(W+γP).(9)
Now we propose a gradient-based method to solve (9). The gradient of f(W+γP) with respect
to P , given by ∇P f(W+γP) =γ∇f(W+γP) , is accessible with fair expense, enabling us to
introduce a sequenceP k to track the residual ofW k by optimizingf(W k +γP)
Pk+1 =P k −α∇f( ¯Wk;ξ k)⊙F(P k)−α|∇f( ¯Wk;ξ k)| ⊙G(P k).(10)
where ¯Wk :=W k +γP k is the mixed weight. We then derive the hyper-gradient of the upper-level
objective. Notice ∇∥P ∗(W)∥ 2 = 2∇P ∗(W)P ∗(W) . Assuming W ∗ is the unique minimum of
f(·), we know P ∗(W) satisfies P ∗(W) +W=W ∗. Taking gradient with respective to W on both
sides, we have ∇P ∗(W) =−I and hence ∇∥P ∗(W)∥ 2 =−2P ∗(W) . Approximating P ∗(W) by
Pk, we reach the update of the main array.
Wk+1 =W k +βP k+1 ⊙F(W k)−β|P k+1| ⊙G(W k).(11)
Featuring moving the residual Pk to Wk, (11) is referred to astransferprocess. The updates (10) and
(11) are performed alternatively until convergence. It is noticeable that Residual Learning has
the same recursion format as Tiki-Taka. However, as we will discuss in Section 5, the proposed
method can be naturally extended, and simulations in Section 6 show that the extension of Residual
Learningoutperforms the extension ofTiki-Taka.
On the response functions side, it is naturally required to let zero be a symmetric point, i.e.,G(0) = 0,
which can be implemented by the zero-shifting technique [39] by subtracting a reference array.
Convergence properties of Residual Learning.We begin by analyzing the convergence of
Residual Learningwithout considering the zero-shift first, which enables us to understand how
zero-shifted response functions affect convergence.
If the optimal point W ∗ exists and is unique, the solution of the lower-level objective has a closed
form P ∗(W) := W ∗−W
γ . At that time, the upper-level objective equals ∥W ∗ −W∥ 2. However, the
solutions of f(·) are non-unique in general, especially for non-convex objectives with multiple local
minima. To ensure the existence and uniqueness of W ∗, we assume the objective is strongly convex.
Assumption 4(µ-strong convexity).The objectivef(W)isµ-strongly convex.
Under the strongly convex assumption, the optimal point W ∗ is unique. Although the requirement of
strong convexity is non-essential by the development of bilevel optimization [40–43], and the proof
can be extended to more general cases, we leave it for future work.
Involving two sequences Wk and Pk, Residual Learning converges in different senses, including:
(a) the residual array Pk converges to the optimal point P ∗(Wk); (b) Wk converges to the critical
point of f(·) or the optimal point W ∗; (c) the sum ¯Wk =W k +γP k converges to a critical point
where∇f( ¯Wk) = 0. Taking all these into account, we define the convergence metric as
ERL
K := 1
K
K−1X
k=0
E

∥∇f( ¯Wk)∥2 +O(∥P k −P ∗(Wk)∥2) +O(∥W k −W ∗∥2)

.(12)
7

0 5 10 15 20 25 30
Epoch
20
40
60
80
100T est Accuracy
= 0.5
= 0.6
= 0.7
Analog SGD
Tiki-T aka
Digital SGD28 30
95
96
97
0 5 10 15 20 25 30
Epoch
20
40
60
80
100T est Accuracy
= 0.6
= 0.7
= 0.8
Analog SGD
Tiki-T aka
Digital SGD
28 30
98
99
Figure 4: Test accuracy of training on MNIST dataset under different τ;(Left)FCN.(Right)CNN.
For simplicity, the constants in front of some terms in ERL
K are hidden. Now, we provide the
convergence ofResidual Learningwith generic responses.
Theorem 3(Convergence of Residual Learning).Under Assumptions 1–3 and 4, with the learning
rateα=O
p
1/σ2K

,β=O(αγ 3/2), it holds forResidual Learningthat
ERL
K ≤O
p
σ2/K+σ 2SRL
K

(13)
whereS RL
K denotes the amplification factor ofP k given byS RL
K := 1
K
PK
k=0

G(Pk)√
F(P k)

2
∞
.
The proof of Theorem 3 is deferred to Appendix I. Theorem 3 claims that Residual Learning
converges at the rate O
p
σ2/K

to a neighbor of critical point with radius O(σ2SRL
K ), which
share almost the same expression with the convergence of Analog SGD. The difference lies in the
amplification factor SRL
K and SASGD
K , where the former depends on Pk while the latter depends on Wk.
Impact of response functions.Response function affects the Analog SGD and Residual
Learning similarly. However, attributed to the residual array, constructing response functions to
enable exact convergence ofResidual Learningis viable.
As we have discussed, Pk tends to P ∗(Wk) which tends to 0 given Wk tends to W ∗. Therefore,
response functions withG(P) = 0whenP= 0are required for the exact convergence.
Assumption 5.(Zero-shifted symmetric point)P= 0is a symmetric point, i.e.G(0) = 0.
Under it and the Lipschitz continuity of the response functions, it holds directly that

G(Pk)√
F(P k)

∞
≤
LS∥Pk∥∞ for a constant LS ≥0 . Consequently, when Pk →P ∗(Wk)→0 as Wk →W ∗, the
asymptotic error disappears. Formally, the following corollary holds true.
Corollary 1(Exact convergence of Residual Learning).Under Assumption 5 and the conditions
in Theorem 3, ifγ≥Ω(R −1/5
min ), it holds thatE RL
K ≤O
p
σ2L/K

.
The proof of Corollary 1 is deferred to Appendix I.5. Corollary 1 demonstrates the failure of
Tiki-Taka in Figure 2. The symmetric point is w⋄ =c Linτ in this example, which violates
Assumption 5 whenc Lin ̸= 0and hence introduces asymptotic error intoResidual Learning.
5 Extension of Residual Learning: limited granularity and noisy IO
This section extends Residual Learning to more practical scenarios involving more hardware
imperfections. To be specific, we consider thenoisy IOandlimited granularityas examples. We
highlight that we are not trying to diminish the importance of imperfection, but we focus on two of
the primary ones that are known to be crucial.
Noisy IO introduces noise during the reading of Pk+1 in the transfer process (11), given by Wk+1 =
Wk +β(P k+1 +ε k)⊙F(W k)−β|P k+1 +ε k| ⊙G(Wk) with a noise εk. It incurs the implicit penalty
issues again, leading to a penalized upper-level objective ∥P ∗(W)∥ 2 + Σε∥W∥ 2/2, as claimed by
Theorem 1, where Σε is the standard variation of εk. To filter out the noise, we propose to use a
digital bufferH k to take a moving average of noisyP k+1 signals by
Hk+1 = (1−β)H k +β(P k+1 +ε k+1)(14)
8

Intuitively, with a fixed Pk+1, Hk will converge to a neighborhood of Pk+1 with radius O(β).
Therefore, a sufficiently smallβ renders Hk a fair approximation of noiselessPk, enabling optimizing
the upper-level objective with clearer signals. After that,H k+1 is transferred toW k as follows
Wk+1 =W k +βH k+1 ⊙F(W k)−β|H k+1| ⊙G(W k).(15)
Furthermore, the optimization process suffers from a constant error in the order of O(∆wmin) as the
pulses are fired discretely, with each changing the weight by O(∆wmin). To overcome these issues,
we propose introducing a threshold mechanism to train in limited precision. Instead of transferring
Hk+1 to Wk at each iteration, the transfer is triggered only if an element in Hk+1 is greater than the
response granularity∆w min. The proposed algorithms are referred to asResidual Learningv2.
CIFAR10
DSGD ASGD TT/RL TTv2 RLv2
ResNet18 95.43±0.13 84.47±3.40 94.81±0.09 95.31±0.05 95.12±0.14
ResNet34 96.48±0.02 95.43±0.12 96.29±0.12 96.60±0.05 96.42±0.13
ResNet50 96.57±0.10 94.36±1.16 96.34±0.04 96.63±0.09 96.56±0.08
CIFAR100
DSGD ASGD TT/RL TTv2 RLv2
ResNet18 81.12±0.25 68.98±1.01 76.17±0.23 78.56±0.29 79.83±0.13
ResNet34 83.86±0.12 78.98±0.55 80.58±0.11 81.81±0.15 82.85±0.19
ResNet50 83.98±0.11 79.88±1.26 80.80±0.22 82.82±0.33 83.90±0.20
Table 1: Fine-tuning ResNet models with thepower responseon CIFAR10/100. Test accuracy is
reported. DSGD, ASGD, TT/RL, TTv2, and RLv2 represent Digital SGD, Analog SGD, Residual
Learning/Tiki-Taka, andResidual Learning v2, respectively.
6 Numerical Simulations
In this section, we verify the main theoretical results by simulations on both synthetic datasets and real
datasets. We use the open source toolkit IBM Analog Hardware Acceleration Kit (AIHWKIT ) [44] to
simulate the behaviors ofAnalog SGD,Residual Learning(which reduces toTiki-Taka). Each
simulation is repeated three times, and the mean and standard deviation are reported. We consider
two types of response functions in our simulations: power and exponential response functions with
dynamic ranges [−τ, τ] , while the symmetric point is 0, as required by Corollary 1. More details,
simulations, and ablation studies can be found in Appendix K.
MNIST FCN/CNN.We train a fully-connected network (FCN) and a convolutional neural network
(CNN) on the MNIST dataset and compare the performance of Analog SGD and Tiki-Taka under
various τ on power responses; see the results in Figure 4. By tracking residual, Tiki-Taka outper-
forms Analog SGD and reaches comparable accuracy with Digital SGD. For both architectures, the
accuracy of Tiki-Taka drops by <1% . In contrast, Analog SGD takes a few epochs to achieve an
observable accuracy increment in FCN training, rendering a slower convergence rate thanTiki-Taka.
In CNN training, Analog SGD’s accuracy increases more slowly thanTiki-Taka does and finally
gets stuck at about 80%. It is consistent with the theoretical claims.
CIFAR10/CIFAR100 ResNet.We fine-tune three ResNet models with different scales on CI-
FAR10/CIFAR100 datasets. The power response functions are used, whose results are shown in Table
1. The results show that the Tiki-Taka outperforms Analog SGD by about 1.0% in most of the
cases in ResNet34/50, and the gap even reaches about 7.0% for ResNet18 training on the CIFAR100
dataset. On top of that, we also compare the proposed Residual Learning v2 and Tiki-Taka v2.
Both of them outperform Residual Learning since they introduce a digital buffer to filter out the
reading noise. However, Residual Learning v2 outperforms Tiki-Taka v2 on the CIFAR100
dataset, demonstrating the benefit from the bilevel formulation.
9

7 Conclusions and Limitations
This paper studies the impact of a generic class of asymmetric and non-linear response functions on
gradient-based training in analog in-memory computing hardware. We first formulate the dynamic of
Analog Update based on the pulse update rule. Based on it, we show that Analog SGD implicitly
optimizes a penalized objective and hence can only converge inexactly. To overcome this issue, we
propose a Residual Learning framework which solves a bilevel optimization problem. Explicitly
aligning the algorithmic stationary point and physical symmetric point, Residual Learning prov-
ably converges to the optimal point exactly. Furthermore, we demonstrate how to extend Residual
Learning to overcome the noisy reading and limited update granularity issues. The efficiency of
the proposed method is verified through simulations. One limitation of this work is that the current
analysis considers only the three hardware imperfections. While they are known to be crucial for
analog training, it is also important to extend our convergence analysis and methods to more practical
scenarios involving more imperfections in future work.
References
[1] Norm Jouppi, George Kurian, Sheng Li, Peter Ma, Rahul Nagarajan, Lifeng Nai, Nishant
Patil, Suvinay Subramanian, Andy Swing, Brian Towles, et al. TPU v4: An optically reconfig-
urable supercomputer for machine learning with hardware support for embeddings. InAnnual
International Symposium on Computer Architecture, pages 1–14, 2023.
[2] Hadi Esmaeilzadeh, Adrian Sampson, Luis Ceze, and Doug Burger. Neural acceleration for
general-purpose approximate programs. InIEEE/ACM international symposium on microarchi-
tecture, pages 449–460. IEEE, 2012.
[3] Dharmendra S Modha, Filipp Akopyan, Alexander Andreopoulos, Rathinakumar Appuswamy,
John V Arthur, Andrew S Cassidy, Pallab Datta, Michael V DeBole, Steven K Esser, Car-
los Ortega Otero, et al. Neural inference at the frontier of energy, space, and time.Science,
382(6668):329–335, 2023.
[4] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timo-
thée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open
and efficient foundation language models.arXiv preprint arXiv:2302.13971, 2023.
[5] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are
few-shot learners.Advances in neural information processing systems, 33:1877–1901, 2020.
[6] An Chen. A comprehensive crossbar array model with solutions for line resistance and nonlinear
device characteristics.IEEE Transactions on Electron Devices, 60(4):1318–1326, 2013.
[7] Wilfried Haensch, Tayfun Gokmen, and Ruchir Puri. The next generation of deep learning
hardware: Analog computing.Proceedings of the IEEE, 107(1):108–122, 2019.
[8] Vivienne Sze, Yu-Hsin Chen, Tien-Ju Yang, and Joel S Emer. Efficient processing of deep
neural networks: A tutorial and survey.Proceedings of the IEEE, 105(12):2295–2329, 2017.
[9] Abu Sebastian, Manuel Le Gallo, Riduan Khaddam-Aljameh, and Evangelos Eleftheriou.
Memory devices and applications for in-memory computing.Nature Nanotechnology, 15:529–
544, 2020.
[10] Manuel Le Gallo, Riduan Khaddam-Aljameh, Milos Stanisavljevic, Athanasios Vasilopoulos,
Benedikt Kersting, Martino Dazzi, Geethan Karunaratne, Matthias Brändli, Abhairaj Singh,
Silvia M Mueller, et al. A 64-core mixed-signal in-memory compute chip based on phase-change
memory for deep neural network inference.Nature Electronics, 6(9):680–693, 2023.
[11] Geoffrey W Burr, Robert M Shelby, Abu Sebastian, Sangbum Kim, Seyoung Kim, Severin Sidler,
Kumar Virwani, Masatoshi Ishii, Pritish Narayanan, Alessandro Fumarola, et al. Neuromorphic
computing using non-volatile memory.Advances in Physics: X, 2(1):89–124, 2017.
[12] J Joshua Yang, Dmitri B Strukov, and Duncan R Stewart. Memristive devices for computing.
Nature nanotechnology, 8(1):13, 2013.
10

[13] Shubham Jain et al. Neural network accelerator design with resistive crossbars: Opportunities
and challenges.IBM Journal of Research and Development, 63(6):10–1, 2019.
[14] Stefan Cosemans, Bram-Ernst Verhoef, Jonas Doevenspeck, Ioannis A. Papistas, Francky
Catthoor, Peter Debacker, Arindam Mallik, and Diederik Verkest. Towards 10000TOPS/W
DNN inference with analog in-memory computing – a circuit blueprint, device options and
requirements. InIEEE International Electron Devices Meeting, pages 22.2.1–22.2.4, 2019.
[15] Ioannis A Papistas, Stefan Cosemans, Bram Rooseleer, Jonas Doevenspeck, M-H Na, Arindam
Mallik, Peter Debacker, and Diederik Verkest. A 22 nm, 1540 TOP/s/W, 12.1 TOP/s/mm 2
in-memory analog matrix-vector-multiplier for DNN acceleration. InIEEE Custom Integrated
Circuits Conference, pages 1–2. IEEE, 2021.
[16] Tayfun Gokmen and Yurii Vlasov. Acceleration of deep neural network training with resistive
cross-point devices: Design considerations.Frontiers in neuroscience, 10:333, 2016.
[17] Geoffrey W Burr, Robert M Shelby, Severin Sidler, Carmelo Di Nolfo, Junwoo Jang, Irem
Boybat, Rohit S Shenoy, Pritish Narayanan, Kumar Virwani, Emanuele U Giacometti, et al.
Experimental demonstration and tolerancing of a large-scale neural network (165 000 synapses)
using phase-change memory as the synaptic weight element.IEEE Transactions on Electron
Devices, 62(11):3498–3507, 2015.
[18] Sapan Agarwal, Steven J Plimpton, David R Hughart, Alexander H Hsia, Isaac Richter,
Jonathan A Cox, Conrad D James, and Matthew J Marinella. Resistive memory device require-
ments for a neural algorithm accelerator. InInternational Joint Conference on Neural Networks,
pages 929–938. IEEE, 2016.
[19] Paiyu Chen, Binbin Lin, I-Ting Wang, Tuohung Hou, Jieping Ye, Sarma Vrudhula, Jae-sun Seo,
Yu Cao, and Shimeng Yu. Mitigating effects of non-ideal synaptic device characteristics for
on-chip learning. InIEEE/ACM International Conference on Computer-Aided Design, pages
194–199. IEEE, 2015.
[20] Vinay Joshi, Manuel Le Gallo, Simon Haefeli, Irem Boybat, Sasidharan Rajalekshmi Nan-
dakumar, Christophe Piveteau, Martino Dazzi, Bipin Rajendran, Abu Sebastian, and Evangelos
Eleftheriou. Accurate deep neural network inference using computational phase-change memory.
Nature communications, 11(1):2473, 2020.
[21] Zhaoxian Wu, Tayfun Gokmen, Malte J Rasch, and Tianyi Chen. Towards exact gradient-based
training on analog in-memory computing. InAdvances in Neural Information Processing
Systems, 2024.
[22] Tayfun Gokmen and Wilfried Haensch. Algorithm for training neural networks on resistive
device arrays.Frontiers in Neuroscience, 14, 2020.
[23] Tayfun Gokmen. Enabling training of neural networks on noisy hardware.Frontiers in Artificial
Intelligence, 4:1–14, 2021.
[24] Malte J Rasch, Fabio Carta, Omobayode Fagbohungbe, and Tayfun Gokmen. Fast and robust
analog in-memory deep neural network training.Nature Communications, 15(1):7133–7147,
2024.
[25] Peng Yao, Huaqiang Wu, Bin Gao, Sukru Burc Eryilmaz, Xueyao Huang, Wenqiang Zhang,
Qingtian Zhang, Ning Deng, Luping Shi, H-S Philip Wong, et al. Face classification using
electronic synapses.Nature communications, 8(1):15199, 2017.
[26] Zhongrui Wang, Can Li, Peng Lin, Mingyi Rao, Yongyang Nie, Wenhao Song, Qinru Qiu,
Yunning Li, Peng Yan, John Paul Strachan, et al. In situ training of feed-forward and recurrent
convolutional memristor networks.Nature Machine Intelligence, 1(9):434–442, 2019.
[27] Yaoyuan Wang, Shuang Wu, Lei Tian, and Luping Shi. SSM: a high-performance scheme for
in situ training of imprecise memristor neural networks.Neurocomputing, 407:270–280, 2020.
11

[28] Shanshi Huang, Xiaoyu Sun, Xiaochen Peng, Hongwu Jiang, and Shimeng Yu. Overcoming
challenges for achieving high in-situ training accuracy with emerging memories. InDesign,
Automation & Test in Europe Conference & Exhibition, pages 1025–1030. IEEE, 2020.
[29] Weier Wan, Rajkumar Kubendran, Clemens Schaefer, Sukru Burc Eryilmaz, Wenqiang Zhang,
Dabin Wu, Stephen Deiss, Priyanka Raina, He Qian, Bin Gao, et al. A compute-in-memory
chip based on resistive random-access memory.Nature, 608(7923):504–512, 2022.
[30] Peng Yao, Huaqiang Wu, Bin Gao, Jianshi Tang, Qingtian Zhang, Wenqiang Zhang, J Joshua
Yang, and He Qian. Fully hardware-implemented memristor convolutional neural network.
Nature, 577(7792):641–646, 2020.
[31] S. R. Nandakumar, Manuel Le Gallo, Irem Boybat, Bipin Rajendran, Abu Sebastian, and
Evangelos Eleftheriou. Mixed-precision architecture based on computational memory for
training deep neural networks. InIEEE International Symposium on Circuits and Systems,
pages 1–5, 2018.
[32] S. R. Nandakumar, Manuel Le Gallo, Christophe Piveteau, Vinay Joshi, Giovanni Mariani, Irem
Boybat, Geethan Karunaratne, Riduan Khaddam-Aljameh, Urs Egger, Anastasios Petropoulos,
Theodore Antonakopoulos, Bipin Rajendran, Abu Sebastian, and Evangelos Eleftheriou. Mixed-
precision deep learning based on computational memory.Frontiers in Neuroscience, 14, 2020.
[33] Benjamin Scellier and Yoshua Bengio. Equilibrium propagation: Bridging the gap between
energy-based models and backpropagation.Frontiers in computational neuroscience, 11:24,
2017.
[34] Mohamed Watfa, Alberto Garcia-Ortiz, and Gilles Sassatelli. Energy-based analog neural
network framework.Frontiers in Computational Neuroscience, 17:1114651, 2023.
[35] Benjamin Scellier, Maxence Ernoult, Jack Kendall, and Suhas Kumar. Energy-based learning
algorithms for analog computing: a comparative study.Advances in Neural Information
Processing Systems, 36, 2024.
[36] Jack Kendall, Ross Pantone, Kalpana Manickavasagam, Yoshua Bengio, and Benjamin Scellier.
Training end-to-end analog neural networks with equilibrium propagation.arXiv preprint
arXiv:2006.01981, 2020.
[37] Maxence Ernoult, Julie Grollier, Damien Querlioz, Yoshua Bengio, and Benjamin Scellier.
Equilibrium propagation with continual weight updates.arXiv preprint arXiv:2005.04168,
2020.
[38] Léon Bottou, Frank E Curtis, and Jorge Nocedal. Optimization methods for large-scale machine
learning.SIAM review, 60(2):223–311, 2018.
[39] Hyungjun Kim, Malte J Rasch, Tayfun Gokmen, Takashi Ando, Hiroyuki Miyazoe, Jae-Joon
Kim, John Rozen, and Seyoung Kim. Zero-shifting technique for deep neural network training
on resistive cross-point arrays.arXiv preprint arXiv:1907.10228, 2019.
[40] Quan Xiao, Songtao Lu, and Tianyi Chen. A generalized alternating method for bilevel learning
under the polyak-łojasiewicz condition. InProc. Advances in Neural Info. Process. Syst., 2023.
[41] Michael Arbel and Julien Mairal. Non-convex bilevel games with critical point selection maps.
InAdvances in Neural Information Processing Systems, 2022.
[42] Han Shen, Quan Xiao, and Tianyi Chen. On penalty-based bilevel gradient descent method. In
Proc. of International Conference on Machine Learning, 2023.
[43] Jeongyeol Kwon, Dohyun Kwon, Steve Wright, and Robert Nowak. On penalty methods for non-
convex bilevel optimization and first-order stochastic approximation. InProc. of International
Conference on Learning Representations, 2024.
[44] Malte J Rasch, Diego Moreda, Tayfun Gokmen, Manuel Le Gallo, Fabio Carta, Cindy Goldberg,
Kaoutar El Maghraoui, Abu Sebastian, and Vijay Narayanan. A flexible and fast PyTorch toolkit
for simulating training and inference on analog crossbar arrays.IEEE International Conference
on Artificial Intelligence Circuits and Systems, pages 1–4, 2021.
12

[45] Geoffrey W Burr, Matthew J BrightSky, Abu Sebastian, Huai-Yu Cheng, Jau-Yi Wu, Sangbum
Kim, Norma E Sosa, Nikolaos Papandreou, Hsiang-Lan Lung, Haralampos Pozidis, Evangelos
Eleftheriou, and Chung H Lam. Recent Progress in Phase-Change Memory Technology.IEEE
Journal on Emerging and Selected Topics in Circuits and Systems, 6(2):146–162, 2016.
[46] Manuel Le Gallo and Abu Sebastian. An overview of phase-change memory device physics.
Journal of Physics D: Applied Physics, 53(21):213002, 2020.
[47] Jun-Woo Jang, Sangsu Park, Yoon-Ha Jeong, and Hyunsang Hwang. ReRAM-based synaptic
device for neuromorphic computing. InIEEE International Symposium on Circuits and Systems,
pages 1054–1057, 2014.
[48] Jun-Woo Jang, Sangsu Park, Geoffrey W Burr, Hyunsang Hwang, and Yoon-Ha Jeong. Opti-
mization of conductance change in Pr1−xCaxMnO3-based synaptic devices for neuromorphic
systems.IEEE Electron Device Letters, 36(5):457–459, 2015.
[49] Tommaso Stecconi, Valeria Bragaglia, Malte J Rasch, Fabio Carta, Folkert Horst, Donato F
Falcone, Sofieke C Ten Kate, Nanbo Gong, Takashi Ando, Antonis Olziersky, et al. Analog
resistive switching devices for training deep neural networks with the novel Tiki-Taka algorithm.
Nano Letters, 24(3):866–872, 2024.
[50] Seokjae Lim, Myounghoon Kwak, and Hyunsang Hwang. Improved synaptic behavior of
CBRAM using internal voltage divider for neuromorphic systems.IEEE Transactions on
Electron Devices, 65(9):3976–3981, 2018.
[51] Elliot J Fuller, Scott T Keene, Armantas Melianas, Zhongrui Wang, Sapan Agarwal, Yiyang
Li, Yaakov Tuchman, Conrad D James, Matthew J Marinella, J Joshua Yang, Alberto Salleo,
and A Alec Talin. Parallel programming of an ionic floating-gate memory array for scalable
neuromorphic computing.Science, 364(6440):570–574, 2019.
[52] Jianshi Tang, Douglas Bishop, Seyoung Kim, Matt Copel, Tayfun Gokmen, Teodor Todorov,
SangHoon Shin, Ko-Tao Lee, Paul Solomon, Kevin Chan, et al. ECRAM as scalable synaptic
cell for high-speed, low-power neuromorphic computing. InIEEE International Electron
Devices Meeting, pages 13–1. IEEE, 2018.
[53] Murat Onen, Nicolas Emond, Baoming Wang, Difei Zhang, Frances M Ross, Ju Li, Bilge Yildiz,
and Jesús A Del Alamo. Nanosecond protonic programmable resistors for analog deep learning.
Science, 377(6605):539–543, 2022.
[54] Seungchul Jung, Hyungwoo Lee, Sungmeen Myung, Hyunsoo Kim, Seung Keun Yoon, Soon-
Wan Kwon, Yongmin Ju, Minje Kim, Wooseok Yi, Shinhee Han, et al. A crossbar array of
magnetoresistive memory devices for in-memory computing.Nature, 601(7892):211–216,
2022.
[55] Zhihua Xiao, Vinayak Bharat Naik, Jia Hao Lim, Yaoru Hou, Zhongrui Wang, and Qiming Shao.
Adapting magnetoresistive memory devices for accurate and on-chip-training-free in-memory
computing.Science Advances, 10(38):eadp3710, 2024.
[56] Rui Guo, Weinan Lin, Xiaobing Yan, T Venkatesan, and Jingsheng Chen. Ferroic tunnel
junctions and their application in neuromorphic networks.Applied physics reviews, 7(1), 2020.
[57] Panni Wang, Feng Xu, Bo Wang, Bin Gao, Huaqiang Wu, He Qian, and Shimeng Yu. Three-
dimensional NAND flash for vector-matrix multiplication.IEEE Transactions on Very Large
Scale Integration Systems, 27(4):988–991, 2018.
[58] Yachen Xiang, Peng Huang, Runze Han, Chu Li, Kunliang Wang, Xiaoyan Liu, and Jinfeng
Kang. Efficient and robust spike-driven deep convolutional neural networks based on NOR
flash computing array.IEEE Transactions on Electron Devices, 67(6):2329–2335, 2020.
[59] Farnood Merrikh-Bayat, Xinjie Guo, Michael Klachko, Mirko Prezioso, Konstantin K Likharev,
and Dmitri B Strukov. High-performance mixed-signal neurocomputing with nanoscale floating-
gate memory cell arrays.IEEE Transactions on Nneural Networks and Learning Systems,
29(10):4782–4790, 2017.
13

[60] Bonan Zhang, Peter Deaville, and Naveen Verma. Statistical computing framework and
demonstration for in-memory computing systems. InACM/IEEE Design Automation Conference,
pages 979–984, 2022.
[61] Peter Deaville, Bonan Zhang, Lung-Yen Chen, and Naveen Verma. A maximally row-parallel
MRAM in-memory-computing macro addressing readout circuit sensitivity and area. InIEEE
European Solid State Circuits Conference, pages 75–78. IEEE, 2021.
[62] Jung-Hoon Lee, Dong-Hyeok Lim, Hongsik Jeong, Huimin Ma, and Luping Shi. Exploring
cycle-to-cycle and device-to-device variation tolerance in mlc storage-based neural network
training.IEEE Transactions on Electron Devices, 66(5):2172–2178, 2019.
[63] Jintao Zhang, Zhuo Wang, and Naveen Verma. In-memory computation of a machine-learning
classifier in a standard 6t SRAM array.IEEE Journal of Solid-State Circuits, 52(4):915–924,
2017.
[64] Tayfun Gokmen, Malte J Rasch, and Wilfried Haensch. The marriage of training and inference
for scaled deep learning analog hardware. InIEEE International Electron Devices Meeting,
pages 22–3. IEEE, 2019.
[65] Corey Lammie, Athanasios Vasilopoulos, Julian Büchel, Giacomo Camposampiero, Manuel
Le Gallo, Malte Rasch, and Abu Sebastian. Improving the accuracy of analog-based in-memory
computing accelerators post-training. InIEEE International Symposium on Circuits and Systems,
pages 1–5. IEEE, 2024.
[66] Qing Jin, Zhiyu Chen, Jian Ren, Yanyu Li, Yanzhi Wang, and Kaiyuan Yang. PIM-QAT:
Neural network quantization for processing-in-memory (PIM) systems.arXiv preprint
arXiv:2209.08617, 2022.
[67] Malte J Rasch, Charles Mackin, Manuel Le Gallo, An Chen, Andrea Fasoli, Frédéric Odermatt,
Ning Li, S. R. Nandakumar, Pritish Narayanan, Hsinyu Tsai, et al. Hardware-aware training for
large-scale and diverse deep learning inference workloads using in-memory computing-based
accelerators.Nature Communications, 14(1):5282, 2023.
[68] Bonan Zhang, Chia-Yu Chen, and Naveen Verma. Reshape and adapt for output quantization
(RAOQ): Quantization-aware training for in-memory computing systems. InInternational
Conference on Machine Learning, 2024.
[69] Beiye Liu, Hai Li, Yiran Chen, Xin Li, Qing Wu, and Tingwen Huang. V ortex: Variation-aware
training for memristor x-bar. InProceedings of the 52nd Annual Design Automation Conference,
pages 1–6, 2015.
[70] Abhiroop Bhattacharjee, Lakshya Bhatnagar, Youngeun Kim, and Priyadarshini Panda. NEAT:
Non-linearity aware training for accurate and energy-efficient implementation of neural networks
on 1t-1r memristive crossbars.arXiv preprint arXiv:2012.00261, 2020.
[71] Tayfun Gokmen, Murat Onen, and Wilfried Haensch. Training deep convolutional neural
networks with resistive cross-point devices.Frontiers in neuroscience, 11:538, 2017.
[72] Zhongrui Wang, Saumil Joshi, Sergey Savel’Ev, Wenhao Song, Rivu Midya, Yunning Li, Mingyi
Rao, Peng Yan, Shiva Asapu, Ye Zhuo, et al. Fully memristive neural networks for pattern
classification with unsupervised learning.Nature Electronics, 1(2):137–145, 2018.
[73] Nanbo Gong, Malte Rasch, Soon-Cheon Seo, Arthur Gasasira, Paul Solomon, Valeria Bragaglia,
Steven Consiglio, Hisashi Higuchi, Chanro Park, Kevin Brew, et al. Deep learning acceleration
in 14nm CMOS compatible ReRAM array: device, material and algorithm co-optimization. In
IEEE International Electron Devices Meeting, 2022.
[74] Zhaoxian Wu, Quan Xiao, Tayfun Gokmen, Hsinyu Tsai, Kaoutar El Maghraoui, and Tianyi
Chen. Pipeline gradient-based model training on analog in-memory accelerators.arXiv preprint
arXiv:2410.15155, 2024.
14

[75] Logan G Wright, Tatsuhiro Onodera, Martin M Stein, Tianyu Wang, Darren T Schachter, Zoey
Hu, and Peter L McMahon. Deep physical neural networks trained with backpropagation.
Nature, 601(7894):549–555, 2022.
[76] Ali Momeni, Babak Rahmani, Benjamin Scellier, Logan G Wright, Clara C McMahon, Peter
L andWanjura, Yuhang Li, Anas Skalli, Natalia G. Berloff, Tatsuhiro Onodera, Ilker Oguz,
Francesco Morichetti, Philipp del Hougne, Manuel Le Gallo, Abu Sebastian, Azalia Mirhoseini,
Cheng Zhang, Danijela Markovi´c, Daniel Brunner, Christophe Moser, Sylvain Gigan, Florian
Marquardt, Aydogan Ozcan, Julie Grollier, Andrea J Liu, Demetri Psaltis, Andrea Alù, and
Romain Fleury. Training of physical neural networks.arXiv preprint arXiv:2406.03372, 2024.
[77] Demetri Psaltis, David Brady, Xiang-Guang Gu, and Steven Lin. Holography in artificial neural
networks.Nature, 343(6256):325–330, 1990.
[78] Tyler W Hughes, Ian AD Williamson, Momchil Minkov, and Shanhui Fan. Wave physics as an
analog recurrent neural network.Science advances, 5(12):eaay6946, 2019.
[79] Alexander N Tait, Thomas Ferreira De Lima, Ellen Zhou, Allie X Wu, Mitchell A Nahmias,
Bhavin J Shastri, and Paul R Prucnal. Neuromorphic photonic networks using silicon photonic
weight banks.Scientific reports, 7(1):7430, 2017.
[80] Nanbo Gong, T Idé, S Kim, Irem Boybat, Abu Sebastian, V Narayanan, and Takashi Ando.
Signal and noise extraction from analog memory elements for neuromorphic computing.Nature
communications, 9(1):2102, 2018.
[81] Mingyi Rao, Hao Tang, Jiangbin Wu, Wenhao Song, Max Zhang, Wenbo Yin, Ye Zhuo, Fatemeh
Kiani, Benjamin Chen, Xiangqi Jiang, et al. Thousands of conductance levels in memristors
integrated on CMOS.Nature, 615(7954):823–829, 2023.
[82] Deepak Sharma, Santi Prasad Rath, Bidyabhusan Kundu, Anil Korkmaz, Damien Thompson,
Navakanta Bhat, Sreebrata Goswami, R Stanley Williams, and Sreetosh Goswami. Linear
symmetric self-selecting 14-bit kinetic molecular memristors.Nature, 633(8030):560–566,
2024.
[83] Yurii Nesterov.Introductory Lectures on Convex Optimization: A Basic Course. Springer, 2013.
15

Appendix for “Analog In-memory Training on Non-ideal Resistive
Elements:
Understanding the Impact of Response Functions”
Table of Contents
A Literature Review 16
B Relation with the result in [21] 18
C Dynamic of Non-ideal Analog Update 20
D Comparison ofResidual Learning v2andTiki-Taka v221
E Useful Lemmas and Proofs 21
E.1 Lemma 1: Properties of weighted norm . . . . . . . . . . . . . . . . . . . . . . 21
E.2 Lemma 2: Properties of weighted norm . . . . . . . . . . . . . . . . . . . . . . 21
E.3 Lemma 3: Lipschitz continuity of analog update . . . . . . . . . . . . . . . . . 21
E.4 Lemma 4: Element-wise product error . . . . . . . . . . . . . . . . . . . . . . 22
F Proof of Theorem 4: Error from Pulse Update 23
G Proof of Theorem 1: Implicit Bias of Analog Training 23
H Proof of Theorem 2: Convergence ofAnalog SGD25
I Proof of Theorem 3: Convergence ofResidual Learning28
I.1 Main proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
I.2 Proof of Lemma 5: Descent of sequence ¯Wk . . . . . . . . . . . . . . . . . . . 32
I.3 Proof of Lemma 6: Descent of sequenceW k . . . . . . . . . . . . . . . . . . . 35
I.4 Proof of Lemma 7: Descent of sequenceP k . . . . . . . . . . . . . . . . . . . . 37
I.5 Proof of Corollary 1: Exact convergence ofTiki-Taka. . . . . . . . . . . . . 39
J Proof of Theorem 6: Convergence ofAnalog GD40
K Simulation Details and Additional Results 41
K.1 Power and Exponential Response Functions . . . . . . . . . . . . . . . . . . . . 42
K.2 Least squares problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
K.3 Classification problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
K.4 Additional performance on real datasets . . . . . . . . . . . . . . . . . . . . . . 43
K.5 Ablation study on cycle variation . . . . . . . . . . . . . . . . . . . . . . . . . 43
K.6 Ablation study on various response functions . . . . . . . . . . . . . . . . . . . 44
K.7 Ablation study onγ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
L Broader Impact 45
A Literature Review
This section briefly reviews literature that is related to this paper, as complementary to Section 1.
Training on AIMC hardware.Analog training has shown promising early successes in certain tasks
like face classification [25] and digit classification [26], where 1,000× lower energy consumption
compared with digital implementation is presented. Researchers are also exploring approaches to
mitigate the impact of hardware non-idealities. For example, [ 27, 28] proposes to leverage the
16

momentum technique to stabilize the training by reducing the noise. In order to overcome other
potential non-idealities, a hybrid training paradigm is also being explored. [29] leverages the chip-in-
the-loop technique to train models layer-by-layer, while [30] proposes to train the backbone in the
digital domain and train the last layer in the analog domain. In general, these works have provided
valuable insights into analog training, shedding light on many critical technical challenges. However,
their focus has largely been on experimental and simulation aspects, with limited systematic and
theoretical analysis of how specific imperfections affect the training process. In our paper, we present
an alternative viewpoint and novel tools to explore the effects of non-idealities.
Resistive element.A series of works seeks various resistive elements that have near-constant or at
least symmetric responses. The leading candidates currently include PCM [45, 46], ReRAM [47–49],
CBRAM [50, 51], ECRAM [52, 53], MRAM [54, 55], FTJ [56] or flash memory [57–59].
However, the resistive element possessing symmetric updates may not be the best option in terms of
manufacturing. For example, although ECRAM provides almost symmetric updates, it is still less
competitive than ReRAM as ReRAM has a faster response speed and lower pulse voltage [49]. The
suitability of the resistive elements is evaluated based on metrics across multiple dimensions, such as
the number of conductance states, retention, material endurance, switching energy, response speed,
manufacturing cost, and cell size. Among them, this paper is only interested in the impact of response
functions in the training.
Imperfection of AIMC hardware.Besides the response functions, analog training suffers from all
kinds of hardware imperfection, especially when the task’s scale increases, like asymmetric update
[17, 19], reading/writing noise [18, 60, 61], device/cycle variations [62], non-linear current response
due to IR drop [18, 6, 63]. This paper mainly focuses on asymmetric response functions. However,
this paper is not trying to diminish the importance of other hardware imperfections but focuses on
one of the primary ones that are known to be very important [19, 16].
Hardware-aware training.For inference on AIMC hardware purposes, models pretrained on
digital hardware will be programmed on analog hardware. Due to the hardware imperfection, the
pretrained models suffer from performance drops. Hardware-aware training (HWA) is a technique
designed to bridge the gap between ideal pretrained models and non-ideal programmed models. In
contrast to standard training methods, hardware-aware training explicitly incorporates device-specific
imperfections, such as weight drift [20], device fail [64], bounded dynamic range [65], quantization
error from ADC [66–68], device variation [69], and non-linear current output [70], into the training
loop. By modeling these constraints during the training phase, the learned parameters become
inherently more robust to real-world deployment conditions. It is worth highlighting that HWA is
still performed on digital hardware, and the trained model will be programmed onto AIMC hardware.
On the contrary, this paper considers a different and more challenging setting where the training is
performed directly on analog hardware.
Gradient-based training on AIMC hardware.A series of works focuses on implementing back-
propagation (BP) and gradient-based training on AIMC hardware. The seminal work [ 16, 71]
leverages the rank-one structure of the gradient and implements Analog SGD by a stochastic pulse
update scheme,rank-update. Rank-update significantly accelerates the gradient descent step by
avoiding dealing the gradients with O(N 2) elements directly but using two O(N) vectors for update
instead, where N is the numbers of matrix row and column. To alleviate theasymmetric update issue,
researchers also design various of Analog SGD variants, Tiki-Taka algorithm family [22–24]. The
key components of Tiki-Taka are introducing aresidual arrayto stabilize the training. Apart from
the rank-update, a hybrid scheme that performs forward and backward in the analog domain but
computes the gradients in the digital domain has been proposed in [31, 32]. Their solution, referred
to asmixed-precision update, provides a more accurate gradient signal but requires 5 ×-10× higher
overhead compared to the rank-update scheme [24].
Attributed to these efforts, analog training has empirically shown great promise in achieving a similar
level of accuracy as digital training on chip prototype, with reduced energy consumption and training
time [72, 73]. Simultaneously, the parallel acceleration solution with AIMC hardware is also under
exploration [74]. Despite its good performance, it is still mysterious about when and why they work.
Theoretical foundation of gradient-based training.The closely related result comes from the
convergence study of Tiki-Taka [21]. Similar to our work, they attempt to model the dynamic
and provide the convergence properties of Analog SGD and Tiki-Taka. However, their work is
17

limited to a special linear response function. Furthermore, their paper considers a simplified version
of Tiki-Taka, with a hyper-parameter γ= 0 (see Section 4). As we will show empirically and
theoretically, Tiki-Taka benefits from a non-zero γ. Consequently, We compare the results briefly
in Table 2 and comprehensively in Appendix B.
γ Generic response Linear response
Tiki-Taka[21] = 0 % O
q
1
K
1
1−33P 2max/τ 2

Tiki-Taka[Corollary 1] ̸= 0 O
q
1
K
1
RRL
min

O
q
1
K
1
1−P 2max/τ 2

Table 2: Comparison between our paper and [ 21]. Mixing-coefficient γ is a hyper-parameter of
Tiki-Taka. “Generic response” and “Linear response” columns are the convergence rates in the
corresponding settings. K represents the number of iterations. RRL
min and P 2
max/τ 2 <1 measure the
saturation while the former one reduces to the latter on linear response functions.
Energy-based models and equilibrium propagation.Apart from achieving explicit gradient signals
by the BP, there are also attempts to train models based onequilibrium propagation(EP, [ 33]),
which provides a biologically plausible alternative to traditional BP. EP is applicable to a series
of energy-based models, where the forward pass is performed by minimizing an energy function
[34, 35]. The update signal in EP is computed by measuring the output difference between a free
phase and an active phase. EP eliminates the need for BP non-local weight transport mechanism,
making it more compatible with neuromorphic and energy-efficient hardware [36, 37]. We highlight
here that the approach to attain update signals (BP or EP) is orthogonal to the update mechanism
(pulse update). Their difference lies in the objective f(W k), which is hidden in this paper. Therefore,
building upon the pulse update, our work is applicable to both BP and EP.
Physical neural network.The model executing on AIMC hardware, which leverages resistive
crossbar array to accelerate MVM operation, is a concrete implementation of physical neural networks
(PNNs, [75, 76]). PNN is a generic concept of implementing neural networks via a physical system
in which a set of tunable parameters, such as holographic grating [77], wave-based systems [78], and
photonic networks [79]. Our work particularly focuses on training with AIMC hardware, but the
methodology developed in this paper can be transferred to the study of other PNNs.
B Relation with the result in [21]
Similar to this paper, [21] also attempts to model the dynamic of analog training. They shows that
Analog SGD converges to a critical point of problem (1) inexactly with an asymptotic error, and
Tiki-Taka converges to a critical point exactly. In this section, we compare our results with our
results and theirs.
As discussed in Section 1, [21] studies the analog training on special linear response functions
q+(w) = 1− w
τ , q −(w) = 1 + w
τ .(16)
It can be checked that the symmetric point is0 while the dynamic range of it is[−τ, τ] . The symmetric
and asymmetric components is defined by F(W) = 1 and G(W) = W
τ , respectively. It indicates
Fmax = 1. Furthermore, they assume the bounded weight saturation by assuming bounded weights,
i.e., ∥Wk∥∞ ≤W max,∀k∈[K] with a constant Wmax < τ . Under this assumption, the lower
bounds of response functions are given by
min{R(Wk)}= min{Q +(Wk)⊙Q −(Wk)}= 1−
 ∥Wk∥∞
τ
2
(17)
RASGD
min = min{R(W k)}= 1−
 Wmax
τ
2
.(18)
Challenge of analyzing the convergence of Tiki-Taka with generic response functions.For
linear response functions (16), the recursion of residual array Pk has a special structure, where the
18

first and the biased term can be combined
Pk+1 =P k −α∇f( ¯Wk;ξ k)− α
τ |∇f( ¯Wk;ξ k)| ⊙P k (19)
=

1− α
τ |∇f( ¯Wk;ξ k)|

⊙P k −α∇f( ¯Wk;ξ k)
which is a weighted average of Pk and ∇f( ¯Wk;ξ k). Consequently, Pk can be interpreted as an
approximation of the average gradient. For this perspective, the transfer operation can be interpreted
as biased gradient descent. However, given a generic G(·), the combination is no longer viable,
bringing difficulties to the analysis.
Convergence of Analog SGD.As we will show in Remark 1 at the end of Appendix H, inequality (8)
can be improved when the saturation never happens
1
K
K−1X
k=0
E[∥∇f(W k)∥2](20)
≤ 4F 2
max
RRL
min
r
(f(W0)−f ∗)σ2L
K + 2Fmaxσ2 × 1
K
K−1X
k=0

G(Wk)p
F(W k)

2
∞
,
min{R(Wk)}(21)
≤O
 r
(f(W0)−f ∗)σ2L
K
1
1−W 2max/τ 2
!
+ 2σ2 × 1
K
KX
k=0
∥Wk∥2
∞/τ 2
1− ∥W k∥2∞/τ 2
which is exactly the result in [21].
Convergence of Tiki-Taka.It is shown that a non-zero γ in (10) improves the training accuracy
[22]. However, [ 21] considers a special case with γ= 0 while this paper considers a non-zero
γ. As we will discuss latter in this section, different γ leads to different convergence behaviors of
Tiki-Taka.
With the linear response, if we also assume the bounded saturation of Pk by letting ∥Pk∥∞ ≤P max,
the minimal average response function is given by RRL
min = 1−
  Pmax
τ
2
. The upper bound in
Corollary 1 becomes
1
K
K−1X
k=0
∥∇f( ¯Wk)∥2 ≤O
 
1
1−P 2max/τ 2
r
(f(W0)−f ∗)σ2L
K
!
.(22)
As a comparison, without introducing a non-zeroγ, [21] shows that convergence rate ofTiki-Taka is
only
1
K
K−1X
k=0
∥∇f(W k)∥2 ≤O
 
1
1−33P 2max/τ 2
r
(f(W0)−f ∗)σ2L
K
!
.(23)
Even though it is not a completely fair comparison since two paper relies on different assumptions,
it is still worthy to compare the analysis in two paper. [21] assumes the noise should be non-zero,
i.e. [Eξ[|∇f(W;ξ)|]] i ≥c noiseσ,∀i∈[D] holds for a non-zero constant cnoise. Instead, this paper
does not make this assumption but assumes that the objective is strongly convex. As mentioned in
Section 4, the strong convexity is introduced only to ensure the existence of P ∗(Wk). Therefore, we
believe it can be relaxed, and the convergence rate can remain unchanged, which is left as a future
work. Taking that into account, we believe the comparison can provide insight of how the non-zero γ
improves the convergence rate ofTiki-Taka.
Why does non-zero γ improve the convergence rate of Tiki-Taka?As discussed in Section 4,
Pk is interpreted as a residual array that optimizes f(W k +γP) . In the ideal setting that F(W) = 1
and G(W) = 0 , it can be shown that Pk converges to P ∗(Wk) if Wk is fixed and Pk is kept updated,
even though theW k ̸=W ∗ (hence∇f(W k)̸= 0).
Instead, without a non-zero γ, [21] points out that Pk is an approximation of clear gradient by
showing
Eξk[∥Pk+1 −C∇f(W k)∥2](24)
19

≤

1− β
C

∥Pk −C∇f(W k)∥2 +O(βC ′)∥∇f(W k)∥2 +remainder
where C, C′ are constants depending on the resistive element and model dimension, and the “remain-
der” is the non-essential terms. Consider the case that Wk is fixed and (10) is kept iterating, in which
case the increment on Pk is constant since γ= 0 . Telescoping (24) we find the upper bound above
only guarantee that
lim sup
k→∞
E[∥Pk+1 −C∇f(W k)∥2]≤O(CC ′∥∇f(W k)∥2)(25)
which means that Pk tracks the gradient accurately only when ∇f(W k) reaches zero asymptotically.
Consequently, the less accurate approximation leads to a slower rate than this paper.
C Dynamic of Non-ideal Analog Update
This section presents details about how to get the dynamic of analog update(3) appearing in Section 2
and its error analysis. The primary distinction between digital and analog training is the weight
update method. As discussed in Section 1, the weight update in AIMC hardware is implemented by
Analog Update, which sends a series of pulses to the resistive elements.
Pulse update.Consider the response of one resistive element in one cycle, which involves only
one pulse. Given the initial weight w, the updated weight increases or decreases by about ∆wmin
depending on the pulse polarity, where ∆wmin >0 is theresponse granularitydetermined by
elements. The granularity is further scaled by a factor, which varies by the update direction due to
theasymmetric updateproperty of resistive elements. The notations q+(·) and q−(·) are used to
denote theresponse functionson positive or negative sides, respectively, to describe the dominating
part of the factor. In practice, the analog noise also causes a deviation of the effective factor from
the response functions, referred to ascycle variation. It is represented by the magnitude σc times
a random variable ξc with expectation 0 and variance 1. Taking all of them into account, with
s∈ {+,−} being the update direction, the updated weight after receiving one pulse is ˜Uq(w, s)
where ˜Uq(·,·) :R× {+,−} →R is the element-dependent update that implements the resistive
element, which can be expressed as
˜Uq(w, s) :=w+ ∆w min ·(q s(w) +σ cξ)(26)
=
w+ ∆w min ·(q +(w) +σ cξc), s= +,
w−∆w min ·(q −(w) +σ cξc), s=−.
The typical signal and noise ratio σc/qs(w) is roughly 5%-100% [ 80, 49], varied by the type of
resistive elements. Furthermore, the response functions also vary by elements due to the imperfection
in fabrication, calledelement variation(also referred to asdevice variationin literature [16]).
Equation (26) is a resistive element level equation. Existing work exploring the candidates of resistive
elements usually reports the response curves similar to Figure 1, [73, 52, 49]. Taking the difference
between weights in two consecutive pulse cycles and adopting statistical approaches [ 80], all the
element-dependent quantities, including ∆wmin, q+(·), q−(·) and σc, can be estimated from the
response curves of the resistive elements.
Analog update implemented by pulse updates.Even though the update scheme has evolved over
the years [16, 71], we discuss a simplified version, called Analog Update, to retain the essential
properties. To update the weight w by ∆w, a series of pulses are sent, whosebit length (BL)is
computed by BL :=
l
|∆w|
∆wmin
m
. After received BL pulses, the updated weight w′ can be expressed as
the function composition of (26) byBLtimes
w′ = ˜Uq ◦ ˜Uq ◦ · · · ◦ ˜Uq| {z }
×BL
(w, s) =: ˜UBL
q (w, s).(27)
Roughly speaking, given an ideal responseq+(w) =q −(w) = 1 and σc = 0, BL pulses, with ∆wmin
increment for each individual pulse, incur the weight update ∆w. Since the response granularity
∆wmin is scaled by the response function qs(w), the expected increment is approximately scaled
by qs(w) as well. Accordingly, we propose an approximate dynamic of Analog Update is given by
20

w′ ≈U q(w,∆w) , where Uq(w,∆w) is defined in (3). The following theorem provides an estimation
of the approximation error. It has been shown empirically that the response granularity can be made
sufficiently small for updating [81, 82], implying ∆wmin ≪∆w . Therefore, we establish the error
estimation of the approximation based on a small response granularity condition.
Theorem 4(Error from discrete pulse update).Suppose the response granularity is sufficiently small
such that ∆wmin ≤o(∆w) . With the update direction s=sign(∆w) , the error between the true
update ˜UBL
q (w, s)and the approximatedU q(w,∆w)is bounded by
lim
∆w→0
| ˜UBL
q (w, s)−U q(w,∆w)|
| ˜UBLq (w, s)−w|
= 0.(28)
The proof of Theorem 4 is deferred to Appendix F. In Theorem 4, | ˜UBL
q (w, s)−U q(w,∆w)| is the
error between the true update and the proposed dynamic, while | ˜UBL
q (w, s)−w| is the difference
between original weight and the updated one. Theorem 4 shows that the proposed dynamic dominates
the update, and the approximation error is negligible when ∆w is small, which holds as ∆w always
includes a small learning rate in gradient-based training.
Takeaway.Theorem 4 enables us to discuss the impact of response functions directly without
dealing with element-specific details like response granularity ∆wmin and cycle variation σc.
Response functions are the bridge between the resistive element level equation (pulse update
(26)) and algorithm level equation (dynamic ofAnalog Update(3)).
D Comparison ofResidual Learning v2andTiki-Taka v2
Introducing a digital buffer, the proposed Residual Learning v2 has a similar form of Tiki-Taka
v2[23]. However, there are slight differences.Tiki-Taka v2updates the digital buffer by
Hk+ 1
2
=H k +β(P k+1 +ε k)(29)
which do not include a decay coefficient in front of Hk. Furthermore, Tiki-Taka v2 uses the
gradient ∇f(W k;ξ k) that are solely computed on the main array Wk. Instead, Residual Learning
v2 computes gradient on a mixed weight ¯Wk =W k +γP k. As suggested by the ablation simulations
in Section K.7, the training benefits from a non-zeroγ.
E Useful Lemmas and Proofs
E.1 Lemma 1: Properties of weighted norm
Lemma 1. ∥W∥ S has the following properties: (a) ∥W∥ S =∥W⊙
√
S∥; (b) ∥W∥ S ≤
∥W∥
p
∥S∥∞; (c)∥W∥ S ≥ ∥W∥
p
min{S}.
Proof of Lemma 1.The lemma can be proven easily by definition.
E.2 Lemma 2: Properties of weighted norm
A direct property from Definition 1 is that all q+(·), q−(·), and F(·) are bounded, as guaranteed by
the following lemma.
Lemma 2.The following statements are valid for all W∈ R . (a) F(·) is element-wise upper
bounded by a constant Fmax >0 , i.e., ∥F(W)∥ ∞ ≤F max; (b) Q+(·) and ∇Q−(·) are element-wise
bounded byL Q, i.e.,∥∇Q +(W)∥ ∞ ≤L Q,∥∇Q −(W)∥ ∞ ≤L Q.
E.3 Lemma 3: Lipschitz continuity of analog update
Lemma 3.The increment defined in (5) is Lipschitz continuous with respect to ∆W under any
weighted norm∥ · ∥ S, i.e., for anyW,∆W,∆W ′ ∈R D andS∈R D
+, it holds
∥∆W⊙F(W)− |∆W| ⊙G(W)−(∆W ′ ⊙F(W)− |∆W ′| ⊙G(W))∥ S (30)
21

≤F max∥∆W−∆W ′∥S.
Proof of Lemma 3. We prove for the case where D= 1 and S= 1 , and the general case can be
proven similarly. Notice that the absolute value | · | and vector norm ∥ · ∥, scalar multiplication ×
and element-wise multiplication ⊙, are equivalent at that situation. We adopt both notations just for
readability.
∥∆W⊙F(W)− |∆W| ⊙G(W)−(∆W ′ ⊙F(W)− |∆W ′| ⊙G(W))∥(31)
=∥(∆W−∆W ′)⊙F(W)−(|∆W| − |∆W ′|)⊙G(W)∥.
Since∥∆W−∆W ′∥ ≥ ∥|∆W| − |∆W ′|∥and|G(W)| ≤ |F(W)|, we have
|(∆W−∆W ′)⊙F(W)−(|∆W| − |∆W ′|)⊙G(W)|(32)
≤ |(∆W−∆W ′)⊙(F(W)− |G(W)|)|
≤ |∆W−∆W ′| |F(W)− |G(W)||
≤F max|∆W−∆W ′|
which completes the proof.
E.4 Lemma 4: Element-wise product error
Lemma 4.LetU, V, Q∈R D be vectors indexed by[D]. Then the following inequality holds
⟨U, V⊙Q⟩ ≥C + ⟨U, V⟩ −C − ⟨|U|,|V|⟩(33)
where the constantC + andC − are defined by
C+ :=1
2 (max{Q}+ min{Q}),(34)
C− :=1
2 (max{Q} −min{Q}).(35)
Proof of Lemma 4.For any vectorsU, V, Q∈R D, it is always valid that
⟨U, V⊙Q⟩=
X
i∈[D]
[U] i[V] i[Q]i (36)
=
X
i∈[D],[U] i[V] i≥0
[U] i[V] i[Q]i +
X
i∈[D],[U] i[V] i<0
[U] i[V] i[Q]i
≥min{Q} ×

 X
i∈[D],[U] i[V] i≥0
[U] i[V] i

 + max{Q} ×

 X
i∈[D],[U] i[V] i<0
[U] i[V] i


(a)
=C +

 X
i∈[D],[U] i[V] i≥0
[U] i[V] i

 −C −

 X
i∈[D],[U] i[V] i≥0
|[U] i[V] i|


+C +

 X
i∈[D],[U] i[V] i<0
[U] i[V] i

 −C −

 X
i∈[D],[U] i[V] i<0
|[U] i[V] i|


=C +
X
i∈[D]
[U] i[V] i −C −
X
i∈[D]
|[U] i[V] i|
=C + ⟨U, V⟩ −C − ⟨|U|,|V|⟩
where(a)uses the following equality
min{Q}[U] i[V] i =C +[U] i[V] i −C −|[U] i[V] i|,if[U] i[V] i ≥0,(37)
max{Q}[U] i[V] i =C +[U] i[V] i −C −|[U] i[V] i|,if[U] i[V] i <0.(38)
This completes the proof.
22

F Proof of Theorem 4: Error from Pulse Update
Theorem 4(Error from discrete pulse update).Suppose the response granularity is sufficiently small
such that ∆wmin ≤o(∆w) . With the update direction s=sign(∆w) , the error between the true
update ˜UBL
q (w, s)and the approximatedU q(w,∆w)is bounded by
lim
∆w→0
| ˜UBL
q (w, s)−U q(w,∆w)|
| ˜UBLq (w, s)−w|
= 0.(28)
Proof of Theorem 4.Recall the definition of the bit length is
BL :=
 |∆w|
∆wmin

= Θ
 |∆w|
∆wmin

(39)
leading to
|BL ∆wmin − |∆w|| ≤∆w min or|sBL ∆w min −∆w| ≤∆w min.(40)
Notice that the update responding to each pulse is a Θ(∆wmin) term. Directly manipulating
UBL
p (w, s)and expanding it in Taylor series to the first-order term yields
UBL
p (w, s) =w+s·∆w min
BL−1X
t=0
qs(w+ Θ(t∆w min)) + ∆wmin
BL−1X
t=0
σcξt (41)
=w+s·∆w min
BL−1X
t=0
qs(w) +
BL−1X
t=0
Θ(t(∆wmin)2) + ∆wmin
BL−1X
t=0
σcξt
=w+s·∆w min ·BL·q s(w) + Θ(BL2(∆wmin)2) + ∆wmin ·
√
BL·σ cξ
=w+ ∆w·q s(w) + (sBL ∆wmin −∆w) + Θ((∆w) 2) +
p
∆wmin ·
√
∆w·σ cξ
=U q(w,∆w) + Θ(∆w min) + Θ((∆w)2) + Θ(
p
∆wmin ·
√
∆w·σ c)
whereξ:= 1√
BL
PBL−1
t=0 ξt is the accumulated noise with variance1. The proof is completed.
G Proof of Theorem 1: Implicit Bias of Analog Training
In this section, we provide a full version of Theorem 1. Before that, we formally define the
accumulated asymmetric function Rc(W) :R D →R D element-wise. Let R(W) := G(W)
F(W) be the
asymmetric ratio andR c(W)is defined by
[Rc(W)] i :=
Z [W] i
τ min
i
[R(W)] i d[W] i (42)
which satisfies ∇Rc(W) =R(W) and ∇ ⟨Σ, Rc(W)⟩= Σ⊙R(W) . Since we do not further
assume stronger properties for response functions, like monotonicity, it is hard to provide strong
claims on the shape of R(W) or Rc(W) . Here we provide the expression of Rc(W) for the linear
response functions Q+(W) = 1− W
τ , Q−(W) = 1 + W
τ . In this case, F(W) = 1 and G(W) = W
τ
based on definition (4); and hence R(W) = G(W)
F(W) = W
τ . Accordingly, the accumulated asymmetric
function is given by
[Rc(W)] i =
Z [W] i
τ min
i
[R(W)] i d[W] i =
Z [W] i
τ min
i
[W] i
τ d[W] i (43)
= 1
2τ ([W] i)2 − 1
2τ (τ min
i )2.
Therefore, the last term in the objective (7) becomes
⟨Σ, Rc(W)⟩=
DX
i=1
[Σ]i[Rc(W)] i =
DX
i=1
[Σ]i
 1
2τ ([W] i)2 − 1
2τ (τ min
i )2

(44)
23

= 1
2τ ∥W∥ 2
Σ +const.
which is a weightedℓ 2 norm regularization term. In the scalar case, it reduces to (45).
min
W
fΣ(W) :=f(W) + Σ
2τ ∥W∥ 2 (45)
It is noticeable that if the ratio R(W) is monotonic at each coordinate, Rc(W) reaches its minimum
at W ⋄. Therefore, Rc(W) has no impact on the convergence only when the optimal point of f(W)
isW ⋄.
Theorem 5(Implicit Penalty, full version of Theorem 1).Let T(w) denote the effective update of
Analog SGD.
T(W) :=

Eξ [Uq(W,−αf ′(W;ξ))]−W
α
 =|E ξ[f ′(w;ξ)]⊙F(W)−E ξ[|f ′(W;ξ)|]⊙G(W)|.
(46)
Analog SGDimplicitly optimizes the following penalized objective
min
W
fΣ(W) :=f(W) +⟨Σ, R c(W)⟩(47)
in the sense that there exists a pointW S given by
W S := (∇2f(W ∗)− ∇R(W ⋄)Σ)−1(∇2f(W ∗)W ∗ − ∇R(W ⋄)ΣW ⋄)(48)
such that ∥∇fΣ(W S)∥ ≤O((W ⋄ −W ∗)2) and T(W S)≤O((W ⋄ −W ∗)2). Both T(W S) and
∥∇fΣ(W S)∥ are significantly smaller thanT(W ⋄) =O(|W ⋄−W ∗|) and T(W ∗) =O(|W ⋄−W ∗|)
whenW ⋄ is close toW ∗.
IfWis a scalar, i.e.D= 1, (48) reduces to (45)
min
W
fΣ(W) :=f(W) + Σ
2τ ∥W∥ 2 (49)
with its solution
W S := f ′′(W ∗)W ∗ −R ′(W ⋄)ΣW ⋄
f ′′(W ∗)−R ′(W ⋄)Σ .(50)
Proof of Theorem 1 and 5. We separately show that∥∇fΣ(W)∥ ≤O((W ⋄ −W ∗)2) and T(W S)≤
O((W ⋄ −W ∗)2).
Proof of ∥∇fΣ(W)∥ ≤O((W ⋄ −W ∗)2).The gradient of the penalized objective fΣ(W) is given
by
∇fΣ(W) =∇f(W) + Σ⊙R(W).(51)
Leveraging the fact that∇f(W ∗) = 0, G(W ⋄)
F(W ⋄) = 0, as well as Taylor expansion given by
∇f(W S) =∇f(W ∗) +∇ 2f(W ∗)(W S −W ∗) +O((W S −W ∗)2),(52)
G(W S)
F(W S) = G(W ⋄)
F(W ⋄) +∇R(W ⋄)(W S −W ⋄) +O((W S −W ⋄)2),(53)
we bound the gradient of the penalized objective as follows
∥∇fΣ(W)∥=
∇f(W S)−Σ⊙ G(W S)
F(W S)
 (54)
=
∇2f(W ∗)(W S −W ∗) +O((W S −W ∗)2)−Σ⊙(∇R(W ⋄)(W S −W ⋄)) +O((W S −W ⋄)2)

=O((W S −W ∗)2) +O((W S −W ⋄)2)
=O((W ∗ −W ⋄)2)
where the last inequality holds by the definition ofW S.
24

Proof ofT(w S)≤O((w ⋄ −w ∗)2).By the definition of effective updateT(W S), we have

Eξ

Uq(W S,−α∇f(W S;ξ))

−W S
α
 (55)
=
Eξ[∇f(W S;ξ)]⊙F(W S)−E ξ[|∇f(W S;ξ)|]⊙G(W S)

≤


∇f(W S)−E ξ[|∇f(W S;ξ)|]⊙ G(W S)
F(W S)
 Fmax
≤
∇f(W S)−E ξ[|∇f(W S;ξ)− ∇f(W S)|]⊙ G(W S)
F(W S)
 Fmax
+
(Eξ[|∇f(W S;ξ)|]−E ξ[|∇f(W S;ξ)− ∇f(W S)|])⊙ G(W S)
F(W S)
 Fmax
≤ ∥∇fΣ(W)∥F max +
(Eξ[|∇f(W S;ξ)|]−E ξ[|∇f(W S;ξ)− ∇f(W S)|])⊙ G(W S)
F(W S)
 Fmax
The first term in the right-hand side ( RHS) of (55) is already bounded by (54). By inequality
||x| − |y|| ≤ |x−y|for anyx, y∈R, the second term in the RHS of (55) is bounded by
(Eξ[|∇f(W S;ξ)|]−E ξ[|∇f(W S;ξ)− ∇f(W S)|])⊙ G(W S)
F(W S)
 (56)
≤
|∇f(W S)| ⊙ G(W S)
F(W S)

=
|∇f(W S)− ∇f(W ∗)| ⊙
 G(W S)
F(W S) − G(W ⋄)
F(W ⋄)

≤O(|W S −W ∗|)·O(|W S −W ⋄|)
=O((W ∗ −W ⋄)2)
Plugging back (54) and (56) into (55) shows T(w S)≤O((w ⋄ −w ∗)2). It is trivial to prove
T(W ⋄) =O(|W ⋄ −W ∗|)andT(W ∗) =O(|W ⋄ −W ∗|)by the definition ofW S and (52).
H Proof of Theorem 2: Convergence ofAnalog SGD
Theorem 2(Inexact convergence of Analog SGD).Under Assumption 1–3, if the learning rate is set
asα=O(1/
√
K), it holds that
EK ≤O
p
σ2/K+σ 2SASGD
K

(8)
whereS ASGD
K denotes the amplification factor given byS ASGD
K := 1
K
PK−1
k=0

G(Wk)√
F(W k)

2
∞
.
Proof of Theorem 2.TheL-smooth assumption (Assumption 1) implies that
Eξk[f(W k+1)]≤f(W k) +E ξk[⟨∇f(W k), Wk+1 −W k⟩]| {z }
(a)
+ L
2 Eξk[∥Wk+1 −W k∥2]
| {z }
(b)
.(57)
Next, we will handle the second and the third terms in the RHS of (57) separately.
Bound of the second term (a).To bound term (a) in the RHS of (57), we leverage the assumption
that noise has expectation0(Assumption 2)
Eξk[⟨∇f(W k), Wk+1 −W k⟩](58)
=αE ξk
"*
∇f(W k)⊙
p
F(W k), Wk+1 −W k
α
p
F(W k)
+ (∇f(Wk;ξ k)− ∇f(W k))⊙
p
F(W k)
+#
=− α
2 ∥∇f(W k)⊙
p
F(W k)∥2
25

− 1
2α Eξk



Wk+1 −W kp
F(W k)
+α(∇f(W k;ξ k)− ∇f(W k))⊙
p
F(W k)

2

+ 1
2α Eξk



Wk+1 −W kp
F(W k)
+α∇f(W k;ξ k)⊙
p
F(W k)

2
 .
The second term of the RHS of (58) is bounded by
1
2α Eξk



Wk+1 −W kp
F(W k)
+α(∇f(W k;ξ k)− ∇f(W k))⊙
p
F(W k)

2
 (59)
= 1
2α Eξk



Wk+1 −W k +α(∇f(W k;ξ k)− ∇f(W k))⊙F(W k)p
F(W k)

2

≥ 1
2αFmax
Eξk

∥Wk+1 −W k +α(∇f(W k;ξ k)− ∇f(W k))⊙F(W k)∥2
.
The third term in the RHS of (58) can be bounded by variance decomposition and bounded variance
assumption (Assumption 2)
1
2α Eξk



Wk+1 −W kp
F(W k)
+α∇f(W k;ξ k)⊙
p
F(W k)

2
 (60)
= α
2 Eξk


|∇f(W k;ξ k)| ⊙ G(Wk)p
F(W k)

2

≤ α
2
|∇f(W k)| ⊙ G(Wk)p
F(W k)

2
+ ασ2
2

G(Wk)p
F(W k)

2
∞
.
Define the saturation vectorR(W k)∈R D by
R(Wk) :=F(W k)⊙2 −G(W k)⊙2 = (F(W k) +G(W k))⊙(F(W k)−G(W k))(61)
=Q +(Wk)⊙Q −(Wk).
Note that the first term in the RHS of (58) and the second term in the RHS of (60) can be bounded by
− α
2 ∥∇f(W k)⊙
p
F(W k)∥2 + α
2
|∇f(W k)| ⊙ G(Wk)p
F(W k)

2
(62)
=− α
2
X
d∈[D]

[∇f(W k)]2
d

[F(W k)]d − [G(Wk)]2
d
[F(W k)]d

=− α
2
X
d∈[D]

[∇f(W k)]2
d
[F(W k)]2
d −[G(W k)]2
d
[F(W k)]d

≤ − α
2Fmax
X
d∈[D]
 
[∇f(W k)]2
d
 
[F(W k)]2
d −[G(W k)]2
d

=− α
2Fmax
∥∇f(W k)∥2
R(Wk) ≤0.
Plugging (59) to (62) into (58), we bound the term (a) by
Eξk[⟨∇f(W k), Wk+1 −W k⟩](63)
=− α
2Fmax
∥∇f(W k)∥2
R(Wk) + ασ2
2

G(Wk)p
F(W k)

2
∞
26

− 1
2αFmax
Eξk
h
∥Wk+1 −W k +α(∇f(W k;ξ k)− ∇f(W k))⊙F(W k)∥2
i
.
Bound of the third term (b).The third term (b) in the RHS of (57) is bounded by
L
2 Eξk[∥Wk+1 −W k∥2](64)
≤LE ξk[∥Wk+1 −W k +α(∇f(W k;ξ k)− ∇f(W k))⊙F(W k)∥2]
+α 2LEξk[∥(∇f(W k;ξ k)− ∇f(W k))⊙F(W k)∥2]
≤LE ξk[∥Wk+1 −W k +α(∇f(W k;ξ k)− ∇f(W k))⊙F(W k)∥2] +α 2LF 2
maxσ2
where the last inequality leverages the bounded variance of noise (Assumption 2) and the fact that
F(W k)is bounded byF max element-wise.
Substituting (63) and (64) back into (57), we have
Eξk[f(W k+1)]≤f(W k)− α
2Fmax
∥∇f(W k)∥2
R(Wk) +α 2LF 2
maxσ2 + ασ2
2

G(Wk)p
F(W k)

2
∞
(65)
− 1
Fmax
 1
2α −LF max

Eξk[∥Wk+1 −W k +α(∇f(W k;ξ k)− ∇f(W k))⊙F(W k)∥2].
The third term in the RHS of (65) can be bounded by
Eξk[∥Wk+1 −W k +α(∇f(W k;ξ k)− ∇f(W k))⊙F(W k)∥2](66)
=α 2Eξk[∥∇f(W k)⊙F(W k) +|∇f(W k;ξ k)| ⊙G(W k)∥2]
≥ 1
2 α2Eξk[∥∇f(W k)⊙F(W k) +|∇f(W k)| ⊙G(W k)∥2]
−α 2Eξk[∥(|∇f(W k)| − |∇f(W k;ξ k)|)⊙G(W k)∥2]
≥ 1
2 α2Eξk[∥∇f(W k)⊙F(W k) +|∇f(W k)| ⊙G(W k)∥2]
−α 2Eξk[∥(∇f(W k)− ∇f(W k;ξ k))⊙G(W k)∥2]
≥ 1
2 α2Eξk[∥∇f(W k)⊙F(W k) +|∇f(W k)| ⊙G(W k)∥2]−α 2Fmaxσ2

G(Wk)p
F(W k)

2
∞
where the first inequality holds because ∥x∥2 ≥ 1
2 ∥x−y∥ 2 − ∥y∥2 for any x, y∈R D, the second
inequality comes from||x| − |y|| ≤ |x−y|for anyx, y∈R, and the last inequality holds because
Eξk[∥(∇f(W k)− ∇f(W k;ξ k))⊙G(W k)∥2](67)
=E ξk


(∇f(W k)− ∇f(W k;ξ k))⊙ G(Wk)p
F(W k)
⊙
p
F(W k)

2

≤F maxEξk


(∇f(W k)− ∇f(W k;ξ k))⊙ G(Wk)p
F(W k)

2

≤F maxEξk

∥∇f(W k)− ∇f(W k;ξ k)∥2

G(Wk)p
F(W k)

2
∞
≤F maxσ2

G(Wk)p
F(W k)

2
∞
.
The learning rateα≤ 1
4LFmax
implies that 1
2α −LF max ≤ 1
4α in (65), which leads (57) to
Eξk[f(W k+1)]≤f(W k)− α
2Fmax
∥∇f(W k)∥2
R(Wk) +α 2LF 2
maxσ2 +ασ 2

G(Wk)p
F(W k)

2
∞
(68)
27

− α
8Fmax
∥∇f(W k)⊙F(W k) +|∇f(W k)| ⊙G(W k)∥2.
Reorganizing (68), taking expectation over all ξK, ξK−1 ,· · ·, ξ 0, and averaging them for k from 0 to
K−1deduce that
EK = 1
K
KX
k=0
E[∥∇f(W k)⊙F(W k) +|∇f(W k)| ⊙G(W k)∥2 + 4∥∇f(Wk)∥2
R(Wk)](69)
≤ 8Fmax(f(W0)−E[f(W k+1)])
αK + 8αLF3
maxσ2 + 8Fmaxσ2 × 1
K
K−1X
k=0

G(Wk)p
F(W k)

2
∞
≤ 8Fmax(f(W0)−f ∗)
αK + 8αLF3
maxσ2 + 8Fmaxσ2 × 1
K
K−1X
k=0

G(Wk)p
F(W k)

2
∞
= 16F2
max
r
(f(W0)−f ∗)σ2L
K + 8Fmaxσ2SASGD
K
where the last equality chooses the learning rate as α= 1
Fmax
q
f(W 0)−f ∗
σ2LK . The proof is completed.
Remark 1(Tighter bound without saturation).Assuming the saturation never happens during the
training, i.e. R(Wk)≥R RL
min >0 for all k∈[K] , we get a tighter bound in (68) by leveraging
∥∇f(W k)∥2
R(Wk) ≥min{R(W k)} ∥∇f(W k)∥2 ≥R RL
min ∥∇f(W k)∥2
Eξk[f(W k+1)]≤f(W k)− α
2Fmax
∥∇f(W k)∥2
R(Wk) +α 2LF 2
maxσ2 +ασ 2

G(Wk)p
F(W k)

2
∞
(70)
which leads to
1
K
KX
k=0
[∥∇f(W k)∥2](71)
= 4F 2
max
RRL
min
r
(f(W0)−f ∗)σ2L
K + 2Fmaxσ2 × 1
K
K−1X
k=0

G(Wk)p
F(W k)

2
∞
,
min{R(Wk)}.
It exactly reduces to the result for the convergence of Analog SGD in [21] on special linear repsonse
functions, as discussed in Appendix B.
I Proof of Theorem 3: Convergence ofResidual Learning
This section provides the convergence guarantee of the Tiki-Taka under the strongly convex
assumption.
Theorem 3(Convergence of Residual Learning).Under Assumptions 1–3 and 4, with the learning
rateα=O
p
1/σ2K

,β=O(αγ 3/2), it holds forResidual Learningthat
ERL
K ≤O
p
σ2/K+σ 2SRL
K

(13)
whereS RL
K denotes the amplification factor ofP k given byS RL
K := 1
K
PK
k=0

G(Pk)√
F(P k)

2
∞
.
I.1 Main proof
Proof of Theorem 3. The proof of the Tiki-Taka convergence relies on the following two lemmas,
which provide the sufficient descent ofW k and ¯Wk, respectively.
28

Lemma 5(Descent Lemma of ¯Wk).Suppose Assumptions 1–2 hold. It holds forTiki-Takathat
Eξk[f( ¯Wk+1)]≤f( ¯Wk)− α
4Fmax
∥∇f( ¯Wk)∥2
R(Pk) + 2ασ2

G(Pk)p
F(P k)

2
∞
+ 2α2LF 2
maxσ2
(72)
− αγ
8Fmax
∥∇f( ¯Wk)⊙F(P k) +|∇f( ¯Wk)| ⊙G(P k)∥2
+ Fmax
α Eξk
h
∥Wk+1 −W k∥2
R(Pk)†
i
+E ξk[∥Wk+1 −W k∥2].
Lemma 6(Descent Lemma ofW k).It holds forTiki-Takathat
∥Wk+1 −W ∗∥2 ≤ ∥Wk −W ∗∥2 − β
2γFmax
∥Wk −W ∗∥2
R(Wk) (73)
− βγ
2Fmax
∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2
+ 2βF 3
max
γ ∥Pk+1 −P ∗(Wk)∥2
R(Wk)† + 2β2∥Pk+1 −P ∗(Wk)∥2.
The proof of Lemma 5 and 6 are deferred to Section I.2 and I.3, respectively. For a sufficiently large
γ, P ∗(Wk) is ensured to be located in the dynamic range of the analog array Pk. Therefore, we may
assume both q+(Pk) and q−(Pk) are non-zero, equivalently, there exists a non-zero constantRRL
min
such thatmin{R(P k)} ≥R RL
min for allk. Under this condition, we have the following inequalities
α
4Fmax
∥∇f( ¯Wk)∥2
R(Pk) ≥ αRRL
min
4Fmax
∥∇f( ¯Wk)∥2,(74)
Fmax
αγ ∥Wk+1 −W k∥2
R(Pk)† ≤ Fmax
αγRRL
min
∥Wk+1 −W k∥2.(75)
Similarly, we bound the term∥P k+1 −P ∗(Wk)∥2
R(Wk)† in (72) by
2βF 3
max
γ ∥Pk+1 −P ∗(Wk)∥2
R(Wk)† ≤ 2βF 3
max
γmin{R(W k)} ∥Pk+1 −P ∗(Wk)∥2 .(76)
Notice it is only required to havemin{R(W k)}>0for the inequality to hold.
By inequality (75), the last two terms in the RHS of (72) is bounded by
Fmax
α Eξk
h
∥Wk+1 −W k∥2
R(Pk)†
i
+E ξk[∥Wk+1 −W k∥2](77)
= Fmax
αRRL
min
Eξk

∥Wk+1 −W k∥2
+E ξk[∥Wk+1 −W k∥2]
(a)
≤ 2Fmax
αRRL
min
Eξk

∥Wk+1 −W k∥2
= 2β2Fmax
αRRL
min
∥Pk+1 ⊙F(W k)− |P k+1| ⊙G(W k)∥2
≤ 4β2Fmax
αRRL
min
∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2
+ 4β2Fmax
αRRL
min
∥Pk+1 ⊙F(W k)− |P k+1| ⊙G(W k)−(P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k))∥2
(b)
≤ 4β2Fmax
αRRL
min
∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2 + 4β2Fmax
αRRL
min
∥Pk+1 −P ∗(Wk)∥2.
where (a) holds if learning rate α is sufficiently small such that Fmax
αγRRL
min
≥1 ; (b) comes from the
Lipschitz continuity of the analog update (c.f. Lemma 3).
With all the inequalities and lemmas above, we are ready to prove the main conclusion in Theorem 3
now. Define a Lyapunov function by
Vk :=f( ¯Wk)−f ∗ +C∥W k −W ∗∥2.(78)
29

By Lemmas 5 and 6, we show thatV k has sufficient descent in expectation
Eξk[Vk+1] (79)
=E ξk

f( ¯Wk+1)−f ∗ +C∥W k+1 −W ∗∥2
≤f( ¯Wk)−f ∗ − α
4Fmax
∥∇f( ¯Wk)∥2
R(Pk) + 2ασ2

G(Pk)p
F(P k)

2
∞
+ 2α2LF 2
maxσ2
− α
8Fmax
∥∇f( ¯Wk)⊙F(P k) +|∇f( ¯Wk)| ⊙G(P k)∥2
+ 4β2Fmax
αRRL
min
∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2 + 4β2Fmax
αRRL
min
Eξk[∥Pk+1 −P ∗(Wk)∥2]
+C
 
∥Wk −W ∗∥2 − β
2γFmax
∥Wk −W ∗∥2
R(Wk) + 3βF 3
max
γmin{R(W k)} Eξk[∥Pk+1 −P ∗(Wk)∥2]
− βγ
2Fmax
∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2
!
≤V k − αRRL
min
4Fmax
∥∇f( ¯Wk)∥2 + 2ασ2

G(Pk)p
F(P k)

2
∞
+ 2α2LF 2
maxσ2
− α
8Fmax
∥∇f( ¯Wk)⊙F(P k) +|∇f( ¯Wk)| ⊙G(P k)∥2
−
 βγ
2Fmax
C− 4β2Fmax
αRRL
min

∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2
+
 3βF 3
max
γmin{R(W k)} C+ 4β2Fmax
αRRL
min

Eξk[∥Pk+1 −P ∗(Wk)∥2]− β
2γFmax
C∥W k −W ∗∥2
R(Wk).
LetC= 10βF 2
max
αRRL
minγ , which leads to the positive coefficient in front of∥P k+1 −P ∗(Wk)∥2, i.e.
Eξk[Vk+1] (80)
≤V k − αRRL
min
4Fmax
∥∇f( ¯Wk)∥2 + 2ασ2

G(Pk)p
F(P k)

2
∞
+ 2α2LF 2
maxσ2
− α
8Fmax
∥∇f( ¯Wk)⊙F(P k) +|∇f( ¯Wk)| ⊙G(P k)∥2
− β2Fmax
αRRL
min
∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2
+
 30β2F 5
max
αγmin{R(W k)}RRL
min
+ 4β2Fmax
αRRL
min

Eξk[∥Pk+1 −P ∗(Wk)∥2]− 5β2Fmax
αRRL
min
∥Wk −W ∗∥2
R(Wk).
Notice that the ∥Pk+1 −P ∗(Wk)∥2 appears in the RHS above, we also need the following lemma to
bound it in terms of∥P k −P ∗(Wk)∥2.
Lemma 7(Descent Lemma of Pk).Suppose Assumptions 1-2 and 4 hold. It holds for Tiki-Taka that
Eξk[∥Pk+1 −P ∗(Wk)∥2](81)
≤

1− αγµL
4(µ+L)

∥Pk −P ∗(Wk)∥2 + 2α(µ+L)F maxσ2
γµL

G(Pk)p
F(P k)

2
∞
+α 2F 2
maxσ2.
The proof of Lemma 7 is deferred to Section I.4. By Lemma 7, we bound the ∥Pk+1 −P ∗(Wk)∥2 in
terms of∥P k −P ∗(Wk)∥2 as
 30β2F 5
max
αγmin{R(W k)}RRL
min
+ 4β2Fmax
αRRL
min

Eξk[∥Pk+1 −P ∗(Wk)∥2](82)
30

(a)
≤ 32β2F 5
max
αγmin{R(W k)}RRL
min
Eξk[∥Pk+1 −P ∗(Wk)∥2]
≤ 32β2F 5
max
αγmin{R(W k)}RRL
min

1− α
4
µL
γ(µ+L)

∥Pk −P ∗(Wk)∥2
+ 32β2F 5
max
αγmin{R(W k)}RRL
min

2α(µ+L)F maxσ2
γµL

G(Pk)p
F(P k)

2
∞
+α 2F 2
maxσ2


≤ 32β2F 5
max
αγmin{R(W k)}RRL
min
∥Pk −P ∗(Wk)∥2 +O

β2σ2

G(Pk)p
F(P k)

2
∞
+αβ 2F 2
maxσ2


(b)
≤ 32β2F 5
max
αγmin{R(W k)}RRL
min
∥Pk −P ∗(Wk)∥2 +ασ 2

G(Pk)p
F(P k)

2
∞
+α 2LF 2
maxσ2
where (a) assumes 4β2Fmax
αRRL
min
≤ 2β2F 5
max
αγmin{R(W k)}RRL
min
with lost of generality to keep the formulations
simple since γmin{R(W k)} is typically small; (b) holds given α and β is sufficiently small. In
addition, the strong convexity of the objective (c.f. Assumption 4) implies that
αRRL
min
8Fmax
∇f( ¯Wk)
2
≥ αµ2RRL
min
8Fmax
 ¯Wk −W ∗2
= αµ2RRL
min
8Fmax
∥Wk +γP k −W ∗∥2 (83)
= αµ2γ2RRL
min
8Fmax
Pk − W ∗ −W k
γ

2
= αµ2γ2RRL
min
8Fmax
∥Pk −P ∗(Wk)∥2 .
Substituting (82) and (83) back into (80) yields
Eξk[Vk+1] (84)
≤V k − αRRL
min
8Fmax
∥∇f( ¯Wk)∥2 + 3ασ2

G(Pk)p
F(P k)

2
∞
+ 3α2LF 2
maxσ2
− α
8Fmax
∥∇f( ¯Wk)⊙F(P k) +|∇f( ¯Wk)| ⊙G(P k)∥2
− β2Fmax
αRRL
min
∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2
−
 αµ2γ2RRL
min
8Fmax
− 32β2F 5
max
αγmin{R(W k)}RRL
min

∥Pk −P ∗(Wk)∥2 − 5β2Fmax
αRRL
min
∥Wk −W ∗∥2
R(Wk)
=V k − αRRL
min
8Fmax
∥∇f( ¯Wk)∥2 + 3ασ2

G(Pk)p
F(P k)

2
∞
+ 3α2LF 2
maxσ2
− α
8Fmax
∥∇f( ¯Wk)⊙F(P k) +|∇f( ¯Wk)| ⊙G(P k)∥2
− αµ2γ3 min{R(Wk)}
512F 5maxRRL
min
∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2
− αµ2γ2RRL
min
16Fmax
∥Pk −P ∗(Wk)∥2 − 5αµ2γ3
512F 5maxRRL
min
∥Wk −W ∗∥2
R(Wk)
where the last step chooses the transfer learning rate by
β= αµγ
3
2
p
min{R(Wk)}RRL
min
16
√
2F 3max
.(85)
Rearranging inequality (79) above, we have
α
8Fmax
∥∇f( ¯Wk)⊙F(P k) +|∇f( ¯Wk)| ⊙G(P k)∥2 + α
8FmaxRRL
min
∥∇f( ¯Wk)∥2 (86)
+ αµ2γ3 min{R(Wk)}
512F 5maxRRL
min
∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2
31

+ 5αµ2γ3 min{R(Wk)}
512F 5maxRRL
min
∥Wk −W ∗∥2
R(Wk) + αµ2γ2RRL
min
16Fmax
∥Pk −P ∗(Wk)∥2
≤V k −E ξk[Vk+1] + 3α2LF 2
maxσ2 + 3ασ2

G(Pk)p
F(P k)

2
∞
.
Define the convergence metricE RL
K as
ERL
K := 1
K
K−1X
k=0
E

∥∇f( ¯Wk)⊙F(P k) +|∇f( ¯Wk)| ⊙G(P k)∥2 + 1
RRL
min
∥∇f( ¯Wk)∥2 (87)
+ µ2γ3 min{R(Wk)}
64F 4maxRRL
min
∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2
+ 5µ2γ3
64F 4maxRRL
min
∥Wk −W ∗∥2
R(Wk) + µ2γ2RRL
min
2 ∥Pk −P ∗(Wk)∥2

.
Taking expectation over all ξK, ξK−1 ,· · ·, ξ 0, averaging (86) over k from 0 to K−1 , and choosing
the parameterαasα=O

1
Fmax
q
V0
σ2LK

deduce that
ERL
K ≤8F max
 V0 −E[V k+1]
αK + 3αLF2
maxσ2

+ 24Fmaxσ2 × 1
K
K−1X
k=0

G(Pk)p
F(P k)

2
∞
(88)
≤8F max
 V0
αK + 3αLF2
maxσ2

+ 24Fmaxσ2 × 1
K
K−1X
k=0

G(Pk)p
F(P k)

2
∞
=O
 
F 2
max
r
V0σ2L
K
!
+ 24Fmaxσ2SRL
K .
The strong convexity of the objective (Assumption 4) implies that
V0 =f( ¯W0)−f ∗ +C∥W 0 −W ∗∥2 ≤

1 + 2C
µ

(f(W0)−f ∗).(89)
Plugging it back to the above inequality, we have
ERL
K =O
 
F 2
max
r
(f(W0)−f ∗)σ2L
K
!
+ 24Fmaxσ2SRL
K .(90)
The proof is completed.
I.2 Proof of Lemma 5: Descent of sequence ¯Wk
Lemma 5(Descent Lemma of ¯Wk).Suppose Assumptions 1–2 hold. It holds forTiki-Takathat
Eξk[f( ¯Wk+1)]≤f( ¯Wk)− α
4Fmax
∥∇f( ¯Wk)∥2
R(Pk) + 2ασ2

G(Pk)p
F(P k)

2
∞
+ 2α2LF 2
maxσ2
(72)
− αγ
8Fmax
∥∇f( ¯Wk)⊙F(P k) +|∇f( ¯Wk)| ⊙G(P k)∥2
+ Fmax
α Eξk
h
∥Wk+1 −W k∥2
R(Pk)†
i
+E ξk[∥Wk+1 −W k∥2].
Proof of Lemma 5.TheL-smooth assumption (Assumption 1) implies that
Eξk[f( ¯Wk+1)]≤f( ¯Wk) +E ξk[

∇f( ¯Wk), ¯Wk+1 − ¯Wk

] + L
2 Eξk[∥ ¯Wk+1 − ¯Wk∥2](91)
32

=f( ¯Wk) +γE ξk[

∇f( ¯Wk), Pk+1 −P k

]| {z }
(a)
+E ξk[

∇f( ¯Wk), Wk+1 −W k

]| {z }
(b)
+ L
2 Eξk[∥ ¯Wk+1 − ¯Wk∥2]
| {z }
(c)
.
Next, we will handle the each term in the RHS of (91) separately.
Bound of the second term (a).To bound term (a) in the RHS of (91), we leverage the assumption
that noise has expectation0(Assumption 2)
Eξk[

∇f( ¯Wk), Pk+1 −P k

](92)
=αE ξk
"*
∇f( ¯Wk)⊙
p
F(P k), Pk+1 −P k
α
p
F(P k)
+ (∇f( ¯Wk;ξ k)− ∇f( ¯Wk))⊙
p
F(P k)
+#
=− α
2 ∥∇f( ¯Wk)⊙
p
F(P k)∥2
− 1
2α Eξk



Pk+1 −P kp
F(P k)
+α(∇f( ¯Wk;ξ k)− ∇f( ¯Wk))⊙
p
F(P k)

2

+ 1
2α Eξk



Pk+1 −P kp
F(P k)
+α∇f( ¯Wk;ξ k)⊙
p
F(P k)

2
 .
The second term in the RHS of (92) can be bounded by
1
2α Eξk



Pk+1 −P kp
F(P k)
+α(∇f( ¯Wk;ξ k)− ∇f( ¯Wk))⊙
p
F(P k)

2
 (93)
= 1
2α Eξk



Pk+1 −P k +α(∇f( ¯Wk;ξ k)− ∇f( ¯Wk))⊙F(P k)p
F(P k)

2

≥ 1
2αFmax
Eξk

∥Pk+1 −P k +α(∇f( ¯Wk;ξ k)− ∇f( ¯Wk))⊙F(P k)∥2
.
The third term in the RHS of (92) can be bounded by variance decomposition and bounded variance
assumption (Assumption 2)
1
2α Eξk



Pk+1 −P kp
F(P k)
+α∇f( ¯Wk;ξ k)⊙
p
F(P k)

2
 (94)
≤ α
2 Eξk


|∇f( ¯Wk;ξ k)| ⊙ G(Pk)p
F(P k)

2

≤ α
2
|∇f( ¯Wk)| ⊙ G(Pk)p
F(P k)

2
+ ασ2
2

G(Pk)p
F(P k)

2
∞
.
Notice that the first term in the RHS of (92) and the second term in the RHS of (94) can be bounded
together
− α
2 ∥∇f( ¯Wk)⊙
p
F(P k)∥2 + α
2
|∇f( ¯Wk)| ⊙ G(Pk)p
F(P k)

2
(95)
=− α
2
X
d∈[D]

[∇f( ¯Wk)]2
d

[F(P k)]d − [G(Pk)]2
d
[F(P k)]d

=− α
2
X
d∈[D]

[∇f( ¯Wk)]2
d
[F(P k)]2
d −[G(P k)]2
d
[F(P k)]d

33

≤ − α
2Fmax
X
d∈[D]
 
[∇f( ¯Wk)]2
d
 
[F(P k)]2
d −[G(P k)]2
d

=− α
2Fmax
∥∇f( ¯Wk)∥2
R(Pk) ≤0.
Plugging (93) to (95) into (92), we bound the term (a) by
Eξk[

∇f( ¯Wk), Pk+1 −P k

](96)
≤ − α
2Fmax
∥∇f( ¯Wk)∥2
R(Pk) + ασ2
2

G(Pk)p
F(P k)

2
∞
− 1
2αFmax
Eξk
hPk+1 −P k +α(∇f( ¯Wk;ξ k)− ∇f( ¯Wk))⊙F(P k)
2i
.
Bound of the third term (b).By Young’s inequality, we have
Eξk[

∇f( ¯Wk), Wk+1 −W k

]≤ α
4Fmax
∥∇f( ¯Wk)∥2
R(Pk) + Fmax
α Eξk[∥Wk+1 −W k∥2
R(Pk)†].
(97)
Bound of the third term (c).Repeatedly applying inequality ∥U+V∥ 2 ≤2∥U∥ 2 + 2∥V∥ 2 for any
U, V∈R D, we have
L
2 Eξk[∥ ¯Wk+1 − ¯Wk∥2](98)
≤LE ξk[∥Wk+1 −W k∥2] +LE ξk[∥Pk+1 −P k∥2]
≤LE ξk[∥Wk+1 −W k∥2] + 2LEξk
hPk+1 −P k +α(∇f( ¯Wk;ξ k)− ∇f( ¯Wk))⊙F(P k)
2i
+ 2α2LEξk
h(∇f( ¯Wk;ξ k)− ∇f( ¯Wk))⊙F(P k)
2i
≤E ξk[∥Wk+1 −W k∥2] + 2LEξk
hPk+1 −P k +α(∇f( ¯Wk;ξ k)− ∇f( ¯Wk))⊙F(P k)
2i
+ 2α2LF 2
maxσ2
where the last inequality comes from the bounded variance assumption (Assumption 2)
2α2LEξk
h(∇f( ¯Wk;ξ k)− ∇f( ¯Wk))⊙F(P k)
2i
(99)
≤2α 2LF 2
maxEξk
h∇f( ¯Wk;ξ k)− ∇f( ¯Wk)
2i
≤2α 2LF 2
maxσ2.
Combination of the upper bound(a),(b), and(c).Plugging (96), (97), (98) into (91), we derive
Eξk[f( ¯Wk+1)]≤f( ¯Wk)− α
4Fmax
∥∇f( ¯Wk)∥2
R(Pk) + ασ2
2

G(Pk)p
F(P k)

2
∞
(100)
−
 1
2αFmax
−2L

Eξk
hPk+1 −P k +α(∇f( ¯Wk;ξ k)− ∇f( ¯Wk))⊙F(P k)
2i
+ Fmax
α Eξk
h
∥Wk+1 −W k∥2
R(Pk)†
i
+E ξk[∥Wk+1 −W k∥2] + 2α2LF 2
maxσ2.
We bound the fourth term in the RHS of (100) using the similar technique as in (66)
Eξk
hPk+1 −P k +α(∇f( ¯Wk;ξ k)− ∇f( ¯Wk))⊙F(P k)
2i
(101)
≥ α2
2 ∥∇f( ¯Wk)⊙F(P k) +|∇f( ¯Wk)| ⊙G(P k)∥2 −α 2Fmaxσ2

G(Pk)p
F(P k)

2
∞
.
34

Inequality (101) as well as the learning rate ruleα≤ 1
4LFmax
leads to the conclusion
Eξk[f( ¯Wk+1)]≤f( ¯Wk)− α
4Fmax
∥∇f( ¯Wk)∥2
R(Pk) + 2ασ2

G(Pk)p
F(P k)

2
∞
+ 2α2LF 2
maxσ2
(102)
− αγ
8Fmax
∥∇f( ¯Wk)⊙F(P k) +|∇f( ¯Wk)| ⊙G(P k)∥2
+ Fmax
α Eξk
h
∥Wk+1 −W k∥2
R(Pk)†
i
+E ξk[∥Wk+1 −W k∥2].
The proof is completed.
I.3 Proof of Lemma 6: Descent of sequenceW k
Lemma 6(Descent Lemma ofW k).It holds forTiki-Takathat
∥Wk+1 −W ∗∥2 ≤ ∥Wk −W ∗∥2 − β
2γFmax
∥Wk −W ∗∥2
R(Wk) (73)
− βγ
2Fmax
∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2
+ 2βF 3
max
γ ∥Pk+1 −P ∗(Wk)∥2
R(Wk)† + 2β2∥Pk+1 −P ∗(Wk)∥2.
Proof of Lemma 6.The proof begins from manipulating the norm∥W k+1 −W ∗∥2
∥Wk+1 −W ∗∥2 =∥W k −W ∗∥2 + 2⟨W k −W ∗, Wk+1 −W k⟩+∥W k+1 −W k∥2.(103)
Revisit that we interpret Pk as the residual of Wk, namely P ∗(W) := W ∗−W
γ . Therefore, we bound
the second term in the RHS of (103) by
2⟨W k −W ∗, Wk+1 −W k⟩(104)
= 2⟨W k −W ∗, βPk+1 ⊙F(W k)−β|P k+1| ⊙G(W k)⟩
= 2β⟨W k −W ∗, P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)⟩
+ 2β⟨W k −W ∗, Pk+1 ⊙F(W k)− |P k+1| ⊙G(W k)−(P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k))⟩.
The first term in the RHS of (104) is bounded by
2β⟨W k −W ∗, P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)⟩(105)
= 2β
*
(Wk −W ∗)⊙
p
F(W k), P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)p
F(W k)
+
=− 2β
γ
D
(Wk −W ∗)⊙
p
F(W k),(W k −W ∗)⊙
p
F(W k)
E
+ 2β
γ
*
(Wk −W ∗)⊙
p
F(W k),|W k −W ∗| ⊙ G(Wk)p
F(W k)
+
(a)
=− β
γ ∥(Wk −W ∗)⊙
p
F(W k)∥2 + β
γ
|Wk −W ∗| ⊙ G(Wk)p
F(W k)

2
− β
γ
(Wk −W ∗)⊙
p
F(W k) +|W k −W ∗| ⊙ G(Wk)p
F(W k)

2
(b)
≤ − β
γFmax
∥Wk −W ∗∥2
R(Wk) − β
γ
(Wk −W ∗)⊙
p
F(W k) +|W k −W ∗| ⊙ G(Wk)p
F(W k)

2
(c)
≤ − β
γFmax
∥Wk −W ∗∥2
R(Wk) − βγ
Fmax
∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2
35

where (a) leverages the equality 2⟨U, V⟩=∥U∥ 2 − ∥V∥ 2 − ∥U−V∥ 2 for any U, V∈R D, (b) is
achieved by similar technique (62), and(c)comes from
− β
γ
(Wk −W ∗)⊙
p
F(W k) +|W k −W ∗| ⊙ G(Wk)p
F(W k)

2
(106)
=−βγ

1p
F(W k)
⊙
 Wk −W ∗
γ ⊙F(W k) +

Wk −W ∗
γ
 ⊙G(W k)

2
≤ − βγ
Fmax
∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2 .
The second term in the RHS of (104) is bounded by the Lipschitz continuity of analog update (c.f.
Lemma 3)
2β
γ ⟨Wk −W ∗, Pk+1 ⊙F(W k)− |P k+1| ⊙G(W k)−(P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k))⟩
≤ β
2γFmax
∥Wk −W ∗∥2
R(Wk) + 2βFmax
γ (107)
× ∥Pk+1 ⊙F(W k)− |P k+1| ⊙G(W k)−(P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k))∥2
R(Wk)†
≤ β
2γFmax
∥Wk −W ∗∥2
R(Wk) + 2βF 3
max
γ ∥Pk+1 −P ∗(Wk)∥2
R(Wk)† .
Substituting (105) and (107) into (104), we bound the second term in the RHS of (103) by
2⟨W k −W ∗, Wk+1 −W k⟩(108)
≤ − β
γFmax
∥Wk −W ∗∥2
R(Wk) − βγ
Fmax
∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2
+ 2βF 3
max
γ ∥Pk+1 −P ∗(Wk)∥2
R(Wk)† .
The third term in the RHS of (103) is bounded by the Lipschitz continuity of analog update (c.f.
Lemma 3)
∥Wk+1 −W k∥2 =β 2∥Pk+1 ⊙F(W k)− |P k+1| ⊙G(W k)∥2 (109)
≤2β 2∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2
+ 2β2∥Pk+1 ⊙F(W k)− |P k+1| ⊙G(W k)−(P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k))∥2
≤2β 2∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2 + 2β2∥Pk+1 −P ∗(Wk)∥2.
Plugging (108) and (109) into (103) yields
∥Wk+1 −W ∗∥2 ≤ ∥Wk −W ∗∥2 − β
2γFmax
∥Wk −W ∗∥2
R(Wk) (110)
−
 βγ
Fmax
−2β 2

∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2
+ 2βF 3
max
γ ∥Pk+1 −P ∗(Wk)∥2
R(Wk)† + 2β2∥Pk+1 −P ∗(Wk)∥2.
Notice the learning rateβis chosen asβ≤ γ
2Fmax
, we have
∥Wk+1 −W ∗∥2 ≤ ∥Wk −W ∗∥2 − β
2γFmax
∥Wk −W ∗∥2
R(Wk) (111)
− βγ
2Fmax
∥P ∗(Wk)⊙F(W k)− |P ∗(Wk)| ⊙G(W k)∥2
+ 2βF 3
max
γ ∥Pk+1 −P ∗(Wk)∥2
R(Wk)† + 2β2∥Pk+1 −P ∗(Wk)∥2
which completes the proof.
36

I.4 Proof of Lemma 7: Descent of sequenceP k
Lemma 7(Descent Lemma of Pk).Suppose Assumptions 1-2 and 4 hold. It holds for Tiki-Taka that
Eξk[∥Pk+1 −P ∗(Wk)∥2](81)
≤

1− αγµL
4(µ+L)

∥Pk −P ∗(Wk)∥2 + 2α(µ+L)F maxσ2
γµL

G(Pk)p
F(P k)

2
∞
+α 2F 2
maxσ2.
Proof of Lemma 7.The proof begins from manipulating the norm∥P k+1 −P ∗(Wk)∥2
∥Pk+1 −P ∗(Wk)∥2 =∥P k −P ∗(Wk)∥2 + 2⟨P k −P ∗(Wk), Pk+1 −P k⟩+∥P k+1 −P k∥2.
(112)
To bound the second term, we need the following equality.
2Eξk[⟨Pk −P ∗(Wk), Pk+1 −P k⟩](113)
=−2αE ξk[

Pk −P ∗(Wk),∇f( ¯Wk;ξ k)⊙F(P k)− |∇f( ¯Wk;ξ k)| ⊙G(P k)

]
=−2αE ξk[

Pk −P ∗(Wk),∇f( ¯Wk;ξ k)⊙F(P k)

]
+ 2αEξk[

Pk −P ∗(Wk),|∇f( ¯Wk;ξ k)| ⊙G(P k)

]
=−2α

Pk −P ∗(Wk),∇f( ¯Wk)⊙F(P k)

+ 2α

Pk −P ∗(Wk),|∇f( ¯Wk)| ⊙G(P k)

+ 2αEξk[

Pk −P ∗(Wk),(|∇f( ¯Wk)| − |∇f( ¯Wk;ξ k)|)⊙G(P k)

]
=−2α

Pk −P ∗(Wk),∇f( ¯Wk)⊙F(P k)− |∇f( ¯Wk)| ⊙G(P k)

| {z }
(T1)
+ 2αE ξk[

Pk −P ∗(Wk),(|∇f( ¯Wk)| − |∇f( ¯Wk;ξ k)|)⊙G(P k)

]| {z }
(T2)
Upper bound of the first term (T1) .With Lemma 4, the second term in the RHS of (112) can be
bounded by
−2α

Pk −P ∗(Wk),∇f( ¯Wk)⊙F(P k)− |∇f( ¯Wk)| ⊙G(P k)

(114)
=−2α

Pk −P ∗(Wk),∇f( ¯Wk)⊙q s(Pk)

≤ −2αC k,+

Pk −P ∗(Wk),∇f( ¯Wk)

+ 2αCk,−

|Pk −P ∗(Wk)|,|∇f( ¯Wk)|

whereC k,+ andC k,− are defined by
Ck,+ :=1
2

max
i∈[D]
{qs([Pk]i)}+ min
i∈[D]
{qs([Pk]i)}

,(115)
Ck,− :=1
2

max
i∈[D]
{qs([Pk]i)} −min
i∈[D]
{qs([Pk]i)}

.(116)
In the inequality above, the first term can be bounded by the strong convexity of f. Let φ(P) :=
f(W+γP) which is γ2L-smooth and γ2µ-strongly convex. It can be verified thatφ(P) has gradient
∇φ(Pk) =∇ Pk f(W k +γP k) =γ∇f( ¯Wk) and optimal point P ∗(W) . Leveraging Theorem 2.1.9
in [83], we have

∇f( ¯Wk), Pk −P ∗(Wk)

= 1
γ ⟨∇φ(Pk), Pk −P ∗(Wk)⟩(117)
≥ 1
γ
 γ2µ·γ 2L
γ2µ+γ 2L ∥Pk −P ∗(Wk)∥2 + 1
γ2µ+γ 2L ∥∇φ(Pk)∥2

= γµL
µ+L ∥Pk −P ∗(Wk)∥2 + 1
γ(µ+L) ∥∇f( ¯Wk)∥2.
The second term in theRHS of (114) can be bounded by Young’s inequality2⟨x, y⟩ ≤u∥x∥ 2+ 1
u ∥y∥2
with anyu >0andx, y∈R D
2αCk,−

|Pk −P ∗(Wk)|,|∇f( ¯Wk)|

(118)
37

≤
αC2
k,−γ(µ+L)
Ck,+
∥Pk −P ∗(Wk)∥2 + αCk,+
γ(µ+L) ∥∇f( ¯Wk)∥2
where u is chosen to align the coefficient in front of ∥∇f( ¯Wk)∥2. Therefore, (T1) in (114) becomes
−2α

Pk −P ∗(Wk),∇f( ¯Wk)⊙F(P k)− |∇f( ¯Wk)| ⊙G(P k)

(119)
≤ −
 
2αγµLCk,+
µ+L −
αC2
k,−γ(µ+L)
Ck,+
!
∥Pk −P ∗(Wk)∥2 − αCk,+
γ(µ+L) ∥∇f( ¯Wk)∥2.
Upper bound of the second term (T2) .Leveraging the Young’s inequality 2⟨x, y⟩ ≤u∥x∥ 2 +
1
u ∥y∥2 with anyu >0andx, y∈R D, we have
2αEξk[

Pk −P ∗(Wk),(|∇f( ¯Wk)| − |∇f( ¯Wk;ξ k)|)⊙G(P k)

](120)
= 2αEξk
"*
(Pk −P ∗(Wk))⊙
p
F(P k),(|∇f( ¯Wk)| − |∇f( ¯Wk;ξ k)|)⊙ G(Pk)p
F(P k)
+#
(a)
≤ αγµLCk,+
(µ+L)F max
∥(Pk −P ∗(Wk))⊙
p
F(P k)∥2
+ α(µ+L)F max
γµLCk,+
Eξk


(|∇f( ¯Wk)| − |∇f( ¯Wk;ξ k)|)⊙ G(Pk)p
F(P k)

2

(b)
≤ αγµLCk,+
(µ+L)F max
∥(Pk −P ∗(Wk))⊙
p
F(P k)∥2
+ α(µ+L)F max
γµLCk,+
Eξk


(|∇f( ¯Wk)− ∇f( ¯Wk;ξ k)|)⊙ G(Pk)p
F(P k)

2

(c)
= αγµLCk,+
(µ+L)F max
∥(Pk −P ∗(Wk))⊙
p
F(P k)∥2 + α(µ+L)F maxσ2
γµLCk,+

G(Pk)p
F(P k)

2
∞
(d)
≤ αγµLCk,+
µ+L ∥Pk −P ∗(Wk)∥2 + α(µ+L)F maxσ2
γµLCk,+

G(Pk)p
F(P k)

2
∞
where (a) choose u >0 to align the coefficient in front of ∥Pk −P ∗(Wk)∥2 in the RHS of (119),
(b) applies ||x| − |y|| ≤ |x−y| for any x, y∈R , (c) uses the bounded variance assumption (c.f.
Assumption 2), and(d)leverages the fact thatF(P k)is bounded byF max element-wise.
Combining the upper bound of(T1)and(T2), we bound (113) by
2Eξk[⟨Pk −P ∗(Wk), Pk+1 −P k⟩](121)
≤ −
 
αγµLCk,+
µ+L −
αC2
k,−γ(µ+L)
Ck,+
!
∥Pk −P ∗(Wk)∥2
− αCk,+
γ(µ+L) ∥∇f( ¯Wk)∥2 + α(µ+L)F maxσ2
γµLCk,+

G(Pk)p
F(P k)

2
∞
≤ − αγµLCk,+
2(µ+L) ∥Pk −P ∗(Wk)∥2 − αCk,+
γ(µ+L) ∥∇f( ¯Wk)∥2 + α(µ+L)F maxσ2
γµLCk,+

G(Pk)p
F(P k)

2
∞
where the last inequality holds when γ is sufficiently large, Pk as well as Ck,− are sufficiently closed
to 0, and the following inequality holds
(µ+L)
C2
k,−
C2
k,+
≤ µL
2(µ+L) .(122)
38

Furthermore, the last term in the RHS of (112) can be bounded by the Lipschitz continuity of analog
update (c.f. Lemma 3) and the bounded variance assumption (c.f. Assumption 2)
Eξk[∥Pk+1 −P k∥2] =E ξk[∥α∇f( ¯Wk;ξ k)⊙F(P k)−α|∇f( ¯Wk;ξ k)| ⊙G(P k)∥2](123)
≤α 2F 2
maxEξk[∥∇f( ¯Wk;ξ k)∥2]
=α 2F 2
max∥∇f( ¯Wk)∥2 +α 2F 2
maxσ2
≤ αCk,+
γ(µ+L) ∥∇f( ¯Wk)∥2 +α 2F 2
maxσ2
where the last inequality holds ifαis sufficiently small.
Plugging inequality (121) and (123) above into (112) yields
Eξk[∥Pk+1 −P ∗(Wk)∥2](124)
≤

1− αγµLCk,+
2(µ+L)

∥Pk −P ∗(Wk)∥2 + α(µ+L)F maxσ2
γµLCk,+

G(Pk)p
F(P k)

2
∞
+α 2F 2
maxσ2.
By definition of Ck,+, when the saturation degree of Pk is properly limited, we have Ck,+ ≥ 1
2.
Therefore, we have
Eξk[∥Pk+1 −P ∗(Wk)∥2](125)
≤

1− αγµL
4(µ+L)

∥Pk −P ∗(Wk)∥2 + 2α(µ+L)F maxσ2
γµL

G(Pk)p
F(P k)

2
∞
+α 2F 2
maxσ2
which completes the proof.
I.5 Proof of Corollary 1: Exact convergence ofTiki-Taka
Corollary 1(Exact convergence of Residual Learning).Under Assumption 5 and the conditions
in Theorem 3, ifγ≥Ω(R −1/5
min ), it holds thatE RL
K ≤O
p
σ2L/K

.
Proof of Corollary 1.From Theorem 3, we have
∥∇f( ¯Wk)∥2 ≤O(E RL
K )≤O
 
F 2
max
r
(f(W0)−f ∗)σ2L
K
!
+ 24Fmaxσ2SRL
K .(126)
Under the zero-shift assumption (Assumption 5) and the Lipschitz continuity of the response functions,
it holds directly that

G(Pk)p
F(P k)

2
∞
≤

G(Pk)p
F(P k)

2
=

G(Pk)p
F(P k)
− G(0)p
F(0)

2
≤L 2
S∥Pk∥2 (127)
whereL S ≥0is a constant. Using∥U+V∥ 2 ≤2∥U∥ 2 + 2∥V∥ 2 for anyU, V∈R D, we have
∥Pk∥2 ≤2∥P k −P ∗(Wk)∥2 + 2∥P ∗(Wk)∥2 = 2∥Pk −P ∗(Wk)∥2 + 2
γ2 ∥Wk −W ∗∥2 (128)
where the last inequality comes from the definition of P ∗(Wk), as well as the definition of P ∗(W) .
Recall that convergence metricE RL
K defined in (87) is in the order of
ERL
K ≥Ω

γ3∥Wk −W ∗∥2
R(Wk) +γ 2 ∥Pk −P ∗(Wk)∥2

(129)
≥Ω

min{R(Wk)}γ3∥Wk −W ∗∥2 +γ 2 ∥Pk −P ∗(Wk)∥2

≥Ω
 1
γ2 ∥Wk −W ∗∥2 +γ 2 ∥Pk −P ∗(Wk)∥2

.
39

Therefore, we have
SRL
K = 1
K
KX
k=0

G(Pk)p
F(P k)

2
∞
≤ 1
K
KX
k=0

2∥Pk −P ∗(Wk)∥2 + 2
γ2 ∥Wk −W ∗∥2

≤O(E RL
K )
(130)
where the last inequality holds if γ is sufficiently large. Considering that, ERL
K −S RL
K ≥Ω(E RL
K )≥0
and the conclusion is reached directly from Theorem 3.
J Proof of Theorem 6: Convergence ofAnalog GD
In Section 3.2, we showed that Analog SGD converges to a critical point inexactly with asymptotic
error proportional to the noise variance σ2. Intuitively, without the effect of noise, Analog GD
converges to the critical point. Define the convergence metric by
EAGD
K := 1
K
K−1X
k=0

∥∇f(W k)⊙F(W k)− |∇f(W k)| ⊙G(W k)∥2 +∥∇f(W k)∥2
R(Wk)

.(131)
The convergence is guaranteed by the following theorem.
Theorem 6(Convergence ofAnalog GD).Under Assumption 1–2, it holds that
EAGD
K ≤ 8L(f(W0)−f ∗)F 2
max
K .(132)
Further, ifR ASGD
min := mink∈[K] min{Q+(Wk)Q−(Wk)}>0, it holds that
1
K
K−1X
k=0
∥∇f(W k)∥2 ≤ 2L(f(W0)−f ∗)F 2
max
KR ASGD
min
.(133)
Proof of Theorem 6.TheL-smooth assumption (Assumption 1) implies that
f(W k+1)≤f(W k) +⟨∇f(W k), Wk+1 −W k⟩+ L
2 ∥Wk+1 −W k∥2 (134)
=f(W k)− α
2 ∥∇f(W k)⊙
p
F(W k)∥2 − 1
Fmax
 1
2α − LFmax
2

∥Wk+1 −W k∥2
+ 1
2α

Wk+1 −W kp
F(W k)
+α∇f(W k)⊙
p
F(W k)

2
where the second inequality comes from
⟨∇f(W k), Wk+1 −W k⟩=α
*
∇f(W k)⊙
p
F(W k), Wk+1 −W k
α
p
F(W k)
+
(135)
=− α
2 ∥∇f(W k)⊙
p
F(W k)∥2 − 1
2α

Wk+1 −W kp
F(W k)

2
+ 1
2α

Wk+1 −W kp
F(W k)
+α∇f(W k)⊙
p
F(W k)

2
as well as the inequality

Wk+1 −W kp
F(W k)

2
≥ 1
Fmax
∥Wk+1 −W k∥2.(136)
The third term in the RHS of (134) can be bounded by
1
2α

Wk+1 −W kp
F(W k)
+α∇f(W k)⊙
p
F(W k)

2
= α
2
|∇f(W k)| ⊙ G(Wk)p
F(W k)

2
.(137)
40

Define the saturation vectorR(W k)∈R D by
R(Wk) :=F(W k)⊙2 −G(W k)⊙2 = (F(W k) +G(W k))⊙(F(W k)−G(W k))(138)
=q +(Wk)⊙q −(Wk).
Notice the following inequality is valid
− α
2 ∥∇f(W k)⊙
p
F(W k)∥2 + α
2
|∇f(W k)| ⊙ G(Wk)p
F(W k)

2
(139)
=− α
2
X
d∈[D]

[∇f(W k)]2
d

[F(W k)]d − [G(Wk)]2
d
[F(W k)]d

=− α
2
X
d∈[D]

[∇f(W k)]2
d
[F(W k)]2
d −[G(W k)]2
d
[F(W k)]d

≤ − α
2Fmax
X
d∈[D]
 
[∇f(W k)]2
d
 
[F(W k)]2
d −G(W k)]2
d

=− α
2Fmax
∥∇f(W k)∥2
Sk ≤0.
Substituting (137) and (139) back into (134) yields
1
Fmax
 1
2α − LFmax
2

∥Wk+1 −W k∥2 ≤f(W k)−f(W k+1).(140)
Noticing that ∥Wk+1 −W k∥2 =α 2∥∇f(W k)⊙F(W k)− |∇f(W k)| ⊙G(W k)∥2 and averaging
forkfrom0toK−1, we have
EAGD
K = 1
K
K−1X
k=0

∥∇f(W k)⊙F(W k)− |∇f(W k)| ⊙G(W k)∥2 +∥∇f(W k)∥2
R(Wk)

(141)
≤ 2(f(W0)−f(W K+1))Fmax
α(1−αLF max)K ≤ 8L(f(W0)−f ∗)F 2
max
K
where the last inequality choose α= 1
2LFmax
. Further, if the degree of saturation is bounded,
(134)–(139) implies that
αRAGD
min
2 ∥∇f(W k)∥2 ≤ α
2 ∥∇f(W k)∥2
R(Wk) ≤f(W k)−f(W k+1).(142)
Averaging (142) forkfrom0toKdeduce that
1
K
K−1X
k=0
∥∇f(W k)∥2 ≤ 2(f(W0)−f(W K+1))Fmax
αKR AGD
min
≤ 2L(f(W0)−f ∗)F 2
max
KR AGD
min
(143)
where the second inequality holds because the learning rate is selected asα= 1
LFmax
.
K Simulation Details and Additional Results
This section provides details about the experiments in Section 6. All simulation is performed
under the PYTORCH framework https://github.com/pytorch/pytorch. The analog training
algorithms, including Analog SGD and Tiki-Taka, are provided by the open-source simulation
toolkit AIHWKIT[44], which has MIT license; seegithub.com/IBM/aihwkit.
Optimizer.The digital SGD optimizer is implemented by FloatingPointRPUConfig in
AIHWKIT , which is equivalent to the SGD implemented in PYTORCH . The Analog SGD is im-
plemented by selecting SingleRPUConfig as configuration and Tiki-Taka optimizers are imple-
mented byUnitCellRPUConfigwithTransferCompounddevices in AIHWKIT.
41

Hardware.We conduct our experiments on one NVIDIA RTX 3090 GPU, which has 24GB memory
and a maximum power of 350W. The simulations take from 30 minutes to 5 hours, depending on
model sizes and datasets.
Statistical Significance.The simulation data reported in all tables is repeated three times. The
randomness originates from the data shuffling, random initialization, and random noise in the analog
hardware. The mean and standard deviation are calculated usingstatisticslibrary.
K.1 Power and Exponential Response Functions
Thepower responseis a power function, given by
q+(w) =

1− w
τ
γres
, q −(w) =

1 + w
τ
γres
(144)
which can be changed by adjusting the dynamic radius τ and shape parameter γres. We also consider
theexponential response, whose response is an exponential function, defined by
q+(w) = exp (γres(1−w/τ))−1
exp (γres)−1 , q −(w) = exp (γres(1 +w/τ))−1
exp (γres)−1 .(145)
It could be checked that the boundary of their dynamic ranges are τ max =τ and τ min =−τ , while
the symmetric point is 0, as required by Corollary 1. Figure 5 illustrates how the response functions
change with differentγ res.
w
Power Step: Response Functions
w
Exponential Step: Response Functions
w
Power Step: Sym/Asym Components
w
Exponential Step: Sym/Asym Components
q+ (w)
q (w)
res = 0.2
res = 1.0
res = 2.0
F(w)
G(w)
res = 0.2
res = 1.0
res = 2.0
Figure 5: Examples of response functions. The dependence of the response function on the weight w
can grow at various rates, including but not limited to power (Left) or exponential rate (Right). τ
is the radius of the dynamic range, and γres is a parameter that needs to be determined by physical
measurements.
K.2 Least squares problem
In Figure 2 (see Section 1.1), we consider the least squares problem on a synthetic dataset and a
ground truthW ∗ ∈R D. The problem can be formulated by
min
W∈R D
f(W) := 1
2 ∥AW−b∥ 2 = 1
2 ∥A(W−W ∗)∥2.(146)
The elements of W ∗ are sampled from a Gaussian distribution with mean 0 and variance σ2
W ∗.
Consider a matrix A∈R Dout×D of size D= 50 and Dout = 100 whose elements are sampled from a
Gaussian distribution with variance σ2
A. The label b∈R Dout is generated by b=AW ∗ where W ∗
are sampled from a standard Gaussian distribution with σ2
W ∗. The response granularity ∆wmin=1e-4
whileτ= 3.5. The maximum bit length is 8. The variance are set asσ 2
A = 1.002,σ 2
W ∗ = 0.52.
42

K.3 Classification problem
We conduct training simulations of image classification tasks on a series of real datasets. In the
implementation ofTiki-Taka, only a few columns or rows ofP k are transferred per time toW k in
the recursion (11) to balance the communication and computation. In our simulations, we transfer 1
column every time. The response granularity is set as∆w min =1e-3.
The other setting follows the settings ofAIHWKIT , including output noise (0.5 % of the quantization
bin width), quantization and clipping (output range set 20, output noise 0.1, and input and output
quantization to 8 bits). Noise and bound management techniques are used in [71]. A learnable scaling
factor is set after each analog layer, which is updated using SGD.
3-FC / MNIST.Following the setting in [ 16], we train a model with 3 fully connected layers. The
hidden sizes are 256 and 128. The activation functions are Sigmoid. The learning rates are α= 0.1
for Digital SGD, α= 0.05, β= 0.01 for Analog SGD and Tiki-Taka. The batch size is 10 for all
algorithms. In Figure 4, the power response functions with γres = 0.5 are used, and various τ are
used as indicated in the legend.
CNN / MNIST.We train a convolution neural network, which contains 2-convolutional layers,
2-max-pooling layers, and 2-fully connected layers. The activation functions are Tanh. The first two
convolutional layers use 5×5 kernels with 16 and 32 kernels, respectively. Each convolutional layer
is followed by a subsampling layer implemented by the max pooling function over non-overlapping
pooling windows of size 2 × 2. The output of the second pooling layer, consisting of 512 neuron
activations, feeds into a fully connected layer consisting of 128 tanh neurons, which is then connected
into a 10-way softmax output layer. The learning rates are set as α= 0.1 for Digital SGD,
α= 0.05, β= 0.01 for Analog SGD are Residual Learning/Tiki-Taka. The batch size is 8 for
all algorithms. In Figure 4, the power response functions with γres = 0.5 are used, and various τ are
used as indicated in the legend.
ResNet & MobileNet / CIFAR10 & CIFAR100.We train different models from the ResNet family,
including ResNet18, 34, and 50. The base model is pre-trained on ImageNet dataset. The last fully con-
nected layer is replaced by an analog layer. The learning rates are set as α= 0.075 for Digital SGD,
α= 0.075, β= 0.01 for Analog SGD, Residual Learning/Tiki-Taka, Tiki-Taka v2, and
Residual Learning v2 . Tiki-Taka adopts γ= 0.4 unless stated otherwise. The batch size is 128
for all algorithms.
K.4 Additional performance on real datasets
We train different models from the MobileNet family, including MobileNet2, MobileNetV3L,
MobileNetV3S. The base model is pre-trained on ImageNet dataset. The last fully connected
layer is replaced by an analog layer. The learning rates are set as α= 0.075 for Digital SGD,
α= 0.075, β= 0.01 for Analog SGD or Tiki-Taka. Tiki-Taka adopts γ= 0.4 unless stated
otherwise. The batch size is 128 for all algorithms. Power response function with γres = 4.0 and
τ= 0.05is used in the simulations.
CIFAR10/CIFAR100 ResNet.We fine-tune three models from the ResNet family with different
scales on CIFAR10/CIFAR100 datasets. The power response functions with γres = 3.0 and τ= 0.1 ,
and the exponential response functions with γres = 4.0 and τ= 0.1 are used, whose results are shown
in Table 1 and 3, respectively. The results show that the Tiki-Taka outperforms Analog SGD by
about 1.0% in most of the cases in ResNet34/50, and the gap even reaches about10.0% for ResNet18
training on the CIFAR100 dataset.
CIFAR10/CIFAR100 MobileNet.We fine-tune three MobileNet models with different scales on
CIFAR10/CIFAR100 datasets. The response function is set as the power response with the parameter
γres = 4.0 and τ= 0.05 , whose results are shown in Table 4. In the simulations, the accuracy of
Analog SGD drops significantly by about 10% in most cases, while Tiki-Taka remains comparable
to theDigital SGDwith only a slight drop.
K.5 Ablation study on cycle variation
To verify the conclusion of Theorem 4 that the error introduced by cycle variation is a higher-order
term, we conduct a numerical simulation training on an image classification task on the MNIST
43

CIFAR10
DSGD ASGD TT/RL TTv2 RLv2
ResNet18 95.43±0.13 84.47±3.40 94.81±0.09 95.31±0.05 95.12±0.14
ResNet34 96.48±0.02 95.43±0.12 96.29±0.12 96.60±0.05 96.42±0.13
ResNet50 96.57±0.10 94.36±1.16 96.34±0.04 96.63±0.09 96.56±0.08
CIFAR100
DSGD ASGD TT/RL TTv2 RLv2
ResNet18 81.12±0.25 68.98±1.01 76.17±0.23 78.56±0.29 79.83±0.13
ResNet34 83.86±0.12 78.98±0.55 80.58±0.11 81.81±0.15 82.85±0.19
ResNet50 83.98±0.11 79.88±1.26 80.80±0.22 82.82±0.33 83.90±0.20
Table 3: Fine-tuning ResNet models with theexponential responseon CIFAR10/100 datasets.
Test accuracy is reported. DSGD, ASGD, and TT represent Digital SGD, Analog SGD, Tiki-Taka,
respectively.
dataset using Fully-connected network (FCN) or convolution neural network (CNN) network. In the
pulse update (26), the parameter σc is varied from 10% to 120%, where the noise signal is already
larger than the response function signal itself. The results are shown in Table 5. The results show
that the test accuracy of both Analog SGD and Tiki-Taka is not significantly affected by the cycle
variation, which complies with the theoretical analysis.
K.6 Ablation study on various response functions
We also train a FCN model on the MNIST dataset under various response functions. As shown in
the figure, larger γres leads to a steeper response function. The results are shown in Table 6. The
accuracy <15.00 in the table implies that Analog SGD fails completely at all trials, which is close to
random guess. The results show that Analog SGD works well only when the asymmetric is mild, i.e.
γres is small and τ is large, while Tiki-Taka outperforms Analog SGD and achieves comparable
accuracy withDigital SGD.
K.7 Ablation study onγ
We conduct a series of simulations to study the impact of mixing coefficientγ in (10) on CIFAR10
or CIFAR100 dataset in the ResNet training tasks. The results are presented in Figure 6, which
shows that Tiki-Taka achieves a great accuracy gain from increasing γ from 0 to 0.1, while the
gain saturates after that. Therefore, we conclude that Tiki-Taka benefits from a non-zero γ, and the
performance is robust to theγselection.
CIFAR10
DSGD ASGD TT/RL TTv2 RLv2
MobileNetV2 95.28±0.20 94.34±0.27 95.05±0.11 95.20±0.14 95.26±0.03
MobileNetV3S 94.45±0.10 80.66±6.18 93.65±0.24 93.54±0.06 93.79±0.00
MobileNetV3L 95.95±0.08 80.79±2.97 95.39±0.27 95.27±0.09 95.33±0.08
CIFAR100
DSGD ASGD TT/RL TTv2 RLv2
MobileNetV2 80.60±0.18 63.41±1.20 73.33±0.94 78.41±0.15 79.60±0.10
MobileNetV3S 78.94±0.05 51.79±1.05 71.14±0.93 74.51±0.37 75.39±0.00
MobileNetV3L 82.16±0.26 66.80±1.40 78.81±0.52 79.56±0.10 80.18±0.07
Table 4: Fine-tuning MobileNet models withpower responseon CIFAR10/100 datasets. Test accuracy
is reported.DSGD,ASGD, andTTrepresentDigital SGD,Analog SGD,Tiki-Taka, respectively.
44

FCN CNN
DSGD ASGD TT DSGD ASGD TT
σc = 10%
98.17±0.05
97.22±0.21 97.66±0.04
99.09±0.04
92.68±0.45 98.74±0.07
σc = 30% 96.97±0.12 97.07±0.12 93.36±0.55 98.89±0.05
σc = 60% 96.33±0.21 97.70±0.09 93.07±0.53 98.68±0.09
σc = 90% 95.99±0.15 97.44±0.15 91.87±0.48 98.92±0.02
σc = 120% 96.19±0.20 96.97±0.20 91.57±0.58 98.85±0.04
Table 5: Test accuracy comparison under different cycle variation levelsσc on MNIST dataset. DSGD,
ASGD, andTTrepresentDigital SGD,Analog SGD,Tiki-Taka, respectively
DSGD Power response Exponential response
ASGD TT/RL ASGD TT/RL
γres = 0.5
τ= 0.6
98.17±0.05
96.01±0.26 96.92±0.19 <15.00 97.27±0.07
τ= 0.7 97.40±0.15 97.05±0.05 <15.00 97.39±0.15
τ= 0.8 97.38±0.10 96.82±0.17 94.00±0.63 97.16±0.16
γres = 1.0
τ= 0.6 <15.00 97.39±0.05 <15.00 97.46±0.08
τ= 0.7 <15.00 97.33±0.05 <15.00 97.49±0.04
τ= 0.8 <15.00 97.34±0.09 <15.00 97.25±0.16
γres = 2.0
τ= 0.6 <15.00 96.93±0.15 <15.00 97.19±0.16
τ= 0.7 <15.00 97.27±0.02 <15.00 97.72±0.07
τ= 0.8 <15.00 97.18±0.04 <15.00 97.06±0.10
Table 6: Test accuracy comparison under different response function parameters τ and γres for
FCN training on MNIST dataset with power or exponential response functions. DSGD, ASGD, and TT
representDigital SGD,Analog SGD,Tiki-Taka, respectively.
0.0 0.1 0.2 0.3 0.4
93
94
95
96Accuracy
 Resnet18
Resnet34
Resnet50
0.0 0.1 0.2 0.3 0.4
76
78
80
82Accuracy
Resnet18
Resnet34
Resnet50
Figure 6: The test accuracy of ResNet family models after 100 epochs trained by Tiki-Taka under
differentγin (10);(Left)CIFAR10.(Right)CIFAR100.
L Broader Impact
This paper focuses on developing a theoretical analysis for gradient-based training algorithms on a
class of generic AIMC hardware, which can be leveraged to boost both energy and computational
efficiency of training. While such efficiency gains could, in principle, enable broader and potentially
unintended uses of machine learning models, we do not identify any specific societal risks that need
to be highlighted in this context.
45
