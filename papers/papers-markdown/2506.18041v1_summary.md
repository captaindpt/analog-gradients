# Fully Analog End-to-End Online Training with Real-time Adaptability on Integrated Photonic Platform

**Authors:** Zhimu Guo, A. Aadhi, Adam N. McCaughan, Alexander N. Tait, Nathan Youngblood, Sonia M. Buckley, Bhavin J. Shastri
**Institutions:** Queen's University, NIST, University of Pittsburgh
**Year:** 2025
**Paper ID:** 2506.18041v1

## Core Thesis

This paper demonstrates the **first fully analog end-to-end adaptive learning system** on a foundry-manufactured silicon photonic integrated circuit. Using the **Multiplexed Gradient Descent (MGD)** algorithm, the system performs in-situ, on-the-fly training at gigabaud rates with real-time adaptation to environmental changes—achieving true autonomous neuromorphic hardware without external CPU dependency.

## The Grand Challenge

**Problem:** State-of-the-art analog photonic neuromorphic systems face critical limitations:
1. **No on-the-fly training** with dynamic data
2. **Frequent analog-to-digital conversions** required
3. **No real-time adaptation** to crosstalk and environmental variations
4. **Hardware-specific algorithms** that don't generalize
5. **Offline training dependency** on external computers

**Why it matters:**
- Backpropagation requires layer-by-layer gradient communication
- Digital training requires intensive matrix multiplications
- Computer-in-the-loop training has high latency
- Calibration-based approaches need frequent recalibration

**The missing piece:** Truly autonomous online learning operating entirely in the analog domain without external CPU.

## Revolutionary Approach: Multiplexed Gradient Descent (MGD)

### Core Algorithm

**Key insight:** Measure gradients DIRECTLY from output perturbations, eliminating digital matrix multiplications.

**How it works:**
1. **Baseline measurement:** Measure loss L₀ without perturbations
2. **Perturbed measurement:** Add small perturbations wₑᵢ(t) to each weight
3. **Gradient extraction:** ΔLᵢ(t) = L with perturbation - L₀
4. **Weight update:** wᵢ incorporates instantaneous ΔLᵢ(t) and wₑᵢ(t)

**Perturbation strategy:**
- Random binary sequence (-1, 1) for each weight
- Amplitude Δwᵢ sets perturbation magnitude
- Unique sequence per batch per epoch
- Pairwise-uncorrelated across weights

**Why it's revolutionary:**
- **No backpropagation:** No layer-by-layer gradient communication
- **No matrix multiplications:** Gradient measured directly optically
- **Hardware-agnostic:** Works with any trainable physical system
- **Fully analog:** Entire pipeline stays in optical domain

### Hardware Implementation

**Silicon photonic integrated circuit components:**

1. **Microring Resonator (MRR) Weight Bank:**
   - Weights: 5 MRRs with radii 8.0-8.05 μm
   - Tuning: In-resonator photoconductive heaters (IRPHs)
   - Control: Thermo-optic effect via voltage
   - Q factor: ~6000
   - Free spectral range: ~12 nm

2. **On-chip Balanced Photodetectors (BPDs):**
   - Bandwidth: 16 GHz
   - Germanium-based detectors in series
   - Direct optical gradient measurement
   - Eliminates off-chip coupling losses

3. **Wavelength Division Multiplexing (WDM):**
   - n wavelengths for n inputs
   - m × n network array
   - Incoherent architecture (no phase control needed)
   - Broadcast-and-weight topology

4. **RFSoC FPGA Integration:**
   - DAC: 1 GBaud with 8 samples/symbol
   - ADC: 4 GS/s sampling
   - Fast data encoding and readout
   - Gradient detection at GHz rates

**Key architectural advantages:**
- Monolithic integration (weight bank + photodetectors)
- No high-precision digital multiplications
- Low latency: 11.7 ps optical path
- Total latency: 74.2 ps (including electronics)

## Experimental Results

### 1. Analog End-to-End Training

**Linear Classification Task:**
- Problem: Arbitrary line (a·x₁ - b·x₂ = 0)
- Training time: < 100 seconds to convergence
- Epochs: 200
- **Accuracy: >90%**
- Stability: σ_accuracy = 0.259%, σ_loss = 0.00312
- Comparable to calibration time in other systems

**Nonlinear Classification Task:**
- Problem: Quadratic boundary ((a·x₁ + b·x₂)² - 0.05 = 0)
- Nonlinearity: Programmed on FPGA
- Training time: < 100 seconds
- Epochs: 100
- **Accuracy: >80%**
- Stability: σ_accuracy = 1.06%

**Key achievement:** First demonstration of fully analog nonlinear classification with in-situ training.

### 2. Online Tracking (Dynamic Learning Rules)

**Experimental setup:**
- Dataset: 2,000 samples in 2D space
- Task: Track changing classification boundary
- Angles: 13 configurations from 15° to 255° (20° increments)
- Update frequency: Every 800 seconds (200 epochs)
- No external information provided during transitions

**Performance:**
- **Average accuracy: >85%** across all angles
- **Recovery time: ~20 seconds** after rule change
- **Convergence: <10 epochs** for most transitions
- Specific example (255° to 95°): 4 epochs (~20s) recovery

**Breakthrough:** First photonic system demonstrating:
- Simultaneous training and inference
- On-the-fly adaptation to changing problems
- No downtime during learning rule updates
- Comparable performance across diverse configurations

### 3. Real-time Adaptation to Environmental Changes

**Challenge:** Analog photonic systems highly sensitive to:
- External temperature fluctuations
- Internal thermal crosstalk between weights
- Both can cause >50% effective weight changes

**Temperature Adaptation Test:**
- Platform temperature: 25°C baseline
- Variations: 25°C → 27°C → 25°C → 23°C → 25°C
- Change frequency: Every 200 epochs
- Temperature control: ±0.25°C precision

**Results:**
- 2°C change causes ~50% weight variation
- System autonomously compensates
- **Rate of adaptation: >20% weight change per minute**
- Quick recovery after each temperature transition
- No manual recalibration required

**Thermal Crosstalk Adaptation Test:**
- Bias voltage on neighboring channels: 0V → 5V
- Ramp rate: 25 mV per epoch over 200 epochs
- Sustained crosstalk: 5V for final 200 epochs

**Results:**
- Brief instability during voltage ramp
- **System recovers and maintains performance**
- Accuracy remains stable despite sustained crosstalk
- Demonstrates robustness to on-chip interference

**Key innovation:** Self-adaptive system that dynamically adjusts without:
- External monitoring
- Manual calibration
- Training downtime
- Prior knowledge of disturbances

### 4. Scalability: Multi-Layer Network Simulation

**Yin-Yang Dataset Classification:**
- Architecture: 4-30-3 network (210 total weights)
- Input layer: 4 neurons
- Hidden layer: 30 neurons (with ReLU)
- Output layer: 3 neurons
- Fully connected topology

**Performance:**
- **80% accuracy: ~1,000 epochs**
- **97.9% accuracy: 8,000 epochs**
- Digital PyTorch baseline (ADAM): 97.6 ± 1.5%
- **Parity with digital training achieved**

**Hardware scaling:**
- Each neuron → 4 MRRs
- Total: 37 neurons × 4 = 148 MRRs (minimum)
- Total weights: 210 MRRs
- Demonstrates practical scalability

## Performance Metrics

### Latency
- **Optical path: 11.7 ps**
- **End-to-end (with electronics): 74.2 ps**
- Photodetector bandwidth: 16 GHz (current bottleneck)

### Energy Efficiency
- **2-input system: 853 fJ/Op = 1.2 TOPS/W** at 16 GBaud
- **4×30×3 network: 3.4 fJ/Op = 291 TOPS/W**
- Total power: 27.4 mW (photonics + drivers + readout)
- Path to PetaOps/W with phase-change materials

### Convergence Time
- **Classification tasks: ~15 seconds**
- Temperature adaptation: slower (minutes)
- With carrier-depletion PN junctions (17 GHz bandwidth):
  - **1000× faster weight updates**
  - Microsecond to millisecond convergence

### Operating Speed
- **Inference rate: 1 GBaud** (demonstrated)
- Maximum: 16 GBaud (limited by photodetector)
- Training and inference simultaneous

## Comparison with State-of-the-Art

| System | Inference Latency | Training | Energy Efficiency | Online Tracking | Real-time Adaptation |
|--------|------------------|----------|-------------------|-----------------|---------------------|
| **This work** | **11.7 ps** | **22 ms** | **3,000 GOPS/W** | **Yes** | **Yes** |
| Momeni 2023 | 192 ps | Not given | 0.12 GOPS/W | No | No |
| Bandyopadhyay 2024 | 410 ps | Not given | 13 GOPS/W | No | No |
| Pai 2023 | 1 ns | Offline | 5,000 GOPS/W | No | No |
| Xue 2024 | Not given | 64 ms | 5.4×10⁹ GOPS/W | No | No |
| Ashtiani 2022 | 570 ps | Digital | 71.4 GOPS/W | No | No |

**Unique advantages of this work:**
1. Only system with true online tracking
2. Only system with real-time environmental adaptation
3. Lowest analog training latency (22 ms)
4. Hardware-agnostic algorithm
5. No calibration required

## Connections to Other Papers

### Papers 1, 4, 5 (Memristor Training):
- **Common theme:** In-situ training on analog hardware
- **This paper:** Photonic implementation (vs. electronic memristors)
- **Key difference:**
  - Memristors: Current-domain, weight storage in conductance
  - This work: Optical domain, weight in resonance shifts
  - Both avoid digital backpropagation

### Paper 2 (Photonic Computing):
- **Common theme:** Using light for neural network computation
- Paper 2: Mach-Zehnder interferometers (coherent)
- **This paper:** Microring resonators (incoherent WDM)
- **Advantage here:** No phase control needed, more stable

### Paper 6 (Physical Neural Networks - DSTD):
- Paper 6: Training RC circuits with spike-time discretization
- **This paper:** Training photonic circuits with MGD
- **Common insight:** Train the physics directly, don't simulate
- **Difference:**
  - Paper 6: Time-domain (spike times)
  - This: Amplitude-domain (optical power)

### Paper 7 (Tiki-Taka Theoretical Foundation):
- Paper 7: Proves exact convergence for perturbative training
- **This paper:** IMPLEMENTS perturbative training on photonics
- **Connection:** MGD is perturbative approach (like Tiki-Taka)
- **This work validates:** Theory from Paper 7 works on real hardware

### Papers 4, 5 (AGAD, Mixed-Precision):
- Those papers: Gradient accumulation to reduce noise
- **This paper:** Direct gradient measurement to eliminate digital computation
- **Complementary approaches** to same problem:
  - Papers 4,5: Reduce update frequency
  - This: Eliminate digital bottleneck entirely

## Relevance to "Bizarre that we use deterministic silicon to simulate learning"

This paper **demonstrates the ultimate endpoint** of the analog computing journey:

**The Transformation:**
1. **Traditional AI:**
   - Train on GPUs (deterministic digital)
   - Deploy to inference hardware
   - No adaptation after deployment
   - High latency, high energy

2. **This Work:**
   - **Hardware IS the neural network** (photonic circuits)
   - **Train and infer simultaneously** (no separation)
   - **Adapt continuously** (always learning)
   - **Ultralow latency** (11.7 ps optical)

**Key Insights:**

**1. Physics as Computation:**
- Not using silicon to simulate learning
- **Using photons to PERFORM learning**
- Light propagation = forward pass
- Optical interference = weight multiplication
- Photodetector = loss function measurement

**2. Noise as Feature:**
- Device variations used for exploration
- Perturbations enable gradient measurement
- System self-corrects through continuous training
- Environmental changes trigger adaptation (not failure)

**3. True Online Learning:**
- No distinction between training and inference
- Every inference is a training opportunity
- System never "deployed"—always learning
- Biological neural networks work this way!

**4. Hardware-Algorithm Co-design:**
- MGD designed FOR physical systems
- Exploits optical parallelism naturally
- Perturbations cheap in analog domain
- Direct measurement beats digital computation

**The Philosophical Point:**
> We shouldn't try to make deterministic hardware simulate stochastic learning. We should build stochastic hardware that learns natively.

This paper proves it's possible:
- Silicon photonics (manufacturable)
- Gigabaud operation (fast)
- True autonomy (no CPU)
- Real-world robustness (adapts to changes)

## Technical Innovations

### 1. Monolithic Integration
- Weight bank + photodetectors on same chip
- Eliminates off-chip coupling (50% loss reduction)
- Direct optical gradient measurement
- Foundry-manufactured (CMOS-compatible)

### 2. Perturbative Training Without Backpropagation
- Binary perturbations: computationally simple
- Multiplexed across weights: parallel measurement
- Hardware-agnostic: works on any trainable system
- No weight transport problem

### 3. Self-Adaptive Training Parameters
- Learning rate adjusts automatically
- Perturbation amplitude self-optimizes
- No hyperparameter tuning required
- System finds optimal operating point

### 4. Temperature-Controlled Weights
- In-resonator photoconductive heaters
- Current implementation: thermal tuning
- Future: PN junction electro-optic tuning (1000× faster)
- Both supported by same chip

## Limitations and Future Work

**Current Limitations:**
1. **Photodetector bandwidth: 16 GHz** limits maximum speed
2. **Thermal tuning slow:** millisecond response times
3. **Two-layer demonstrations:** scalability to deep networks unproven experimentally
4. **Perturbation fluctuations:** occasional accuracy drops

**Addressed by:**
1. **PN junction modulators:** 17 GHz bandwidth already on chip
2. **Electro-optic tuning:** microsecond response
3. **Simulation:** 210-weight network achieved 97.9%
4. **Hyperparameter tuning:** can reduce fluctuations

**Future Directions:**
1. **Phase-change materials:** PetaOps/W energy efficiency
2. **Larger networks:** scale to 1000+ weights
3. **Recurrent architectures:** temporal processing
4. **Multiple layers on-chip:** deep photonic networks
5. **Integration with sensors:** end-to-end analog pipeline

## Why This Matters

**For Neuromorphic Computing:**
- First truly autonomous analog learning system
- No external CPU dependency
- Real-time adaptation demonstrated
- Path to scalable implementation

**For Analog AI:**
- Proves perturbative training viable on real hardware
- Hardware-agnostic algorithm generalizes
- Robustness to noise and variations
- Energy efficiency roadmap clear

**For Photonics:**
- Demonstrates foundry-manufactured platform works
- WDM architecture scales naturally
- On-chip detection critical for performance
- CMOS-compatible process

**For Real-World Deployment:**
- Online tracking: adaptive systems
- Environmental robustness: no calibration
- Low latency: real-time applications
- Energy efficient: edge deployment

## The Big Picture

This paper represents a **paradigm shift** from:

**Old Paradigm:**
```
Design algorithm → Train on GPU → Deploy to hardware → Pray it works → Recalibrate frequently
```

**New Paradigm:**
```
Design physical system → Train on system → System stays deployed while learning → Adapts automatically
```

**The Achievement:**
- Not just analog inference (many have done this)
- Not just analog training (Papers 1-7 addressed this)
- **Fully autonomous analog learning system** that:
  - Trains itself
  - Adapts to environment
  - Tracks changing problems
  - Needs no external computer
  - Works on manufacturable hardware

**Connection to Central Theme:**
This is the **endpoint** of rejecting "deterministic silicon simulating learning":
1. **Photonic** (not silicon-electronic)
2. **Analog** (not digital)
3. **Physical** (not simulated)
4. **Adaptive** (not static)
5. **Autonomous** (not computer-controlled)

The "bizarre" approach wasn't analog computing—it was trying to force analog to behave digitally. This paper shows **analog can be better** by being genuinely analog:
- Fast (picosecond latency)
- Efficient (TOPS/W)
- Adaptive (real-time learning)
- Robust (self-correcting)
- Scalable (foundry-manufactured)

**The future of AI isn't making analog act digital—it's making analog act analog.**
