# 2510.02516v1.pdf

In-memory Training on Analog Devices with Limited
Conductance States via Multi-tile Residual Learning
Jindan Li1, Zhaoxian Wu1, Gaowen Liu3, Tayfun Gokmen4, Tianyi Chen1, 2
1 Cornell University, New York, NY 10044
2 Rensselaer Polytechnic Institute, Troy, NY 12180
3 Cisco Research, Naperville, IL 60540
4 IBM T. J. Watson Research Center, Yorktown Heights, NY 10598
{jl4767, zw868, tianyi.chen}@cornell.edu
ABSTRACT
Analog in-memory computing (AIMC) accelerators enable efficient deep neural
network computation directly within memory using resistive crossbar arrays, where
model parameters are represented by the conductance states of memristive devices.
However, effective in-memory training typically requires at least 8-bit conductance
states to match digital baselines. Realizing such fine-grained states is costly and
often requires complex noise mitigation techniques that increase circuit complex-
ity and energy consumption. In practice, many promising memristive devices
such as ReRAM offer only about 4-bit resolution due to fabrication constraints,
and this limited update precision substantially degrades training accuracy. To
enable on-chip training with these limited-state devices, this paper proposes a
residual learningframework that sequentially learns on multiple crossbar tiles to
compensate the residual errors from low-precision weight updates. Our theoret-
ical analysis shows that the optimality gap shrinks with the number of tiles and
achieves a linear convergence rate. Experiments on standard image classification
benchmarks demonstrate that our method consistently outperforms state-of-the-art
in-memory analog training strategies under limited-state settings, while incurring
only moderate hardware overhead as confirmed by our cost analysis.
1 INTRODUCTION
With the growing adoption of AI across various fields, the demand foraccurate and energy-efficient
training hardware is increasing. In this context,analog in-memory computing(AIMC) is an emerging
solution that performs matrix vector multiplication (MVM) operations directly on weights stored in
memory, offering significant efficiency improvements over conventional von Neumann systems. In
AIMC hardware, the parameters (matrices) of deep neural networks (DNN) are represented by the
conductance states ofmemristive devicesin analog crossbar arrays, while the inputs (vectors) are
programmed as voltage signals. Using Kirchhoffâ€™s and Ohmâ€™s laws, MVM operations between a
DÃ—D matrix and a vector can be completed in O(1) time on AIMC hardware, while it requires
at least O(D) time in digital MVM (Hu et al., 2016). A full MVM on analog hardware can be
executed with energy in the range of tens of femtojoules (10âˆ’15 joules), whereas accessing a 1 kB
SRAM block in digital systems typically costs 1 picojoule (10âˆ’12 joules) per byte (Murmann, 2020).
This advantage translates into higher energy efficiency. A typical commercial digital accelerator has
plateaued around 10 tera-operations per second per watt (TOPS/W) (Reuther et al., 2022), which can
be significantly surpassed by AIMC accelerators. For example, a monolithic 3D AIMC chip achieves
more than 210 TOPS/W (Chen et al., 2022), and a 4 Ã—4 core array reaches 30 TOPS/W (Jia et al.,
2021). However, due to the inherent difficulty in precisely and reliably changing the conductance of
the memory elements, in-memory analog training presents significant challenges.
This paper focuses on gradient-based in-memory training on AIMC hardware. The objective of
training is to solve the standard model optimization problem, formally defined as:
W âˆ— := arg min
WâˆˆR DÃ—D
f(W)(1)
1
arXiv:2510.02516v1  [cs.LG]  2 Oct 2025

Pulse prob ð’‘ð’Š 
âˆ input ð’™ð’Š
. . . . . . . . 
 
. . . . . . . . 
 . 
     . 
          . 
               . 
 
Pulse 
Coincidence
Rank Update
Pulse prob ð’’ð’‹  
âˆ error ðœ¹ð’‹
. . . . . . . .
. . . . . . . .
Figure 1: Illustration for rank update via
stochastic pulse streams.
where f(Â·) :R DÃ—D â†’R is the objective and W is a
trainable matrix stored in analog crossbar arrays. In dig-
ital accelerators, equation 1 can be solved by stochas-
tic gradient descent (SGD), whose recursion is given by
Wt+1 =W t âˆ’Î±âˆ‡f(W t;Î¾ t). Here, Î± is the learning rate
and Î¾t denotes a sample randomly drawn in iteration t. To
implement SGD on AIMC hardware, one needs to update
the weights stored in the crossbar array using therank up-
datemethod (Gokmen and Vlasov, 2016). This approach
leverages two O(D)-dimensional vectors, the backprop-
agation error Î´ and the input x, to perform in-memory
updates directly on the analog array via stochastic pulse
streams, as illustrated in Figure 1. Ideally, each pulse ad-
justs a weight element wâˆˆW by the minimal increment
Â±âˆ†wmin, with the sign determined by the pulse polarity. The resulting weight evolution is illustrated
in Figure 2.
Figure 2: Illustration of pulsed weight up-
dates on 10 and 20 states softbound devices.
Due to asymmetric update, the actual weight
increment follows âˆ†wp
min = âˆ†wmin Â·q +(w),
where q+(Â·) represents the device positive re-
sponse factor.
We define the number of device states by dividing
the total weight range wâˆˆ[Ï„ min, Ï„max] by this mini-
mal weight change: nstates := (Ï„max âˆ’Ï„ min)/âˆ†wmin,
where nstates determines how many distinct values the
weight can stably represent. A smaller nstates (larger
âˆ†wmin) amplifying quantization noise Î¶ whose vari-
ance scales with âˆ†wmin. This noise captures the gap
between ideal and actual updates and fundamentally
limits training accuracy. Previous studies have shown
that successful training on crossbar-based architec-
tures typically requires at least 8-bit distinct conduc-
tance levels to achieve competitive accuracy (Li et al.,
2018; Chen et al., 2017). However, some devices
struggle to provide this level of granularity within
a single memory cell. MRAM devices are typically
limited to two stable states per cell, whereas ReRAM
is usually constrained to 4-bit per cell in practice
(detailed survey in Table 3 and Appendix A), which
makes it difficult to achieve the multi-bit precision
required for effective training. As illustrated in Fig-
ure 3, reducing the number of states to 20 or fewer results in a convergence failure. While ECRAM
can support thousands of states, it remains hindered by practical challenges, including complex three-
terminal design, CMOS incompatibility, and material instability (Kim et al., 2023; Kwak et al., 2025),
which lack a scalable fabrication pipeline (Kwak et al., 2024). In contrast, ReRAM remains one of
the most manufacturable and scalable options (Stecconi et al., 2024). In practice, its bi-directional
update behavior typically involves limited conductance states together with asymmetric non-idealities
Xi et al. (2020), which form the primary focus of this paper.Rather thanpushing for increasingly
precise devices, our work advocatesalgorithm innovationsto mitigate the limitations of low-state
memristive devices, which better align with current fabrication capabilities and offer energy and area
efficiency for near-term deployment. Importantly, our goal is not to dismiss high-state devices, but to
emphasize the practical and architectural benefits of training with low-state memristive technologies.
1.1 MAIN RESULTS
This work addresses the fundamental challenges of limited precision in gradient-based training on
AIMC hardware, which stem from the limited number of conductance states and the asymmetric
update. We address these challenges by designingcomposite weight representationsthat integrate
multiple low-precision tiles to represent high-precision weights, and by developingmulti-timescale
residual learningalgorithms that enable each tile to dynamically track the residual training error left
by preceding tiles. Together, these techniques ensure stable convergence and high training accuracy
under low-precision constraints. This motivates our first question:
Q1)How can high-precision weights be represented using limited-conductance states AIMC devices?
2

To construct a high precision weight, we define the composite weight asW= PN
n=0 Î³nW (n), where
W (n) denotes a low precision weight on an AIMC tile n, and Î³âˆˆ(0,1) controls its scaling. This
structure increases the total number of representable values exponentially with the number of tiles,
thus significantly enhancing the effective numeric precision. The composite weight W is then used in
both forward and backward passes; see the details of circuit implementation in Section 3.3. Given the
composite weight W, it raises another critical question:
Q2)How to ensure that the composite weight W converges effectively under gradient-based training?
Figure 3: Training fails to converge un-
der 4-bit conductance states. The experi-
ment is conducted on LeNet-5 (MNIST)
using Tiki-Taka (TT-v1).
To ensure that the composite weight W converges un-
der gradient-based training, we propose a multi-timescale
residual learning strategy inspired by the recent advances
insingle-timescale stochastic approximation(STSA)
(Shen and Chen, 2022). However, different from STSA,
which tracks a drifting optimum at a single timescale, our
method employs a multi-timescale scheme in which each
analog tile learns on a progressively slower timescale to ap-
proximate the residual left by lower-resolution tiles. This
recursive refinement ensures that the composite weight
W approaches the global optimum W âˆ— with an exponen-
tially vanishing residual error. Since our algorithms enable
in-memory analog training, the multi-tile strategy incurs
minimal hardware overhead in terms of digital storage and
latency, thereby achieving a better accuracyâ€“efficiency
trade-off than methods that rely on digital processors for
high-precision gradient computation such as Mixed-Precision (MP) (see Table 5 and Section 3.3).
Our contributions.This work makes the following key contributions:
C1) We propose a high-precision in-memory analog training framework termed multi-timescale
residual learning, which overcomes the precision bottleneck of limited conductance states,
without requiring reset operations and relying solely on an open-loop transfer process
between tiles, thus simplifying hardware implementation.
C2) We theoretically analyze the non-convergence of single-tile Analog SGD under realistic
device constraints and establish both an upper bound and a matching lower bound. Further-
more, we analyze the convergence of our multi-timescale residual learning and show that
the error can be exponentially reduced by increasing the number of tiles.
C3) We evaluate the proposed algorithm using IBM AIHWKIT (Rasch et al., 2021) on CIFAR-
100, Fashion-MNIST, and other datasets, demonstrating consistent improvements over
existing in-memory analog training methods under limited conductance states. We analyze
hardware costs (storage, energy, latency and area) on real datasets, showing that our method
achieves an accuracyâ€“efficiency trade-off compared to baseline methods.
1.2 RELATED WORKS
Gradient-based training on AIMC hardware.Gradient-based AIMC training was first explored by
rank-updatemethods such as Analog SGD (Gokmen and Vlasov, 2016). TT-v1 mitigates asymmetric
updates and noise by accumulating gradients on an auxiliary array and periodically transferring
them (Gokmen and Haensch, 2020), while TT-v2 adds digital filtering for improved robustness (Gok-
men, 2021). However, these methods often fail to converge on larger models under limited conduc-
tance states. Hybrid 3T1Câ€“PCM designs (Ambrogio et al., 2018; Cristiano et al., 2018) improve
precision through closed-loop tuning (CLT) but incur high latency and area overhead (detailed in
Appendix A). Another line ofhybrid training paradigmsprograms high-precision digital gradients
directly into analog weights (MP (Gallo et al., 2018)), with momentum-based extensions (Wang
et al., 2020; Huang et al., 2020), though these incur substantial digital storage and compute cost, as
compared in Figure 4.
Multi-sequence Stochastic approximation.Stochastic approximation with multiple coupled se-
quences Yang et al. (2019); Shen and Chen (2022); Huang et al. (2025) has found broad applications
3

in machine learning such as bilevel learning Lu (2023); Jiang et al. (2024) and reinforcement learning
Zeng and Doan (2024a;b). Our analog training on multiple tiles can be naturally viewed as a system of
Figure 4: Algorithm comparison of computation and
storage for per-sample update with model dimension
D= 32 and mini-batch size B= 4 from the statistics
in Table 5. MP incurs substantially higher overhead,
which grows more severe asDandBincrease.
coupled sequences, since the gradient is
computed over all tiles jointly, and in turn,
each tileâ€™s update is driven by this gradient
to ensure the component weight converges
toward the global optimum.
Low-precision computing.Existing
works have primarily shown how low-
precision devices can be combined to
achieve high-precision computation in
static settingssuch as scientific comput-
ing and DNN inference (e.g., bit-slicing
schemes (Feinberg et al., 2018; Song et al.,
2023; 2024; Gallo et al., 2022; Pedretti
et al., 2021; Boybat et al., 2018; Mackin
et al., 2022)). However, extending this con-
cept to high-precision training on multiple
low-precision tiles is far more challenging,
as it must maintain convergence in the pres-
ence of asymmetric updates while weights are continually changing under limited-precision gradients.
Alternative precision enhancement strategies fall under hardware-aware training, which incorporates
quantization and other hardware noise into the digital training process to improve inference accuracy
when weights are deployed on non-ideal analog devices (Klachko et al., 2019; He et al., 2019; BÃ¼chel
et al., 2025), in contrast to our in-memory analog training that updates weights directly on analog
hardware.
Contribution relative to prior works.Our work extends Wu et al. (2024; 2025) by introducing a
new setting that accounts for limited conductance state non-idealities and by addressing it through
a new algorithm called multi-timescale residual learning. Both prior studies focus on asymmetric
non-idealities: they model the analog update dynamics and establish convergence analyzes for Analog
SGD and the Tiki-Taka algorithm. Specifically, Wu et al. (2024) considers only an asymmetric linear
device, while Wu et al. (2025) extends the analysis to general asymmetric devices to demonstrate the
scalability of the approach. Building on their foundation, we incorporate another widespread device
non-ideality, limited conductance states, by modeling a quantization noise term that introduces a new
non-vanishing error component in Analog SGD. To mitigate this error, we generalize the two-tile
residual learning scheme in Wu et al. (2025) to a multi-tile regime, where each tile approximates the
residual left by lower-resolution tiles, leading to an exponentially reduced error floor as the number
of tiles increases. The key challenge is that this residual keeps drifting as lower-resolution tiles are
updated, which we resolve by a multi-timescale learning strategy that freezes the lower-resolution
tiles while the current tile runs a sufficiently long inner loop to track its quasi-stationary residual. See
detailed discussion in Appendix B.
2 TRAININGDYNAMICS ONNON-IDEALAIMC HARDWARE
In this section, we analyze how two critical non-idealities in AIMC hardware,limited conductance
statesandasymmetric updates, affect the training dynamics. We derive an analog update rule that
explicitly captures these effects, and show that under this rule, Analog SGD exhibits an asymptotic
error determined by both the gradient noise and the quantization noise.
Asymmetric pulse update.Rank-update-based training updates the weights on the crossbar array
by simultaneously applying two stochastic pulse streams to its rows and columns, with weight
increments occurring at pulse coincidences. Ideally, each pulse coincidence induces a minimal weight
change âˆ†wmin. However, practical updates depend nonlinearly on both the current weight and the
pulse polarity, causing deviations from this idealized increment and resulting in asymmetric updates.
Specifically, given the weightWt âˆˆR DÃ—D at iteration t, the asymmetric pulse update for an element
wt is modeled as: wt+1 =
wt + âˆ†wmin Â·q +(wt),for a positive pulse,
wt + âˆ†wmin Â·q âˆ’(wt),for a negative pulse, where q+(w) and qâˆ’(w)
4

denote the device response factors to positive and negative pulses, respectively. Following the
decomposition introduced in (Gokmen and Haensch, 2020), we define the symmetric and asymmetric
components as F(w) := qâˆ’(w)+q+(w)
2 and G(w) := qâˆ’(w)âˆ’q+(w)
2 , yielding a compact element-wise
update form triggered by each pulse coincidence: wt+1 =w t +âˆ†w min âŠ™F(w t)âˆ’ |âˆ†wmin| âŠ™G(wt).
Quantization noise from limited conductance states.During the rank update process (see Figure 1),
each weight element wij, located at column i and row j of the crossbar array, is updated by Î±xiÎ´j,
where xi is the i-th entry of the input vector x, Î´j is the j-th entry of the backpropagated error vector
Î´, and Î± is the learning rate. We implement the update using stochastic pulse streams, where the
amplitude of each pulse is generated from a Bernoulli distribution with parameters pi âˆx i and
qj âˆÎ´ j. This scheme guarantees that the expectation of the actual weight change âˆ†wij is equal to
the ideal update Î±xiÎ´j. However, due to the limited number of conductance states, each pulse induces
only a discrete weight increment of magnitude âˆ†wmin. This discretization introduces a mismatch
between the actual update and its ideal target. We capture this discrepancy by defining a stochastic
noise termÎ¶ ij, such thatâˆ†w ij =Î±x iÎ´j +Î¶ ij,and show its statistical properties in the following.
Lemma 1(Statistical properties of pulse update noise).Under the stochastic pulse update in (Gokmen
and Vlasov, 2016), the random variableÎ¶ ij has the following properties:
E[Î¶ij] = 0,andVar[Î¶ ij] = Î˜(Î±Â·âˆ†w min).
The proof of Lemma 1 is deferred to Appendix E.1. Since analog crossbar arrays update all weight
elements in parallel, the matrix update rule combining asymmetric pulse updates and quantization
noise from limited conductance states can be succinctly represented as:
Wt+1 =W t + âˆ†Wt âŠ™F(W t)âˆ’ |âˆ†W t| âŠ™G(W t) +Î¶ t (2)
where the operations | Â· | and âŠ™ denote element-wise absolute value and multiplication, respectively.
The specific form of âˆ†Wt depends on the chosen optimization algorithm. By substituting âˆ†Wt with
the gradient used in digital SGD, the update rule for Analog SGD under equation 2 becomes:
Wt+1 =W t âˆ’Î±âˆ‡f(W t;Î¾ t)âŠ™F(W t)âˆ’ |Î±âˆ‡f(W t;Î¾ t)| âŠ™G(W t) +Î¶ t.(3)
Based on equation 3, we establish the upper and lower bounds on the convergence of Analog SGD on
a single tile with limited conductance states. Our analysis shows that asymmetric pulse responses and
the quantization noise term Î¶t arising from limited conductance states pose fundamental challenges
to convergence and lead to a non-negligible asymptotic error during training.
Theorem 1(Convergence of Analog SGD, short version).Under a set of mild assumptions,
with Ïƒ2 denoting the variance bound of the gradient noise, if the learning rate is set as Î±=
O
 q
2(f(W 0)âˆ’f âˆ—)
Ïƒ2T

, then it holds that:
1
T
Tâˆ’1X
t=0
E[âˆ¥W âˆ— âˆ’W tâˆ¥2]â‰¤ O

RT
r
2(f(W0)âˆ’f âˆ—)Ïƒ2
T

+ 4Ïƒ2ST +R T âˆ†wmin
whereS T := 1
T
PTâˆ’1
t=0
âˆ¥Wtâˆ¥2
âˆž/Ï„ 2
max
1âˆ’âˆ¥Wtâˆ¥2âˆž/Ï„ 2max
,R T := 1
T
PTâˆ’1
t=0
2L
1âˆ’âˆ¥Wtâˆ¥2âˆž/Ï„ 2max
.
Theorem 1 suggests that the average squared Euclidean distance between Wt and W âˆ— is upper
bounded by the sum of three terms: the first term vanishes at a rate of O(
p
Ïƒ2/T) , which also
appears in the digital SGDâ€™s convergence bound; the second and third terms contribute to the
asymptotic errorof Analog SGD, which does not vanish as the number of iterations T increases.
Intuitively, the second term arises from the absolute gradient term|Î±âˆ‡f(W t, Î¾t)| in equation 3, which
introduces variance scaling as Î±Ïƒ2. The third term originates from the quantization noise Î¶t, which
has variance Î˜(Î±âˆ†wmin). In the convergence analysis, after normalizing by the descent coefficient
Î±, these two terms result in residual errors of order Ïƒ2 and âˆ†wmin, respectively. In contrast, in digital
SGD, the variance of sample noise scaling as Î±2Ïƒ2 vanishes under diminishing learning rates. We
next present a matching lower bound.
Theorem 2(Lower bound of the error of Analog SGD, short version).Under a set of mild assumptions,
if the learning rate Î±= 1
2L, there exists an instance where Analog SGD generates a sequence
5

{Wt}Tâˆ’1
t=0 such that the iterates converge to a neighborhood of the optimal solutionW âˆ—, satisfying:
1
T
Tâˆ’1X
t=0
E[âˆ¥W âˆ— âˆ’W tâˆ¥2]â‰¥â„¦(Ïƒ 2ST +R T âˆ†wmin).
The full versions of Theorem 1 and 2 together with their proofs are deferred to Appendix F. These
theoretical insights underscore the importance of addressing quantization noise, which stands as a
key obstacle to fully realizing the potential of analog neural network training.
3 MULTI-TILERESIDUALLEARNING ONNON-IDEALHARDWARE
ð‘Š 0  
ð›¾ð‘Š 1
à´¥ð‘Šð‘–ð‘›ð‘–ð‘¡
 ð‘Š âˆ—
ð¸
ð›¾ð¸
. . . . . . 
à´¥ð‘Š = à·
ð‘›=0
ð‘
ð›¾ð‘›ð‘Š(ð‘›)
ð›¾ð‘ð¸
Figure 5: Illustration of residual learning
intuition. W init denotes the initial com-
posite weight where W (0) is randomly
initialized and all remaining tiles are 0.
As discussed in Section 2, single-tile training on non-ideal
AIMC hardware inevitably results in a non-vanishing error.
We propose a multi-timescale residual learning strategy for
non-ideal AIMC hardware, where each additional scaled
tile iteratively corrects theasymptotic residual errorleft
by the preceding lower-resolution tiles due to limited con-
ductance states and asymmetric updates.
3.1 MULTI-TILE
RESIDUAL LEARNING FORMULATION
Denote the weights stored on a single analog tile at it-
eration t by W (0)
t , the optimal weight by W âˆ—, and the
non-vanishing error as E:= lim tâ†’âˆž W âˆ— âˆ’W (0)
t . To mit-
igate this error, we introduce a second analog tile W (1),
scaled by a factor Î³, to iteratively compensate for it. As illustrated in Figure 5, rather than directly
approximating E, the second tile approximates a scaled target E/Î³. Although W (1) still suffers
from similar device non-idealities and incurs a non-vanishing error when tracking its target (i.e.,
limtâ†’âˆž E/Î³âˆ’W (1)
t =E ), the combined output of the two tiles nonetheless converges to a smaller
residual:
lim
tâ†’âˆž
W âˆ— âˆ’(W (0)
t +Î³W (1)
t ) = lim
tâ†’âˆž
(W âˆ— âˆ’W (0)
t )âˆ’Î³W (1)
t = lim
tâ†’âˆž
Eâˆ’Î³W (1)
t =Î³E.
This shows that the use of an additional tile reduces the asymptotic residual by a factor of Î³.
Extending this idea further, we introduce N more analog tiles W (1), . . . , W(N) , each tile W (n)
is scaled by a geometric factor Î³n. We define the geometric sum of the first n tiles as W
(n)
:=Pnâˆ’1
nâ€²=0 Î³nâ€²
W (nâ€²), nâˆˆ[N], so that the residual left by the first n tiles is W âˆ— âˆ’ W
(n)
. We define
the local optimal point for tile W (n) as P âˆ—
n(W
(n)
) := arg min Pn f( W
(n)
+Î³ nPn). Assuming
that f(Â·) is strongly convex with a unique minimizer W âˆ—, the optimal solution is P âˆ—
n(W
(n)
) =
Î³âˆ’n(W âˆ— âˆ’W
(n)
),withP âˆ—
0 :=W âˆ—. To optimize each tileW (n), we minimize the objectiveâˆ¥W (n) âˆ’
P âˆ—
n(W
(n)
)âˆ¥2, so that Î³nW (n) approximates the residual left by the firstn tiles. Applying this process
to all tiles finally yields an exponentially reduced error between the composite weight W and the
optimal weightW âˆ—. Formally, we solve the multi-layer problem as:
W (0) := arg min
U0
âˆ¥U0 âˆ’P âˆ—
0 âˆ¥2, P âˆ—
0 :=W âˆ—,(4a)
W (1) := arg min
U1
âˆ¥U1 âˆ’P âˆ—
1 (W
(1)
)âˆ¥2,s.t.P âˆ—
1 (W
(1)
) := arg min
P1
f( W
(1)
+Î³P 1),(4b)
. . .
W (N) := arg min
UN
âˆ¥UN âˆ’P âˆ—
N(W
(N)
)âˆ¥2,s.t.P âˆ—
N(W
(N)
) := arg min
PN
f( W
(N)
+Î³ N PN)(4c)
whereU n, Pn âˆˆR DÃ—D fornâˆˆ {0, . . . , N}.
6

. . . . . . . . 
 
. . . . . . . . 
 . 
     . 
          . 
               . 
 
+-      +  -      +  
. . . . . . . .
ð‘½ð’Šð’1
ð‘½ð’Šð’ðŸ
ð‘½ð’Šð’ð’…
t2 âˆ x2
td âˆ xd
t1 âˆ x1 . . . . . . . . 
 
. . . . . . . . 
 . 
     . 
          . 
               . 
 
ð‘°ðŸ
ð‘µ
-      +  +
+
-      +  ð‘¹ðŸ
ð‘µ . . . . . . . .
. . . . . . . . 
 
. . . . . . . . 
 . 
     . 
          . 
               . 
 
+-      +  
+-      +  
. . . . . . . .
. . . . . . . . . . . .
ð‘Š(ð‘)
ð‘¹ð’‹
ð‘µ
ð‘¹ðŸ
ð’
ð‘¹ð’‹
ð’ ð‘¹ðŸ
ðŸŽ ð‘¹ð’‹
ðŸŽ
ð‘°ð’‹
ð‘µð‘°ðŸ
ð‘µ ð‘°ðŸ
ð’ ð‘°ðŸ
ðŸŽð‘°ðŸ
ðŸŽð‘°ðŸ
ð’ ð‘°ð’‹
ðŸŽð‘°ð’‹
ð’
ADC ADC
ð‘Š(0)ð‘Š(ð‘›)
ð‘½ð’ð’–ð’•ðŸ
ð‘µ
ð‘½ð’ð’–ð’•ð’‹
ð‘µ ð‘½ð’ð’–ð’•ð’‹
ðŸŽð‘½ð’ð’–ð’•ð’‹
ð’
ð‘½ð’ð’–ð’•ðŸ
ðŸŽð‘½ð’ð’–ð’•ðŸ
ð’
ð‘½ð’Šð’1 ð‘½ð’Šð’1
ð‘½ð’Šð’ðŸð‘½ð’Šð’ðŸ
ð‘½ð’Šð’ð’…ð‘½ð’Šð’ð’…
. . . . . .
ð’šðŸ ð’šð£
Figure 6: Analog circuit implementation of forward process using composite weight W.
3.2 MULTI-TILE GRADIENT-BASED UPDATE
The optimization problem is challenging because the drifting optimum P âˆ—
n(W
(n)
) is an im-
plicit function of W
(n)
. To decouple this dependency when optimizing W (n), we freeze tiles
{W (0), . . . , W(nâˆ’1)} to ensure that W
(n)
remains fixed. To optimize each tile W (n) in the equa-
tion 4, we aim to update via an approximate descent direction of its objective âˆ¥W (n) âˆ’P âˆ—
n(W
(n)
)âˆ¥2
. The negative gradient of the objective is :
âˆ’âˆ‡W (n) âˆ¥W (n) âˆ’P âˆ—
n(W
(n)
)âˆ¥2 = 2(P âˆ—
n(W
(n)
)âˆ’W (n))(5)
which implies thatP âˆ—
n(W
(n)
)âˆ’W (n) is the descent direction to updateW (n). Forn=N, since
P âˆ—
N(W
(N)
)âˆ’W (N) =Î³ âˆ’N(W âˆ— âˆ’W
(N)
)âˆ’W (N) =Î³ âˆ’N(W âˆ— âˆ’
NX
n=0
Î³nW (n)) =Î³ âˆ’N(W âˆ— âˆ’W)
and EÎ¾[âˆ’âˆ‡f( W;Î¾)] =âˆ’âˆ‡f( W)âˆW âˆ— âˆ’ W under strong convexity assumptions, we directly
use the stochastic gradient âˆ’âˆ‡f( W;Î¾) as the descent direction to update W (N) . For nâˆˆ[Nâˆ’1] ,
since the optimization on W (n+1) (see equation 4) ensures that W (n+1) â‰ˆP âˆ—
n+1(W
(n+1)
) =
Î³âˆ’1(P âˆ—
n(W
(n)
)âˆ’W (n)), we use W (n+1) to update W (n). Following the update rule in equation 2,
for tileW (N) , the update is given by:
W (N)
t+1 =W (N)
t âˆ’Î±âˆ‡f( W t;Î¾ t)âŠ™F
 
W (N)
t

âˆ’
Î±âˆ‡f( W t;Î¾ t)
 âŠ™G
 
W (N)
t

+Î¶ t.(6)
ForW (n),nâˆˆ[Nâˆ’1], the update is given by:
W (n)
tn+1 =W (n)
tn +Î² ËœW (n+1) âŠ™F
 
W (n)
tn

âˆ’
Î² ËœW (n+1) âŠ™G
 
W (n)
tn

+Î¶ tn (7)
where Î² is the learning rate, and the transferred weight is defined as ËœW (n+1) :=W (n+1)
tn+1+Tn+1âˆ’1.
We show in Section 4 that each tile W (n) requires an inner loop of Tn = Î˜(Î³âˆ’1) steps to converge
to its optimum P âˆ—
n(W
(n)
). We thus adopt a multi-timescale training schedule to coordinate these
updates, with each tile W (n) maintains a local step counter tn =âŒŠ(t+ 1)/ QN
nâ€²=n+1 Tnâ€²âŒ‹. A detailed
algorithm is provided in Algorithm 1.
Remark 1.The optimization problem in equation 4 resembles the STSA framework (Shen and
Chen, 2022), where each sequence tracks a drifting optimum that evolves with the updates of other
sequences, denoted as yn,âˆ—(ynâˆ’1) in STSA and P âˆ—
n(W
(n)
) in our setting. However, directly applying
STSA to our problem encounters two main difficulties:C1)STSA relies on rapid convergence of each
sequence to its drifting optimum via a single update step, but in our composite weight structure, a
single-step update on W (nâˆ’1) causes P âˆ—
n(W
(n)
) to drift approximately Î˜(Î³âˆ’1) times faster than a
single-step update on W (n);C2)STSA considers that yn,âˆ—(ynâˆ’1) depends only on sequence ynâˆ’1,
while our scenario involvesP âˆ—
n(W
(n)
)depending on multiple sequences W
(n)
.
Remark 2.Our update dynamics for each tile naturally support an open-loop transfer process. As
shown in equation 5, what needs to be propagated is only the descent direction of each tile rather
7

Dataset TT-v1 TT-v2 MP Ours (3 tiles) Ours (4 tiles) Ours (6 tiles)
Fashion-MNIST (#4) 10.01Â±0.0747.51Â±0.91 75.61Â±0.69 68.09Â±0.4973.35Â±0.1375.11Â±0.07
MNIST (#10) 78.65Â±2.3695.43Â±0.17 99.13Â±0.02 95.07Â±0.3597.10Â±0.1798.53Â±0.09
Table 1: Test accuracy on MNIST and Fashion-MNIST with analog LeNet-5 under 10 and 4 states.
Compared methods include MP, TT-v1, TT-v2 and different versions of our algorithm.
Dataset TT-v1 TT-v2 MP Ours (4 tiles) Ours (6 tiles) Ours (8 tiles)
CIFAR-10 (#4) 11.65Â±0.6887.43Â±0.10 93.31Â±0.04 90.45Â±0.2892.02Â±0.1490.65Â±0.09
CIFAR-100 (#4) 9.75Â±2.4711.28Â±0.62 70.25Â±0.61 63.26Â±0.4568.46Â±0.2369.63Â±0.40
CIFAR-10 (#16) 58.00Â±0.2684.30Â±0.09 95.04Â±0.05 92.98Â±0.6293.29Â±0.6494.36Â±0.08
CIFAR-100 (#16) 26.69Â±0.1765.17Â±0.36 73.16Â±0.07 68.11Â±0.3569.62Â±0.5372.20Â±0.11
Table 2: Test accuracy on CIFAR-10 and CIFAR-100 under 4 and 16 conductance states on ResNet-34.
Compared methods include MP, TT-v1, TT-v2 and different versions of our algorithm.
than its exact weight value. This eliminates the need for closed-loop tuning, thereby reducing control
overhead and highlighting the hardware efficiency of our algorithm.
3.3 ANALOG CIRCUIT IMPLEMENTATION
Figure 6 illustrates how the composite weight W is formed in the analog domain by combining
low-precision tiles W (n) âˆˆR DÃ—D, nâˆˆ {0, . . . , N} . For the forward pass y=x âŠ¤W , each input xd
is encoded by a voltage pulse on the d-th row of each tile W (n), with duration proportional to xd. By
Ohmâ€™s and Kirchhoffâ€™s laws, each tile produces a current of thej-th column as I n
j =PD
d=1 W (n)
d,j xd.
Each I n
j is fed into an inverting op-amp with feedback resistor Rn
j to apply scaling Î³n, yielding
V n
outj =âˆ’R n
j I n
j . The voltage outputs are summed in hardware to produce the final resulty j as:
yj âˆ
NX
n=0
V n
outj =âˆ’
NX
n=0
Rn
j I n
j =âˆ’
NX
n=0
Rn
j
DX
d=1
W (n)
d,j xd =âˆ’
DX
d=1
W d,jxd.
A similar operation is used during the backward pass, where the output is given by Î´= W
âŠ¤
Î´â€², with
Î´â€² denoting the error signal propagated from the next layer. Table 5 compares the computational
complexity and estimated update latency of MP, Analog SGD, TT-v2, and our method. Our algorithm
achieves a low update latency, upper bounded by 95.9 ns even with an infinite number of tiles, which
is over 30Ã— faster than MP, while requiring onlyO(2D) digital storage for the input x and error Î´ and
O(1) digital memory operations for reading and writing, which is comparable to the cost of Analog
SGD. Please see Appendix I, where we discuss the feasibility of circuit-level implementation and
present a detailed comparison of digital storage, runtime, energy, and area costs across algorithms.
4 STOCHASTICAPPROXIMATIONTHEORY FORRESIDUALLEARNING
In this section, we present a proof sketch for the convergence of our proposed multi-timescale residual
learning algorithm. Before analyzing the algorithm, we introduce four assumptions concerning the
objective function, the gradient noise, and the device response characteristics.
Assumption 1(Unbiasness and bounded variance).The sample Î¾t is independently sampled from
a distribution D, âˆ€tâˆˆ[T] , and the stochastic gradient is unbiased with bounded variance, i.e.,
EÎ¾t[âˆ‡f(W t;Î¾ t)] =âˆ‡f(W t)andE Î¾t[âˆ¥âˆ‡f(W t;Î¾ t)âˆ’ âˆ‡f(W t)âˆ¥2]â‰¤Ïƒ 2.
Assumption 2(Smoothness and strong convexity).f(W)isL-smooth andÂµ-strongly convex.
Assumption 3(Bounded weights).The weights are bounded asâˆ¥W tâˆ¥âˆž â‰¤W max â‰¤Ï„ max for allt.
Assumption 4(Response factor and zero shifted symmetric point).(Continuity) q+(Â·) and qâˆ’(Â·) are
continuous;(Saturation) q+(Ï„max) = 0, qâˆ’(Ï„min) = 0;(Positive-definiteness) q+(w)>0 for all
w < Ï„ max, andq âˆ’(w)>0for allw > Ï„ min;(Symmetric point)G(w) = 0if and only ifw= 0.
Assumptions 1â€“2 are standard in convex optimization (Bottou et al., 2018). Assumption 3 assumes
that Wt remains within a small region, which is a mild condition that generally holds in practice.
8

Assumption 4 defines the response function class observed in resistive devices (Wu et al., 2025) and
adopts the widely used zero-shifted symmetric point in analog training (Gokmen and Haensch, 2020).
We begin by presenting Lemmas 2 and 3, which describe how each tile tracks its drifting optimum
within an inner loop and serve as the basis for our convergence analysis. Their full proofs are given
in Appendix G. For notational convenience, here we writeP âˆ—
n(W
(n)
tnâˆ’1) =:P âˆ—
n.
Lemma 2(Descent lemma of the main sequence W (N) ).Under Assumptions 1â€“4, the update
dynamics equation 6 ensures that after a single inner loop of length TN , the expected distance
betweenW (N) and its optimum decreases as:
E

âˆ¥W (N)
t+TN âˆ’1 âˆ’P âˆ—
N âˆ¥2
â‰¤
 
1âˆ’Î˜(Î³ N)
TN
âˆ¥W (N)
t âˆ’P âˆ—
N âˆ¥2 + Î˜(Ïƒ2Î³âˆ’N +Î³ âˆ’ 4N
3 (Ïƒâˆ†wmin)
2
3 ).
Lemma 3(Descent lemma of the sequences W (n)).Under the same assumptions as Lemma 2, for
nâˆˆ {0, . . . , Nâˆ’1}, the update dynamics equation 7 ensures that:
E

âˆ¥W (n)
tn+Tnâˆ’1 âˆ’P âˆ—
n âˆ¥2
â‰¤(1âˆ’Î˜(Î³)) Tn
âˆ¥W (n)
tn âˆ’P âˆ—
n âˆ¥2 + Î˜(Î³2âˆ¥ ËœW (n+1) âˆ’P âˆ—
n+1âˆ¥2 + âˆ†wmin).
Lemmas 2 and 3 yield contraction terms (1âˆ’Î˜(Î³ p))Tn with p= 1 for W (n) and p=N for
W (N) . Using (1âˆ’Î») Tn â‰¤e âˆ’Î»Tn, we set Tn = Î˜(Î³ âˆ’1) and TN = Î˜(Î³ âˆ’N) so that (1âˆ’
Î˜(Î³p))Tn = Î˜(Ï) , where Ï is the contraction rate in the Lyapunov analysis below. To this end,
we now analyze the optimization problem in equation 4 by introducing a Lyapunov sequence as
Jk :=PN
n=0 âˆ¥W (n)
tn+kTnâˆ’1 âˆ’P âˆ—
n(W
(n)
tnâˆ’1+k)âˆ¥2, which aggregates the squared distances between each
tile and its drifting optimum after completing k inner loops. In particular, when the slowest tile W (0)
has completed k inner loops, the fastest tile W (N) will have performed t=k QN
n=0 Tn =O(Î³ âˆ’2N k)
gradient updates, which we take as the reference measure for evaluating the overall convergence
rate. By balancing the learning rates and inner-loop length across all tiles, we establish a linear
convergence rate for the Lyapunov sequence with a non-vanishing asymptotic error induced by
device-level imperfections. This result is formalized in the following theorem.
Theorem 3(Convergence of residual learning).Suppose Assumptions 1â€“4 hold. Let the scaling
parameter satisfy Î³âˆˆ(0,1/
âˆš
6]. For all nâˆˆ {0, . . . , Nâˆ’1} , set the learning rate Î²= Î˜(Î³ 2), the
inner loop length Tn â‰¥Î˜
 
Î³âˆ’1
, except for T0 = Î˜(1). For n=N , set the learning rate Î±= Î˜(1)
andT N â‰¥Î˜
 
Î³âˆ’N
.Givent=O(Î³ âˆ’2N k),Ïâˆˆ(0,1), the Lyapunov functionJ k is bounded as:
E[Jk]â‰¤ O((1âˆ’Ï) Î³2N t)E[J0] + Î˜(Î³âˆ’ 4N
3 (Ïƒâˆ†wmin)
2
3 ).
Theorem 3 shows the Lyapunov function converges linearly up to an asymptotic upper bound
Î˜(Î³âˆ’ 4N
3 (Ïƒâˆ†wmin)2/3) determined solely by quantization and sample noise. Corollary 1 follows
from Theorem 3 by applying the Lyapunov function bound as an upper bound on the component
âˆ¥W (N)
tN+kTN âˆ’1 âˆ’P âˆ—
N(W
(N)
tNâˆ’1+k)âˆ¥2. Then using the definition of P âˆ—
N(W
(N)
) and multiplying both
sides byÎ³ 2N yields the optimality gap of the composite weight.
Corollary 1(Optimality gap of residual learning).Under the same conditions as in Theorem 3, the
limit of the composited weight W t satisfies:
lim sup
tâ†’âˆž
E

âˆ¥W âˆ— âˆ’ W tâˆ¥2
â‰¤Î˜(Î³
2N
3 (Ïƒâˆ†wmin)
2
3 ).
The proofs of Theorem 3 and Corollary 1 can be found in Appendix G. Intuitively, increasing
the value of N reduces the upper bound Î˜
 
Î³
2N
3 (Ïƒâˆ†wmin)
2
3

, demonstrating the effectiveness of
multi-timescale residual learning under a limited number of conductance states.
5 NUMERICALSIMULATIONS
In this section, we evaluate our method using the AIHWKIT toolkit on the SoftBounds device class,
which models bi-directional memristive devices such as ReRAM by capturing saturation effects
and limited update precision. We compare against the MP, TT-v1, and TT-v2 baselines. Detailed
algorithmic procedures are provided in Appendix H.
9

Figure 7: (left) Effect of asymmetry. st: #states, tl: #tiles. (middle) Effect of geometric scaling factor
Î³. (right) A toy example illustrating that training loss decreases along both the epoch and tile-count
dimensions. The results demonstrate that each tile converges successfully, meanwhile, incorporating
more tiles also improves accuracy.
5.1 ANALOG TRAINING PERFORMANCE ON REAL DATASET
We train an analog LeNet-5 model on the MNIST and Fashion-MNIST dataset for 100 epochs with
4 and 10 conductance states, respectively. We also train the ResNet-34 model on the CIFAR-10
and CIFAR-100 datasets with 4 or 16 conductance states, covering both an extreme low-precision
case and the widely adopted industrial setting. Training is performed for 200 epochs on CIFAR-10
and 400 epochs on CIFAR-100, with layer3, layer4, and the fully connected layer mapped
to analog. The parameter configurations for TT-v1, TT-v2, MP, and our method are provided in
Appendix K. As shown in Tables 1 and 2, our residual learning method steadily improves accuracy as
the number of tiles increases, surpassing both TT-v1 and TT-v2 with only 3 to 4 tiles, and reaching
accuracy comparable to MP while incurring far lower storage and runtime overhead, demonstrating
both scalability and robustness across larger networks. To further illustrate the scalability of our
method, we also provide results in Appendix J on models with larger analog deployments and higher
conductance states.
5.2 ABLATION STUDIES
Effect of asymmetry.For a given number of conductance states, the degree of asymmetry in an
analog device is determined by the saturation boundÏ„max (with Ï„min =âˆ’Ï„ max). We evaluate training
accuracy with Ï„max varying in (0,1) on MNIST and show that our algorithm consistently maintains
high accuracy across different levels of asymmetry in Figure 7 (left).
Effect of geometric scaling factor.As show in Figure 7 (middle), we find that the optimal scaling
factor Î³ generally lies near 1
nstates
, which ensures that the weight range of each tile is properly matched
to the resolution of its previous tile, whereas overly largeÎ³severely degrades accuracy.
Effect of number of tiles.To validate the convergence behavior of our residual learning mechanism,
we construct a toy example based on a simple least-squares problem of the form (wâˆ’b) 2. The target
output b is quantized to 16-bit resolution, and each tile has 2-bit update granularity. The parameter
configurations are provided in Appendix K. Figure 7 (right) presents the log-scaled training loss. This
visualization highlights two aspects of the learning dynamics. First, the composite weight converges
reliably toward the target wâˆ— =b . Second, the loss decreases consistently with more tiles, confirming
the effectiveness of the multi-tile strategy.
6 CONCLUSIONS ANDLIMITATIONS
We propose multi-timescale residual learning, an in-memory analog training framework that enables
reliable DNN training under limited conductance states by modeling device non-idealities and proving
convergence, achieving strong results on standard image classification tasks. We acknowledge the lack
of real hardware evaluation and plan to validate our method through future chip-level experiments.
REFERENCES
S. Ambrogio, P. Narayanan, H. Tsai, R. M. Shelby, I. Boybat, C. Di Nolfo, S. Sidler, M. Giordano,
M. Bodini, N. C. P. Farinha, et al. Equivalent-accuracy accelerated neural-network training using
10

analogue memory.Nature, 558(7708):60â€“67, 2018.
D. Apalkov, A. Khvalkovskiy, S. Watts, V . Nikitin, X. Tang, D. Lottis, K. Moon, X. Luo, E. Chen, and
A. Ong et al. Spin-transfer torque magnetic random access memory (stt-mram).ACM J. Emerg.
Technol. Comput. Syst., 9(2):1â€“35, May 2013. doi: 10.1145/2463585.2463589.
L. Bottou, F. E. Curtis, and J. Nocedal. Optimization methods for large-scale machine learning.SIAM
Rev., 60(2):223â€“311, 2018.
I. Boybat, M. Le Gallo, S. R. Nandakumar, T. Moraitis, T. Parnell, T. Tuma, B. Rajendran, Y . Leblebici,
A. Sebastian, and E. Eleftheriou. Neuromorphic computing with multi-memristive synapses.Nat.
Commun., 9(1):2514, June 2018.
Julian BÃ¼chel, Iason Chalas, Giovanni Acampa, An Chen, Omobayode Fagbohungbe, Sidney Tsai,
Kaoutar El Maghraoui, Manuel Le Gallo, Abbas Rahimi, and Abu Sebastian. Analog foundation
models.arXiv preprint arXiv:2505.09663, 2025.
G. W. Burr, R. M. Shelby, S. Sidler, C. Di Nolfo, J. Jang, I. Boybat, R. S. Shenoy, P. Narayanan,
K. Virwani, and E. U. Giacometti. Experimental demonstration and tolerancing of a large-scale
neural network (165 000 synapses) using phase-change memory as the synaptic weight element.
IEEE Trans. Electron Devices, 62(11):3498â€“3507, 2015.
G. W. Burr, M. J. Brightsky, A. Sebastian, H.-Y . Cheng, J.-Y . Wu, S. Kim, N. E. Sosa, N. Papandreou,
H.-L. Lung, and H. Pozidis. Recent progress in phase-change memory technology.IEEE J. Emerg.
Sel. Topics Circuits Syst., 6(2):146â€“162, 2016.
T. Chang, S.-H. Jo, and W. Lu. Short-term memory to long-term memory transition in a nanoscale
memristor.ACS Nano, 5(9):7669â€“7676, September 2011. doi: 10.1021/nn202983n.
M.-C. Chen, S. Ohshita, S. Amano, Y . Kurokawa, S. Watanabe, Y . Imoto, Y . Ando, W.-H. Hsieh,
C.-H. Chang, and C.-C. Wu. A >64 multiple states and >210 tops/w high efficient computing by
monolithic si/caac-igzo+ super-lattice zro2/al2o3/zro2 for ultra-low power edge ai application. In
IEEE Int. Electron Devices Meet., pages 18â€“2, San Francisco, CA, December 2022.
P.-Y . Chen, X. Peng, and S. Yu. Neurosim+: An integrated device-to-algorithm framework for
benchmarking synaptic devices and array architectures. InIEEE Int. Electron Devices Meet., pages
6â€“1, San Francisco, CA, December 2017.
G. Cristiano, M. Giordano, S. Ambrogio, L. P. Romero, C. Cheng, P. Narayanan, H. Tsai, R. M.
Shelby, and G. W. Burr. Perspective on training fully connected networks with resistive memories:
Device requirements for multiple conductances of varying significance.Journal of Applied Physics,
124(15):152102, 2018.
B. Feinberg, U. K. R. Vengalam, N. Whitehair, S. Wang, and E. Ipek. Enabling scientific computing
on memristive accelerators. InProc. ACM/IEEE Annu. Int. Symp. Comput. Archit., pages 367â€“382,
Los Angeles, CA, June 2018.
E. J. Fuller, S. T. Keene, A. Melianas, Z. Wang, S. Agarwal, Y . Li, Y . Tuchman, C. D. James, M. J.
Marinella, and J. J. Yang. Parallel programming of an ionic floating-gate memory array for scalable
neuromorphic computing.Science, 364(6440):570â€“574, 2019.
M. Le Gallo, A. Sebastian, R. Mathis, M. Manica, H. Giefers, T. Tuma, C. Bekas, A. Curioni, and
E. Eleftheriou. Mixed-precision in-memory computing.Nat. Electron., 1(4):246â€“253, 2018.
M. Le Gallo, S. R. Nandakumar, L. Ciric, I. Boybat, R. Khaddam-Aljameh, C. Mackin, and A. Sebas-
tian. Precision of bit slicing with in-memory computing based on analog phase-change memory
crossbars.Neuromorph. Comput. Eng., 2(1):014009, 2022.
T. Gokmen. Enabling training of neural networks on noisy hardware.Front. Artif. Intell., 4:699148,
2021.
T. Gokmen and W. Haensch. Algorithm for training neural networks on resistive device arrays.Front.
Neurosci., 14:103, 2020.
11

T. Gokmen and Y . Vlasov. Acceleration of deep neural network training with resistive cross-point
devices: Design considerations.Front. Neurosci., 10:333, 2016.
N. Gong, M. J. Rasch, S.-C. Seo, A. Gasasira, P. Solomon, V . Bragaglia, S. Consiglio, H. Higuchi,
C. Park, and K. Brew. Deep learning acceleration in 14nm cmos compatible reram array: device,
material and algorithm co-optimization. InIEEE Int. Electron Devices Meet., pages 33â€“7, San
Francisco, CA, December 2022.
Z. He, J. Lin, R. Ewetz, J.-S. Yuan, and D. Fan. Noise injection adaption: End-to-end reram crossbar
non-ideal effect adaption for neural network mapping. InProc. ACM/IEEE Design Autom. Conf.,
pages 1â€“6, Las Vegas, NV , USA, June 2019.
M. Hu, J. P. Strachan, Z. Li, E. M. Grafals, N. Davila, C. Graves, S. Lam, N. Ge, J. J. Yang, and
R. S. Williams. Dot-product engine for neuromorphic computing: Programming 1t1m crossbar
to accelerate matrix-vector multiplication. InProc. ACM/IEEE Design Autom. Conf., pages 1â€“6,
Austin, TX, June 2016.
S. Huang, X. Sun, X. Peng, H. Jiang, and S. Yu. Overcoming challenges for achieving high in-situ
training accuracy with emerging memories. InProc. Des. Autom. Test Eur. Conf., pages 1025â€“1030,
Grenoble, France, March 2020.
Y . Huang, Z. Wu, S. Ma, and Q. Ling. Single-timescale multi-sequence stochastic approximation
without fixed point smoothness: Theories and applications.IEEE Trans. Signal Process., 2025.
S. Jain, H. Tsai, C.-T. Chen, R. Muralidhar, I. Boybat, M. M. Frank, S. WoÂ´ zniak, M. Stanisavljevic,
P. Adusumilli, P. Narayanan, et al. A heterogeneous and programmable compute-in-memory
accelerator architecture for analog-ai using dense 2-d mesh.IEEE Trans. Very Large Scale Integr.
(VLSI) Syst., 31(1):114â€“127, January 2022.
H. Jia, M. Ozatay, Y . Tang, H. Valavi, R. Pathak, J. Lee, and N. Verma. Scalable and programmable
neural network inference accelerator based on in-memory computing.IEEE J. Solid-State Circuits,
57(1):198â€“211, 2021.
H. Jiang, L. Han, P. Lin, Z. Wang, M. H. Jang, Q. Wu, M. Barnell, J. J. Yang, H. L. Xin, and Q. Xia.
Sub-10 nm ta channel responsible for superior performance of a hfo2 memristor.Sci. Rep., 6(1):
28525, 2016.
L. Jiang, Q. Xiao, V . M. Tenorio, F. Real-Rojas, A. G. Marques, and T. Chen. A primal-dual-assisted
penalty approach to bilevel optimization with coupled constraints.arXiv preprint arXiv:2406.10148,
2024.
V . Joshi, M. Le Gallo, S. Haefeli, I. Boybat, S. R. Nandakumar, C. Piveteau, M. Dazzi, B. Rajendran,
A. Sebastian, and E. Eleftheriou. Accurate deep neural network inference using computational
phase-change memory.Nat. Commun., 11(1):2473, 2020.
H. Kim, J. Seo, S. Cho, S. Jeon, J. Woo, and D. Lee. Three-dimensional vertical structural electro-
chemical random access memory for high-density integrated synapse device.Sci. Rep., 13(1):
14325, 2023.
S. Kim, T. Todorov, M. Onen, T. Gokmen, D. Bishop, P. Solomon, K.-T. Lee, M. Copel, D. B. Farmer,
and J. A. Ott. Metal-oxide based, cmos-compatible ecram for deep learning accelerator. InIEEE
Int. Electron Devices Meet., pages 35â€“7, San Francisco, CA, December 2019.
M. Klachko, M. R. Mahmoodi, and D. Strukov. Improving noise tolerance of mixed-signal neural
networks. InProc. Int. Joint Conf. Neural Netw., pages 1â€“8, Budapest, Hungary, July 2019.
H. Kwak, N. Kim, S. Jeon, S. Kim, and J. Woo. Electrochemical random-access memory: Recent
advances in materials, devices, and systems towards neuromorphic computing.Nano Convergence,
11(1):9, 2024.
H. Kwak, J. Choi, S. Han, E. H. Kim, C. Kim, P. Solomon, J. Lee, D. Kim, B. Shin, and D. Lee. Un-
veiling ecram switching mechanisms using variable temperature hall measurements for accelerated
ai computation.Nat. Commun., 16(1):2715, 2025.
12

Y . Li, S. Kim, X. Sun, P. Solomon, T. Gokmen, H. Tsai, S. Koswatta, Z. Ren, R. Mo, and C.-C. Yeh.
Capacitor-based cross-point array for analog neural network with record symmetry and linearity.
InProc. IEEE Symp. VLSI Technol., pages 25â€“26, Honolulu, HI, June 2018.
S. Lu. Bilevel optimization with coupled decision-dependent distributions. InProc. International
Conference on Machine Learning, pages 22758â€“22789, Honolulu, HI, July 2023.
C. Mackin, M. J. Rasch, A. Chen, J. Timcheck, R. L. Bruce, N. Li, P. Narayanan, S. Ambrogio, M. Le
Gallo, S. R. Nandakumar, et al. Optimised weight programming for analogue memory-based deep
neural networks.Nat. Commun., 13(1):3765, July 2022.
B. Murmann. Mixed-signal computing for deep neural network inference.EEE Trans. Very Large
Scale Integr. (VLSI) Syst., 29(1):3â€“13, 2020.
S. R. Nandakumar, M. Le Gallo, C. Piveteau, V . Joshi, G. Mariani, I. Boybat, G. Karunaratne,
R. Khaddam-Aljameh, U. Egger, and A. Petropoulos. Mixed-precision deep learning based on
computational memory.Front. Neurosci., 14:406, 2020.
Y . Nesterov.Lectures on convex optimization, volume 137. Springer, Cham, 2018.
S. Park, A. Sheri, J. Kim, J. Noh, J. Jang, M. Jeon, B. Lee, B. R. Lee, B. H. Lee, and H.-J. Hwang.
Neuromorphic speech systems using advanced reram-based synapse. InIEEE Int. Electron Devices
Meet., pages 25â€“6, December 2013.
G. Pedretti, E. Ambrosi, and D. Ielmini. Conductance variations and their impact on the precision of
in-memory computing with resistive switching memory (rram). InIEEE International Reliability
Physics Symposium., pages 1â€“8, Monterey, CA, April 2021.
M. J. Rasch, D. Moreda, T. Gokmen, M. Le Gallo, F. Carta, C. Goldberg, K. El Maghraoui, A. Sebas-
tian, and V . Narayanan. A flexible and fast pytorch toolkit for simulating training and inference on
analog crossbar arrays. InProc. IEEE Int. Conf. AI Circuits Syst., pages 1â€“4, virtual, June 2021.
M. J. Rasch, F. Carta, O. Fagbohungbe, and T. Gokmen. Fast offset corrected in-memory training.
arXiv preprint arXiv:2303.04721, March 2023.
M. J. Rasch, F. Carta, O. Fagbohungbe, and T. Gokmen. Fast and robust analog in-memory deep
neural network training.Nat. Commun., 15(1):7133, 2024.
A. Reuther, P. Michaleas, M. Jones, V . Gadepally, S. Samsi, and J. Kepner. Ai and ml accelerator
survey and trends. InProc. IEEE High Perform. Extreme Comput. Conf., pages 1â€“10, Waltham,
MA, September 2022.
P. Rzeszut, J. ChË› eciÂ´nski, I. Brzozowski, S. ZiË› etek, W. SkowroÂ´nski, and T. Stobiecki. Multi-state
mram cells for hardware neuromorphic computing.Sci. Rep., 12(1):7178, April 2022. doi:
10.1038/s41598-022-11183-9.
H. Shen and T. Chen. A single-timescale analysis for stochastic approximation with multiple coupled
sequences. InProc. Advances in Neural Information Processing Systems, volume 35, pages
17415â€“17429, New Orleans, LA, December 2022.
L. Song, F. Chen, H. Li, and Y . Chen. Refloat: Low-cost floating-point processing in reram for
accelerating iterative linear solvers. InProc. Int. Conf. High Perform. Comput., Netw., Storage
Anal., pages 1â€“15, Denver, CO, November 2023.
W. Song, M. Rao, Y . Li, C. Li, Y . Zhuo, F. Cai, M. Wu, W. Yin, Z. Li, and Q. Wei. Programming
memristor arrays with arbitrarily high precision for analog computing.Science, 383(6685):903â€“
910, 2024.
S. Stathopoulos, A. Khiat, M. Trapatseli, S. Cortese, A. Serb, I. Valov, and T. Prodromakis. Multibit
memory operation of metal-oxide bi-layer memristors.Sci. Rep., 7(1):17532, December 2017. doi:
10.1038/s41598-017-17785-1.
T. Stecconi, V . Bragaglia, M. J. Rasch, F. Carta, F. Horst, D. F. Falcone, S. C. Ten Kate, N. Gong,
T. Ando, and A. Olziersky. Analog resistive switching devices for training deep neural networks
with the novel tiki-taka algorithm.Nano Lett., 24(3):866â€“872, 2024.
13

J. Stuecheli. Next generation power microprocessor. InHot Chips, Cupertino, CA, August 2013.
J. Tang, D. Bishop, S. Kim, M. Copel, T. Gokmen, T. Todorov, S. Shin, K.-T. Lee, P. Solomon, and
K. Chan. Ecram as scalable synaptic cell for high-speed, low-power neuromorphic computing. In
IEEE Int. Electron Devices Meet., pages 13â€“1, San Francisco, CA, December 2018.
A. Vasilopoulos, J. BÃ¼chel, B. Kersting, C. Lammie, K. Brew, S. Choi, T. Philip, N. Saulnier,
V . Narayanan, M. Le Gallo, et al. Exploiting the state dependency of conductance variations in
memristive devices for accurate in-memory computing.IEEE Transactions on Electron Devices,
70(12):6279â€“6285, December 2023.
Y . Wang, S. Wu, L. Tian, and L. Shi. SSM: A high-performance scheme for in situ training of
imprecise memristor neural networks.Neurocomputing, 407:270â€“280, 2020.
J. Woo, K. Moon, J. Song, S. Lee, M. Kwak, J. Park, and H. Hwang. Improved synaptic behavior
under identical pulses using alox/hfo2 bilayer rram array for neuromorphic systems.IEEE Electron
Device Lett., 37(8):994â€“997, 2016.
Z. Wu, T. Gokmen, M. Rasch, and T. Chen. Towards exact gradient-based training on analog
in-memory computing. InProc. Advances in Neural Information Processing Systems, pages
37264â€“37304, Vancouver, Canada, December 2024.
Z. Wu, Q. Xiao, T. Gokmen, O. Fagbohungbe, and T. Chen. Analog in-memory training on general
non-ideal resistive elements: The impact of response functions.arXiv preprint arXiv:2502.06309,
February 2025.
Y . Xi, B. Gao, J. Tang, A. Chen, M.-F. Chang, X. S. Hu, J. Van Der Spiegel, H. Qian, and H. Wu. In-
memory learning with analog resistive switching memory: A review and perspective.Proceedings
of the IEEE, 109(1):14â€“42, January 2020.
J. Xu, H. Liu, Z. Duan, X. Liao, H. Jin, X. Yang, H. Li, C. Liu, F. Mao, and Y . Zhang. Reharvest:
An adc resource-harvesting crossbar architecture for reram-based dnn accelerators.ACM Trans.
Archit. Code Optim., 21(3):1â€“26, 2024a.
J. Xu, H. Liu, X. Peng, Z. Duan, X. Liao, and H. Jin. A cascaded reram-based crossbar architecture
for transformer neural network acceleration.ACM Trans. Des. Autom. Electron. Syst., 30(1):1â€“23,
2024b.
S. Yang, M. Wang, and E. X. Fang. Multilevel stochastic gradient methods for nested composition
optimization.SIAM J. Optim., 29(1):616â€“659, 2019.
S. Zeng and T. Doan. Fast two-time-scale stochastic gradient method with applications in rein-
forcement learning. InConference on Learning Theory, pages 5166â€“5212, Edinburgh, UK, July
2024a.
S. Zeng and T. T. Doan. Accelerated multi-time-scale stochastic approximation: Optimal com-
plexity and applications in reinforcement learning and multi-agent games.arXiv preprint
arXiv:2409.07767, 2024b.
J. Zhang, Z. Wang, and N. Verma. In-memory computation of a machine-learning classifier in a
standard 6t sram array.IEEE J. Solid-State Circuits, 52(4):915â€“924, 2017.
14

Supplementary Materials
A LITERATUREREVIEW
This section briefly reviews literature that is related to this paper, as complementary to Section 1.2.
Gradient-based training on AIMC hardware.Since the introduction ofrank-update-basedAnalog
SGD (Gokmen and Vlasov, 2016), various techniques have been proposed to improve its robustness
under non-ideal device behavior. To mitigate asymmetric updates and noise accumulation in Analog
SGD, TT-v1 uses an auxiliary array to accumulate a moving average of gradients, periodically
transferring them to the main array (Gokmen and Haensch, 2020). TT-v2 enhances this approach with
digital filtering to improve robustness against noise and low conductance (Gokmen, 2021). However,
despite these refinements, rank-update methods still struggle to converge reliably when scaling to
larger models under limited conductance states. Some in-memory analog training approaches employ
hybrid 3T1Câ€“PCM synapses, which rely on closed-loop tuning (CLT) with about 20 writeâ€“verify
retries to transfer gradients from the linear 3T1C capacitor to the non-ideal PCM device (Ambrogio
et al., 2018; Cristiano et al., 2018). While precise, CLT introduces substantial latency, energy, and
control overhead, and the bulky 3T1C CMOS cells also limit array density compared to compact
memristive devices, which has motivated a shift toward more compact, modestly linear NVMs.
Moreover, the volatile nature of CMOS capacitors means that the effective number of valid states is
ultimately determined by the non-volatile PCM, preventing extension to arbitrary precision beyond the
intrinsic limits of memristive devices. Our approach avoids the use of auxiliary CMOS components
and iterative CLT, and instead employs fully asymmetric and limited-precision memristor-based
synapses, which are trained in-memory through a simpleopen-loop transfermechanism between tiles
and can achieve high-precision training. Meanwhile, another class of in-memory training approaches
known ashybrid training paradigmshas emerged.The MP approach (Gallo et al., 2018), for example,
computes gradients digitally and directly programs these high-precision gradients into low-precision
analog weights, enabling high-accuracy training even with very few conductance states. Subsequent
extensions (Wang et al., 2020; Huang et al., 2020) incorporate momentum to further suppress gradient
noise. However, these methods often incur higher storage, memory access, and computational costs.
Device Name # States Mature
Capacitor (Li et al., 2018) 400âœ“
ECRAM (Tang et al., 2018) 1000âœ—
ECRAM (MO) (Kim et al., 2019) 7100âœ—
PCM (Nandakumar et al., 2020) 200âœ“
RERAM (OM) (Gong et al., 2022) 21âœ“
RERAM (HfO2) (Gong et al., 2022) 4âœ“
RERAM (AlOx/HfO2) (Woo et al., 2016) 40âœ“
RERAM (PCMO ) (Park et al., 2013) 50âœ“
RERAM (HfO2) (Jiang et al., 2016) 26âœ“
Table 3: Comparison of representative analog memory devices
used for DNN training. Here,Maturedenotes whether the corre-
sponding class of memristor devices has been demonstrated with
stable and reproducible fabrication processes (Joshi et al., 2020).
Low-precision computing.Ex-
isting works have mainly demon-
strated how low-precision de-
vices can support high-precision
computing in scientific comput-
ing and DNN inference. In sci-
entific computing, algorithmic
techniques have been proposed
to achieve high-precision arith-
metic on binary devices Fein-
berg et al. (2018); Song et al.
(2023), and residual program-
ming strategies sequentially ap-
proximate the residuals of pre-
viously programmed tiles Song
et al. (2024). The residual con-
cept has also inspired precision-enhancing strategies in DNN inference, where multiple cells are
used to encode high-precision weights Gallo et al. (2022); Pedretti et al. (2021); Boybat et al. (2018).
Varying the significance of these devices has been shown to yield further accuracy improvements
Mackin et al. (2022). Unlike these approaches that operate on static weights, our method tackles
the more challenging setting of training, where weights dynamically evolve under asymmetric and
low-precision updates across multiple coupled tiles, and must still converge jointly toward the optimal
solution. Alternative precision enhancement strategies include incorporating hardware specific noises
into the training process to improve inference accuracy Klachko et al. (2019); He et al. (2019). Other
approaches include logarithmic weight-to-conductance mappings that bias encoding toward more
15

stable device states Vasilopoulos et al. (2023), and inference Zhang et al. (2017) through weighted
majority voting after offline learning of binary weights and column-specific scaling factors.
Memristor devices.To provide an intuitive overview of the characteristics of current analog memris-
tor devices, particularly their conductance states, we survey recent works on ReRAM (Stathopoulos
et al., 2017; Chang et al., 2011), PCM (Burr et al., 2015; 2016), MRAM (Apalkov et al., 2013; Rzeszut
et al., 2022), and ECRAM (Fuller et al., 2019), and summarize their reported conductance state
information in Table 3. In this work, our experiments and analysis primarily focus on bi-directionally
updated devices such as ReRAM, which represent one of the most practically relevant device classes
for analog training. To the best of our knowledge, most reported ReRAM devices provide fewer
than 100 distinct conductance levels, with practical demonstrations typically limited to around 4-bit
precision, which poses a fundamental limitation for scaling analog training to larger models. As
illustrated in Table 11, where we conducted experiments on ResNet-34 with a larger portion of the
model converted into analog and using 80 states, accuracy collapses for TT-v1 and remains far below
our method even when TT-v2 is given the same device with only three tiles. These results suggest
that our residual multi-tile mechanism is necessary for scaling analog training to larger models, rather
than relying on extremely high-precision device assumptions.
B RELATEDWORKWU ET AL. (2024; 2025)
This paper can be viewed as an extension of Wu et al. (2024; 2025) to the multi-tile setting, specifically
designed to address the quantization noise arising from the limited conductance states in analog
in-memory training. We adopt the analog training dynamics model:
Wt+1 =W t + âˆ†Wt âŠ™F(W t)âˆ’ |âˆ†W t| âŠ™G(W t)(8)
and build upon the asymptotic error analysis of Analog SGD presented in Theorem 4, which originates
from the asymmetric non-idealities studied in Wu et al. (2024; 2025). In addition, we explicitly
incorporate thelimited states non-ideality, introducing the quantization noise term Î¶t into both the
model equation 2 and the convergence proof, thereby capturing the impact of discrete conductance
levels on analog training.
Challenge of analyzing the convergence with generic response functions.Wu et al. (2024)
investigates analog training under theasymmetric linear device (ALD)model, where the pulse
response factors are defined as:
q+(w) = 1âˆ’ wâˆ’w â‹„
Ï„max
, q âˆ’(w) = 1 + wâˆ’w â‹„
Ï„max
(9)
with wâ‹„ denoting the symmetric conductance point such that q+(wâ‹„) =q âˆ’(wâ‹„) (Rasch et al., 2023).
By Assumption 4, this point can be shifted to zero, i.e., wâ‹„ = 0. In this case, the symmetric and
asymmetric components reduce to F(w) = 1 and G(w) =|w|/Ï„ max, which simplifies the Analog
SGD recursion equation 3 into the structured form:
Wt+1 =W t âˆ’Î± tâˆ‡f(W t;Î¾ t)âˆ’ Î±t
Ï„max
|âˆ‡f(W t;Î¾ t)| âŠ™W t.(10)
This recursion admits a special structure where the first term and the bias term can be combined,
leading to:
Wt+1 =

1âˆ’ Î±t
Ï„max
|âˆ‡f(W t;Î¾ t)|

âŠ™W t âˆ’Î± tâˆ‡f(W t;Î¾ t)(11)
which is a weighted average of Wt and âˆ‡f(W t;Î¾ t). From this perspective, the transfer operation can
be interpreted asbiased gradient descent, with the linear response enabling a tractable analysis. In
contrast, Wu et al. (2025) considers the more challenging general case where the response functions
are not necessarily linear:
Wt+1 =W t âˆ’Î±âˆ‡f(W t;Î¾ t)âŠ™F(W t)âˆ’ |Î±âˆ‡f(W t;Î¾ t)| âŠ™G(W t).(12)
In this setting, the above decomposition is no longer viable, complicating the analysis. To address this
difficulty, the authors leverage the Lipschitz continuity of the response functions and establish bounds
that relate G(Wt) to Wt, thereby recovering a weighted average interpretation of Wt even under
general nonlinear responses. In our paper, we adopt the generic-response to establish the scalability
of our algorithm.
16

Challenge of analyzing the convergence with quantization noise.The quantization noise has statis-
tical properties with zero mean and variance proportional toÎ˜(Î±âˆ†wmin), which after normalizing by
the step size Î± leads to a residual error of order âˆ†wmin that does not vanish as T increases, thereby
introducing an additional asymptotic error term in Analog SGD. As we will prove in Section F, the
asymptotic error is bounded by
1
T
Tâˆ’1X
t=0
E[âˆ¥W âˆ— âˆ’W tâˆ¥2]â‰¤ O

RT
q
2(f(W 0)âˆ’f âˆ—)Ïƒ2
T

+ 4Ïƒ2ST +R T âˆ†wmin (13)
while the work in Wu et al. (2025) only considers the error from asymmetric updates, which originates
from the absolute stochastic gradient term |Î±âˆ‡f(W t;Î¾ t)| in equation 3 and leads to an asymptotic
error of orderÏƒ 2:
1
T
Tâˆ’1X
t=0
E[âˆ¥W âˆ— âˆ’W tâˆ¥2]â‰¤ O
q
2(f(W 0)âˆ’f âˆ—)Ïƒ2
T

+ 4Ïƒ2ST .(14)
Challenge of analyzing the convergence with multiple-tiles.From the bilevel optimization per-
spective, the convergence analysis in Wu et al. (2025) for the two-tile case amounts to solving the
following two-sequence nested problem:
arg min
W (0)âˆˆRD
âˆ¥P âˆ—
1 (W (0))âˆ¥2,s.t.P âˆ—
1 (W (0))âˆˆarg min
PâˆˆR D
f(W (0) +Î³P).(15)
In contrast, our multi-tile residual learning algorithm generalizes this formulation to a multi-sequence
bilevel optimization problem as described in Section 3:
W (0) := arg min
U0
âˆ¥U0 âˆ’P âˆ—
0 âˆ¥2, P âˆ—
0 :=W âˆ—,
W (1) := arg min
U1
âˆ¥U1 âˆ’P âˆ—
1 (W
(1)
)âˆ¥2,s.t.P âˆ—
1 (W
(1)
) := arg min
P1
f( W
(1)
+Î³P 1),
. . .
W (N) := arg min
UN
âˆ¥UN âˆ’P âˆ—
N(W
(N)
)âˆ¥2,s.t.P âˆ—
N(W
(N)
) := arg min
PN
f( W
(N)
+Î³ N PN).(16)
The analysis of multi-sequence residual learning is substantially more challenging than the two-tile
case. First, each tile must track a drifting optimum that recursively depends on the composite
weights of all preceding tiles, creating a deeply nested dependency that complicates the convergence
analysis. Second, the quantization error from different tiles are not isolated but accumulate and
couple across layers, requiring global measures such as Lyapunov functions to capture their joint
dynamics, meanwhile ensuring that the overall error decays as more tiles are introduced. As detailed
in Section 3 and G, we address these difficulties using a multi-timescale learning strategy, where each
tile is updated in its own inner loop with sufficiently long iterations, while the preceding tiles are
frozen until the current tile converges close enough to its quasi-stationary optimum.
C MAPPINGCOEFFICIENTSETTING
In AIMC, eachlogical weight W is physically represented by mapping the difference between
twophysical conductancevalues: a main conductance Cmain and a reference conductance Cref.
Specifically, the mapping takes the form:
W=ÎºC=Îº(C main âˆ’C ref)(17)
where Îº is a fixed scaling constant that determines the logical weight range based on the physical
conductance range of the device.
This representation scheme allows the hardware to represent both positive and negative weights
using non-negative conductance values, which are physically realizable. Before proceeding with
the analysis, we clarify a slight abuse of notation used in the main text. In our notation, we do not
explicitly distinguish between the physical conductance C of the memristive crossbar array and the
corresponding logical weight W , which are related by a fixed mapping constant. However, it is
important to note that the device-level response functions qÂ±(Â·) as well as symmetric and asymmetric
components F(Â·) and G(Â·) are defined over the conductance domain. In the following theoretical
17

âˆ†cmin
âˆ’Ï„ +Ï„0
(a) A 10-state memristive device with range[âˆ’Ï„,+Ï„] and increment
âˆ†cmin.
âˆ†cmin
âˆ’Ï„ +Ï„0
âˆ¥Wkâˆ¥âˆž
Îº
(b) WithÎº=O(1), weights span most of the conductance range.
âˆ†cmin
âˆ’Ï„ +Ï„0
âˆ¥Wkâˆ¥âˆž
Îº
(c) WithÎº=O(Î³ âˆ’N/4), weights lie well inside the range.
Figure 8: Comparison of dynamic ranges and weight distributions under differentÎº.
analysis, we will reintroduce this mapping explicitly when necessary to ensure mathematical cor-
rectness. In fact, the conductance-update rule is derived using the same approach as the update rule
presented in equation 2 of the main text:
Ct+1 =C t + âˆ†Ct âŠ™F(C t)âˆ’ |âˆ†C t| âŠ™G(C t) + Î¶t
Îº (18)
where Î¶t is a stochastic quantization noise term introduced by the finite weight resolution âˆ†wmin,
with E[Î¶t] = 0,Var[Î¶ t] = Î˜(Î±Â·âˆ†w min). Here Î± is the learning rate. See details in Lemma 1. We
rewrite equation 2 in its exact form by multiplyÎºon both sides of equation 18:
Wt+1 =W t + âˆ†Wt âŠ™F
  Wt
Îº

âˆ’ |âˆ†Wt| âŠ™G
  Wt
Îº

+Î¶ t.(19)
All theoretical guarantees in Section F.2 and G are proved using equation 19; the shorthand equation 2
is retained elsewhere to keep the notation compact. Furthermore, although the logical weight
WâˆˆR DÃ—D in the main text, the proof part focuses on a vector-valued WâˆˆR D while retaining
the same uppercase notation to distinguish it from scalar elements w. This simplification is justified
because, in analog updatesâ€”whether during gradient updates or transfer updatesâ€”each column of
the weight matrix behaves identically. Specifically, during gradient updates, all elements in a column
are updated in parallel, and during transfer updates, updates are applied column-wise from one tile
to another. Therefore, the vector setting captures the essential behavior without loss of generality.
Table 4 summarizes the notations that appear in both the main text and the proofs, especially those
where conductance and weight representations may be easily confused.
In section G, the mapping constant Îº is set as O(Î³ âˆ’ N
4 ) to make Theorem 3 hold. This setting is
feasible because increasing the mapping coefficient Îº narrows the physical conductance range used
to represent the same logical weight values. Figure 8 illustrates that when the logical weights are
concentrated well within the conductance boundaries, the impact of non-ideal device behaviors such
as saturation, nonlinearities, or non-monotonicity is significantly reduced. This makes the training
process more robust.
D NOTATIONS
In this section, we define a series of notations that will be used in the analysis.
Pseodo-inverse of diagonal matrix or vector.For a given diagonal matrix UâˆˆR DÃ—D with its i-th
diagonal element [U] i, we define the pseudo-inverse of a diagonal matrix U as U â€ , which is also a
diagonal matrix with itsi-th diagonal element:
[U â€ ]i :=
1/[U] i,[U] i Ì¸= 0,
0,[U] i = 0. (20)
By definition, the pseudo-inverse satisfies U Uâ€ V=U â€ U V for any diagonal matrix UâˆˆR D and
any matrix VâˆˆR D. With a slight abuse of notation, we also define the pseudo-inverse of a vector
WâˆˆR D asW â€  :=diag(W) â€ .
18

Symbol Meaning
Conductance domain
[âˆ’Ï„, Ï„]Physical conductance range
Ct Matrix of physical conductance at stept
ct Scalar conductance value of a single element at stept
âˆ†cmin Minimum conductance increment from one pulse atc= 0
F(c), G(c)Symmetric and asymmetric components of conductance
q+(c), qâˆ’(c)Upward and downward pulse response factors at conductancec
U(c,âˆ†c)Approximate analog update over conductance
U BL
p (c, s)Pulse-based update using bit-length pulses in conductance domain
Weight domain
[Ï„min, Ï„max]Logical weight range used in training
Wt Matrix of logical weights at stept
wt Scalar logical weight of a single element at stept
âˆ¥Wtâˆ¥âˆž Maximum absolute value among all elements inW t
Wmax Upper bound ofâˆ¥W tâˆ¥âˆž for allt, lies in[âˆ¥W tâˆ¥âˆž, Ï„max)
âˆ†wmin Minimum weight increment from one pulse atw= 0
F(w), G(w)Symmetric and asymmetric components evaluated asF(w/Îº), G(w/Îº)
q+(w), qâˆ’(w)Pulse response factors evaluated asq Â±(w) :=q Â±(w/Îº)
U(w,âˆ†w)Approximate analog update over logical weights
U BL
p (w, s)Pulse-based update using bit length in weight domain
Shared / Mapping
ÎºMapping constant:W=ÎºC
Table 4: Notations in the conductance and weight domains
Weighted norm.For a given weight vector SâˆˆR D
+, the weighted norm âˆ¥ Â· âˆ¥S of vector WâˆˆR D is
defined by:
âˆ¥Wâˆ¥ S :=
vuut
DX
d=1
[S]d[W] 2
d =W âŠ¤diag(S)W(21)
where diag(S)âˆˆR DÃ—D
+ rearranges the vectorSinto a diagonal matrix.
Lemma 4. âˆ¥Wâˆ¥ S has the following properties: (1) âˆ¥Wâˆ¥ S =âˆ¥WâŠ™
âˆš
Sâˆ¥; (2) âˆ¥Wâˆ¥ S â‰¤
âˆ¥Wâˆ¥
p
âˆ¥Sâˆ¥âˆž; (3)âˆ¥Wâˆ¥ S â‰¥ âˆ¥Wâˆ¥
p
min{[S]i :iâˆˆ I}.
E USEFULLEMMAS
E.1 LEMMA1: PULSE UPDATE ERROR
Lemma 1(Statistical properties of pulse update noise).Under the stochastic pulse update in (Gokmen
and Vlasov, 2016), the random variableÎ¶ ij has the following properties:
E[Î¶ij] = 0,andVar[Î¶ ij] = Î˜(Î±Â·âˆ†w min).
Proof of Lemma 1. Each weight update âˆ†wij is the sum of BL independent Bernoulli trials , with
BLlarge enough to satisfy Î±|xiÎ´j |
BLÂ·âˆ†wmin
â‰¤1:
âˆ†wij =
BLX
t=1
Zt (22)
where:
Zt =
(
âˆ†wmin Â·sign(x iÎ´j),with probabilityp:= |Î±xiÎ´j |
BLÂ·âˆ†wmin
,
0,with probability1âˆ’p. (23)
19

Then:
E[Zt] = âˆ†wmin Â·sign(x iÎ´j)Â·p= Î±xiÎ´j
BL ,E[Z 2
t ] = âˆ†w2
min Â·p.(24)
The equality holds forsign(x iÎ´j)Â· |x iÎ´j|=x iÎ´j. So the variance of a single trial is:
Var[Zt] =E[Z 2
t ]âˆ’E[Z t]2 = âˆ†w2
minp(1âˆ’p).(25)
Then summing overBLtrials:
E[âˆ†wij] =BLÂ·E[Z t] =Î±x iÎ´j,Var[âˆ†w ij] =BLÂ·âˆ†w 2
min Â·pÂ·(1âˆ’p).(26)
Thus,
E[Î¶ij] =E[âˆ†w ij]âˆ’Î±x iÎ´j = 0.(27)
Moreover, substitutingp= |Î±xiÎ´j|
BLÂ·âˆ†w min
intoVar[âˆ†w ij], we get:
Var[âˆ†wij] =BLÂ·âˆ†w 2
min Â· |Î±xiÎ´j|
BLÂ·âˆ†w min
Â·

1âˆ’ |Î±xiÎ´j|
BLÂ·âˆ†w min

.(28)
Thus,
Var[Î¶ij] = Var[âˆ†wij] =Î±|x iÎ´j| Â·âˆ†w min Â·

1âˆ’ Î±|xiÎ´j|
BLÂ·âˆ†w min

= Î˜(Î±Â·âˆ†w min).(29)
E.2 LEMMA5: LIPSCHITZ CONTINUITY OF ANALOG UPDATE
Lemma 5.Under Assumption 4, the analog increment defined in equation 2 is Lipschitz continuous
with respect to âˆ†W in terms of any weighted norm âˆ¥ Â· âˆ¥ S, i.e., for any W,âˆ†W,âˆ†W â€² âˆˆR D and
SâˆˆR D
+, it holds
âˆ¥âˆ†WâŠ™F(W)âˆ’ |âˆ†W| âŠ™G(W)âˆ’(âˆ†W â€² âŠ™F(W)âˆ’ |âˆ†W â€²| âŠ™G(W))âˆ¥ S (30)
â‰¤F maxâˆ¥âˆ†Wâˆ’âˆ†W â€²âˆ¥S.
The proof of Lemma 5 can be found in (Wu et al., 2025, Section C).
Lemma 6.Under Assumption 4, the following statements about the response factors are valid; (1)
the symmetric part F(Â·) is upper bounded by a constant Fmax >0 , i.e. F(w)â‰¤F max,âˆ€wâˆˆR ; (2)
The following inequality holds
âˆ’F(w)â‰¤G(w)â‰¤F(w)(31)
whereG(w) =âˆ’F(w)andG(w) =F(w)hold only whenw=Ï„ min andw=Ï„ max, respectively.
E.3 LEMMA7: ELEMENT-WISE PRODUCT ERROR
Lemma 7.LetU, V, Qbe vectors indexed byI. Then the following inequality holds
âŸ¨U, VâŠ™QâŸ© â‰¥C +âŸ¨U, VâŸ© âˆ’C âˆ’âŸ¨|U|,|V|âŸ©(32)
where the constantC + andC âˆ’ are defined by
C+ :=1
2

max
iâˆˆI
{[Q]i}+ min
iâˆˆI
{[Q]i}

,(33)
Câˆ’ :=1
2

max
iâˆˆI
{[Q]i} âˆ’min
iâˆˆI
{[Q]i}

.(34)
The proof of Lemma 7 can be found in (Wu et al., 2025, Section C).
F PROOF OFANALOGSTOCHASTICGRADIENTDESCENTCONVERGENCE
F.1 CONVERGENCE OFANALOGSGD
In this section, we derive the convergence guarantee ofAnalog SGDunder the hardware-constrained
update rule in equation 19.
20

Theorem 4(Convergence of Analog SGD, long version of Theorem 1).Suppose Assumptions 1, 3, 4
hold, if the learning rate is set asÎ±=O(
q
2(f(W 0)âˆ’f âˆ—)
Ïƒ2T ), then it holds that:
1
T
Tâˆ’1X
t=0
E[âˆ¥W âˆ— âˆ’W tâˆ¥2]â‰¤ O
 
RT
r
2(f(W0)âˆ’f âˆ—)Ïƒ2
T
!
+ 4Ïƒ2ST +R T âˆ†wmin
whereS T andR T denote the amplification factor given by :
ST := 1
T
Tâˆ’1X
t=0
âˆ¥Wtâˆ¥2
âˆž/Ï„ 2
max
1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max
, R T := 1
T
Tâˆ’1X
t=0
2L
1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max
.(35)
Proof of Theorem 4.TheL-smooth assumption (Assumption 2) implies that:
EÎ¾t,Î¶t[f(W t+1)]â‰¤f(W t) +E Î¾t,Î¶t[âŸ¨âˆ‡f(W t), Wt+1 âˆ’W tâŸ©]| {z }
(a)
+ L
2 EÎ¾t,Î¶t[âˆ¥Wt+1 âˆ’W tâˆ¥2]
| {z }
(b)
.(36)
The term (a) in equation 36 can be bounded by Assumption 1 that EÎ¾t,Î¶t[âˆ‡f(W t;Î¾ t)] =âˆ‡f(W t)
and2âŸ¨U, VâŸ©=âˆ¥U+Vâˆ¥ 2 âˆ’ âˆ¥Uâˆ¥ 2 âˆ’ âˆ¥Vâˆ¥ 2:
EÎ¾t,Î¶t[âŸ¨âˆ‡f(W t), Wt+1 âˆ’W tâŸ©](37)
=Î± tEÎ¾t,Î¶t
ï£®
ï£°
*
âˆ‡f(W t)âŠ™
r
F( Wt
Îº ), Wt+1 âˆ’W t
Î±t
q
F( Wt
Îº )
+
r
F( Wt
Îº )âŠ™(âˆ‡f(W t;Î¾ t)âˆ’ âˆ‡f(W t))âˆ’ Î¶t
Î±t
q
F( Wt
Îº )
+ï£¹
ï£»
=âˆ’ Î±t
2

r
F( Wt
Îº )âŠ™ âˆ‡f(W t)

2
âˆ’ 1
2Î±t
EÎ¾t,Î¶t
ï£®
ï£¯ï£°

Wt+1 âˆ’W tq
F( Wt
Îº )
+Î± t
r
F( Wt
Îº )âŠ™(âˆ‡f(W t;Î¾ t)âˆ’ âˆ‡f(W t))âˆ’ Î¶tq
F( Wt
Îº )

2ï£¹
ï£ºï£»
+ 1
2Î±t
EÎ¾t
ï£®
ï£¯ï£°

Wt+1 âˆ’W tq
F( Wt
Îº )
+Î± t
r
F( Wt
Îº )âŠ™ âˆ‡f(W t;Î¾ t)âˆ’ Î¶tq
F( Wt
Îº )

2ï£¹
ï£ºï£» .
The second term in equation 37 can be bounded by
1
2Î±t
EÎ¾t,Î¶t
ï£®
ï£¯ï£°

Wt+1 âˆ’W tq
F( Wt
Îº )
+Î± t
r
F( Wt
Îº )âŠ™(âˆ‡f(W t;Î¾ t)âˆ’ âˆ‡f(W t))âˆ’ Î¶tq
F( Wt
Îº )

2ï£¹
ï£ºï£» (38)
= 1
2Î± EÎ¾t,Î¶t
ï£®
ï£¯ï£°

Wt+1 âˆ’W t +Î±(âˆ‡f(W t;Î¾ t)âˆ’ âˆ‡f(W t))âŠ™F( Wt
Îº )âˆ’Î¶ tq
F( Wt
Îº )

2ï£¹
ï£ºï£»
â‰¥ 1
2Î±Fmax
EÎ¾t,Î¶t
"Wt+1 âˆ’W t +Î±(âˆ‡f(W t;Î¾ t)âˆ’ âˆ‡f(W t))âŠ™F( Wt
Îº )âˆ’Î¶ t

2#
.
The last inequality holds by defining a constant Fmax such that âˆ¥F(W)âˆ¥ âˆž â‰¤F max. The third
term in equation 37 can be bounded by variance decomposition and bounded variance assumption
(Assumption 1)
1
2Î±t
EÎ¾t
ï£®
ï£¯ï£°

Wt+1 âˆ’W tq
F( Wt
Îº )
+Î± t
r
F( Wt
Îº )âŠ™ âˆ‡f(W t;Î¾ t)âˆ’ Î¶tq
F( Wt
Îº )

2ï£¹
ï£ºï£» (39)
= Î±t
2 EÎ¾t
ï£®
ï£¯ï£°

|âˆ‡f(W t;Î¾ t)| âŠ™ G( Wt
Îº )q
F( Wt
Îº )

2ï£¹
ï£ºï£»
21

â‰¤ Î±t
2

|âˆ‡f(W t)| âŠ™ G( Wt
Îº )q
F( Wt
Îº )

2
+ Î±tÏƒ2
2

G( Wt
Îº )q
F( Wt
Îº )

2
âˆž
.
Define the saturation vector the saturation vectorH(W t)âˆˆR D as:
H(W t) :=F
 Wt
Îº
âŠ™2
âˆ’G
 Wt
Îº
âŠ™2
(40)
=

F
 Wt
Îº

+G
 Wt
Îº

âŠ™

F
 Wt
Îº

âˆ’G
 Wt
Îº

=q +
 Wt
Îº

âŠ™q âˆ’
 Wt
Îº

.
Note that the first term in the right-hand side (RHS) of equation 36 and the second term in the RHS
of equation 39 can be bounded by
âˆ’ Î±t
2
âˆ‡f(W t)âŠ™
r
F( Wt
Îº )

2
+ Î±t
2

|âˆ‡f( Wt
Îº )| âŠ™ G( Wt
Îº )q
F( Wt
Îº )

2
(41)
=âˆ’ Î±t
2
X
dâˆˆ[D]
 
[âˆ‡f(W t)]2
d
 
[F( Wt
Îº )]d âˆ’ [G( Wt
Îº )]2
d
[F( Wt
Îº )]d
!!
=âˆ’ Î±t
2
X
dâˆˆ[D]
 
[âˆ‡f(W t)]2
d
 
[F( Wt
Îº )]2
d âˆ’[G( Wt
Îº )]2
d
[F( Wt
Îº )]d
!!
â‰¤ âˆ’ Î±t
2Fmax
X
dâˆˆ[D]

[âˆ‡f(W t)]2
d

[F( Wt
Îº )]2
d âˆ’[G( Wt
Îº )]2
d

=âˆ’ Î±t
2Fmax
âˆ¥âˆ‡f(W t)âˆ¥2
H(W t) â‰¤0.
Plugging equation 38 to equation 41 into equation 37, we bound the term (a) by
EÎ¾t,Î¶t[âŸ¨âˆ‡f(W t), Wt+1 âˆ’W tâŸ©](42)
=âˆ’ Î±t
2Fmax
âˆ¥âˆ‡f(W t)âˆ¥2
H(W t) + Î±tÏƒ2
2

G( Wt
Îº )q
F( Wt
Îº )

2
âˆž
âˆ’ 1
2Î±Fmax
EÎ¾t,Î¶t
"Wt+1 âˆ’W t +Î±(âˆ‡f(W t;Î¾ t)âˆ’ âˆ‡f(W t))âŠ™F( Wt
Îº )âˆ’Î¶ t

2#
.
The term (b) in equation 36 can be bounded byE Î¾t[âˆ¥âˆ‡f(W t;Î¾ t)âˆ’ âˆ‡f(W t)âˆ¥2]â‰¤Ïƒ 2:
L
2 EÎ¾t,Î¶t[âˆ¥Wt+1 âˆ’W tâˆ¥2](43)
â‰¤LE Î¾t,Î¶t
"Wt+1 âˆ’W t +Î± t(âˆ‡f(W t;Î¾ t)âˆ’ âˆ‡f(W t))âŠ™F( Wt
Îº )âˆ’Î¶ t

2#
+LE Î¾t
"Î±t(âˆ‡f(W t;Î¾ t)âˆ’ âˆ‡f(W t))âŠ™F( Wt
Îº ) +Î¶ t

2#
â‰¤LE Î¾t,Î¶t
"Wt+1 âˆ’W t +Î± t(âˆ‡f(W t;Î¾ t)âˆ’ âˆ‡f(W t))âŠ™F( Wt
Îº )âˆ’Î¶ t

2#
+ 2Î±2
t F 2
maxLÏƒ2 + 2LF2
max Â·Î˜(Î± tâˆ†wmin).
Substituting equation 42 and equation 43 back into equation 36, we have
EÎ¾t,Î¶t[f(W t+1)](44)
22

â‰¤f(W t)âˆ’ Î±t
2Fmax
âˆ¥âˆ‡f(W t)âˆ¥2
H(W t) + 2Î±2
t LF 2
maxÏƒ2 + Î±tÏƒ2
2

G( Wt
Îº )q
F( Wt
Îº )

2
âˆž
+ 2LF2
max Â·Î˜(Î± tâˆ†wmin)
âˆ’ 1
Fmax
 1
2Î±t
âˆ’LF max

EÎ¾t,Î¶t
"Wt+1 âˆ’W t +Î±(âˆ‡f(W t;Î¾ t)âˆ’ âˆ‡f(W t))âŠ™F( Wt
Îº )âˆ’Î¶ t

2#
â‰¤f(W t)âˆ’ Î±t
2Fmax
âˆ¥âˆ‡f(W t)âˆ¥2
H(W t) + 2Î±2
t LF 2
maxÏƒ2 + Î±tÏƒ2
2

G( Wt
Îº )q
F( Wt
Îº )

2
âˆž
+ 2LF2
max Â·Î˜(Î± tâˆ†wmin).
The last inequality holds whenÎ± t â‰¤ 1
2LFmax
. Taking average overt, we get:
1
T
Tâˆ’1X
t=0
E[âˆ¥âˆ‡f(W t)âˆ¥2
H(W t)](45)
â‰¤ 2Fmax(f(W0)âˆ’f(W T ))
Î±tT + 4LF3
maxÎ±tÏƒ2 +Ïƒ 2Fmax
1
T
Tâˆ’1X
t=0

G( Wt
Îº )q
F( Wt
Îº )

2
âˆž
+ 4LF3
maxÎ˜(âˆ†wmin)
â‰¤ O
 
F 2
max
r
8L(f(W0)âˆ’f âˆ—)Ïƒ2
T
!
+Â§ T FmaxÏƒ2 + 4LF3
maxÎ˜(âˆ†wmin).
The second inequality holds by choosingÎ±=O(
q
f(W 0)âˆ’f âˆ—
2LF 2maxÏƒ2T ). ST denotes the amplification factors
given by:
ST := 1
T
Tâˆ’1X
t=0

G( Wt
Îº )q
F( Wt
Îº )

2
âˆž
.(46)
Since Âµ(Wâˆ’W âˆ—)â‰¤ âˆ‡f(W) , we multiply both sides by Âµ and normalize by the constant Hmin,
defined as Hmin := min tâˆˆ0,1,...,Tâˆ’1 Hmin,t,whereH min,t â‰¤ âˆ¥H(W t)âˆ¥âˆž. This yields the upper
bound for Analog SGD on general response factors:
1
T
Tâˆ’1X
t=0
E[âˆ¥W âˆ— âˆ’W tâˆ¥2]
â‰¤ O
 
F 2
max
Hmin
r
8L(f(W0)âˆ’f âˆ—)Ïƒ2
T
!
+ ST Fmax
Hmin
Ïƒ2 + 4LF 3
max
Hmin
Î˜(âˆ†wmin).(47)
For concrete illustration, we now analyze the asymmetric linear device described in Section B and
equation 10. We can naturally get that Fmax = 1, Hmin,t = 1âˆ’ âˆ¥Wtâˆ¥2
âˆž
Ï„ 2max
. Rearranging equation 44 as
EÎ¾t,Î¶t[f(W t+1)](48)
â‰¤f(W t)âˆ’ Î±t
2(1âˆ’ âˆ¥Wtâˆ¥2âˆž
Ï„ 2max
)
âˆ¥âˆ‡f(W t)âˆ¥2 + 2Î±2
t LÏƒ2 + Î±tÏƒ2âˆ¥Wtâˆ¥2
âˆž
2Ï„ 2max
+ 2LÂ·Î˜(Î± tâˆ†wmin).
Divide both sides of equation 48 by1âˆ’ âˆ¥W tâˆ¥2
âˆž/Ï„ 2
max >0and average overt:
1
T
Tâˆ’1X
t=0
E[âˆ¥âˆ‡f(W t)âˆ¥2]â‰¤ 2RT (f(W0)âˆ’E[f(W T )])
Î±tT +R T Î±tÏƒ2 + 4Ïƒ2ST +R T Î˜(âˆ†wmin)
â‰¤ 2RT (f(W0)âˆ’f âˆ—)
Î±tT +R T Î±tÏƒ2 + 4Ïƒ2ST +R T Î˜(âˆ†wmin).(49)
Here,S T andR T denote the amplification factors given by :
ST := 1
T
Tâˆ’1X
t=0
âˆ¥Wtâˆ¥2
âˆž/Ï„ 2
max
1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max
, R T := 1
T
Tâˆ’1X
t=0
2L
1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max
.(50)
23

Choosing Î±=O(
q
2(f(W 0)âˆ’f âˆ—)
Ïƒ2T ), when Tâ†’ âˆž , it satisfies that Î±â‰¤ 1
2L and equation 49 becomes:
1
T
Tâˆ’1X
t=0
E[âˆ¥âˆ‡f(W t)âˆ¥2]â‰¤ O
 
RT
r
2(f(W0)âˆ’f âˆ—)Ïƒ2
T
!
+ 4Ïƒ2ST +R T âˆ†wmin.(51)
SinceÂµ(Wâˆ’W âˆ—)â‰¤ âˆ‡f(W), multiplyingÂµon both sides, we get:
1
T
Tâˆ’1X
t=0
E[âˆ¥W âˆ— âˆ’W tâˆ¥2]â‰¤ O
 
RT
r
2(f(W0)âˆ’f âˆ—)Ïƒ2
T
!
+ 4Ïƒ2ST +R T âˆ†wmin.(52)
which completes the proof.
F.2 LOWER BOUND OF ASYMPTOTIC ERROR FORANALOGSGD
Under the convergence of Analog SGD with hardware-constrained update rule in Theorem 4, we
derive a lower bound on the asymptotic error floor that arises when training with a single analog tile
on non-ideal AIMC hardware.
Theorem 5(Asymptotic error bound under quantization, long version of Theorem 2).Suppose
Assumptions 1-4 hold, Î±= 1
2L, there exists an instance where Analog SGD generates a sequence
{Wt}Tâˆ’1
t=0 such that:
1
T
Tâˆ’1X
t=0
E[âˆ¥W âˆ— âˆ’W tâˆ¥2]â‰¥â„¦(Ïƒ 2ST +R T âˆ†wmin)
This section provides the lower bound of Analog SGD on noisy asymmetric linear devices with
limited conductance states under Assumptions 1â€“4. The proof is completed based on the following
example from (Wu et al., 2024, Section G.2).
(Example)Consider an example where all the coordinates are identical, i.e., Wt =w t1 for some
wt âˆˆR where 1âˆˆR D is the all-one vector. Define W âˆ— =w âˆ—1 where wâˆ— âˆˆR is a constant scalar
and a quadratic function f(W) := L
2 âˆ¥Wâˆ’W âˆ—âˆ¥2 whose minimum is W âˆ—. Initialize the weight on
W0 =W âˆ—. Furthermore, consider the sample noise Î¾t defined as Î¾t =Îµ t1, where random variable
Îµt âˆˆRis sampled by:
Îµt =
ï£±
ï£²
ï£³
Îµ+
t := Ïƒâˆš
D
q
1âˆ’pt
pt
,w.p.p t,
Îµâˆ’
t :=âˆ’ Ïƒâˆš
D
q
pt
1âˆ’pt
,w.p.1âˆ’p t,
withp t = 1
2

1âˆ’ wt
Ï„max

.(53)
As a reminder, it is always valid that |wt|=âˆ¥W tâˆ¥âˆž â‰¤Ï„ max (see (Wu et al., 2024, Theorem 5)) and
0â‰¤p t â‰¤1 . Therefore, the noise distribution is well-defined. Furthermore, without loss of generality,
we assume |wâˆ—| â‰¤ Ï„max
4 and Ïƒâ‰¤ Ï„maxL
âˆš
D
4
âˆš
3 . We define the objectivef(w;Îµ t) := L
2
 
wâˆ’w âˆ— + Îµt
L
2
,
whose minimum isw âˆ—
Î¾t =w âˆ— âˆ’ Îµt
L . The noiseÎµ t satisfies (Wu et al., 2024, Assumption 7).
Proof of Theorem 5. Consider the example constructed above. Before deriving the lower bound, we
demonstrate Assumption 1â€“2 hold. It is obvious that âˆ‡f(W) =L(Wâˆ’W âˆ—) satisfies Assumption
2. In addition, Assumption 1 could be verified by noticing equation 53 implies EÎ¾t[Î¾t] = 0 and
EÎ¾t[âˆ¥Î¾tâˆ¥2]â‰¤Ïƒ 2. Assumption 3 is verified by (Wu et al., 2024, Lemma 2). We now proceed to
derive the lower bound. Manipulating the recursion equation 10, we have the following result:
EÎ¾t,Î¶t[âˆ¥Wt+1 âˆ’W âˆ—âˆ¥2](54)
=E Î¾t,Î¶t[âˆ¥Wt âˆ’Î± tâˆ‡f(W t;Î¾ t)âˆ’ Î±t
Ï„max
|âˆ‡f(W t;Î¾ t)| âŠ™W t âˆ’W âˆ— +Î¶ tâˆ¥2]
=E Î¾t[âˆ¥Wt âˆ’Î± tâˆ‡f(W t;Î¾ t)âˆ’ Î±t
Ï„max
|âˆ‡f(W t;Î¾ t)| âŠ™W t âˆ’W âˆ—âˆ¥2] + Î˜(Î±tâˆ†wmin)
=E Î¾t[âˆ¥Wt âˆ’Î± tâˆ‡f(W t;Î¾ t)âˆ’W âˆ—âˆ¥2] +E Î¾t[âˆ¥ Î±t
Ï„max
|âˆ‡f(W t;Î¾ t)| âŠ™W tâˆ¥2]
âˆ’2E Î¾t[âŸ¨Wt âˆ’Î± tâˆ‡f(W t;Î¾ t)âˆ’W âˆ—, Î±t
Ï„max
|âˆ‡f(W t;Î¾ t)| âŠ™W tâŸ©] + Î˜(Î±tâˆ†wmin).
24

The second equality holds for âˆ¥U+Vâˆ¥ 2 =âˆ¥Uâˆ¥ 2 +âˆ¥Vâˆ¥ 2 + 2âŸ¨U, VâŸ© with EÎ¶t[2âŸ¨U, VâŸ©] =
EÎ¶t[Î˜(Î¶t)] = 0 here, and EÎ¶t[Î¶2
t ] = Î˜(Î±tâˆ†wmin). The first term on the right-hand side (RHS) of
equation 54 can be bounded as:
EÎ¾t
h
âˆ¥Wt âˆ’Î± tâˆ‡f(W t;Î¾ t)âˆ’W âˆ—âˆ¥2
i
(55)
=âˆ¥W t âˆ’W âˆ—âˆ¥2 âˆ’2Î± tEÎ¾t [âŸ¨Wt âˆ’W âˆ—,âˆ‡f(W t;Î¾ t)âŸ©] +Î± 2
t EÎ¾t
h
âˆ¥âˆ‡f(W t;Î¾ t)âˆ¥2
i
â‰¥(1âˆ’2Î± tL)âˆ¥Wt âˆ’W âˆ—âˆ¥2 +Î± 2
t EÎ¾t
h
âˆ¥âˆ‡f(W t;Î¾ t)âˆ¥2
i
.
Here the second equality uses the unbiasedness of the stochastic gradient, i.e., EÎ¾t[âˆ‡f(W t;Î¾ t)] =
âˆ‡f(W t), and the inequality follows from the Lipschitz condition âŸ¨Wt âˆ’W âˆ—,âˆ‡f(W t)âŸ© â‰¤Lâˆ¥W t âˆ’
W âˆ—âˆ¥2.The second term in the RHS of equation 54 can be bounded as:
EÎ¾t[âˆ¥ Î±t
Ï„max
|âˆ‡f(W t;Î¾ t)| âŠ™W tâˆ¥2](56)
= Î±2
t âˆ¥Wtâˆ¥2
âˆž
Ï„ 2max
EÎ¾t[âˆ¥|âˆ‡f(W t;Î¾ t)|âˆ¥2] = Î±2
t âˆ¥Wtâˆ¥2
âˆž
Ï„ 2max
EÎ¾t[âˆ¥âˆ‡f(W t;Î¾ t)âˆ¥2]
where the first equality uses Wt =w t1. From equation 53, we have EÎ¾t[âˆ¥âˆ‡f(W t;Î¾ t)âˆ¥2] =
âˆ¥âˆ‡f(W t)âˆ¥2 +E Î¾t[âˆ¥Î¾tâˆ¥2] =L 2âˆ¥Wt âˆ’W âˆ—âˆ¥2 +Ïƒ 2, substituting the equation into equation 55 and
equation 56 yields:
EÎ¾t[âˆ¥Wt âˆ’Î± tâˆ‡f(W t;Î¾ t)âˆ’W âˆ—âˆ¥2] +E Î¾t[âˆ¥ Î±t
Ï„max
|âˆ‡f(W t;Î¾ t)| âŠ™W tâˆ¥2](57)
â‰¥
 
1âˆ’2Î± tL+Î± 2
t L2(1 + âˆ¥Wtâˆ¥2
âˆž
Ï„ 2max
)

âˆ¥Wt âˆ’W âˆ—âˆ¥2 +Î± 2
t Ïƒ2(1 + âˆ¥Wtâˆ¥2
âˆž
Ï„ 2max
).
The third term in the RHS of equation 54 can be bounded as:
âˆ’2E Î¾t[âŸ¨Wt âˆ’Î± tâˆ‡f(W t;Î¾ t)âˆ’W âˆ—, Î±t
Ï„max
|âˆ‡f(W t;Î¾ t)| âŠ™W tâŸ©](58)
=âˆ’2E Î¾t[âŸ¨Wt âˆ’W âˆ—, Î±tWt
Ï„max
âŠ™ |âˆ‡f(W t;Î¾ t)|âŸ©] + Î±2
t Wt
Ï„max
EÎ¾t[âŸ¨âˆ‡f(W t;Î¾ t),|âˆ‡f(W t;Î¾ t)|âŸ©]
=âˆ’2
DX
i=1
[âŸ¨wt âˆ’w âˆ—, Î±twt
Ï„max
(pt([âˆ‡f(W t)]i +Îµ +
t )âˆ’(1âˆ’p t)([âˆ‡f(W t)]i +Îµ âˆ’
t ))âŸ©]
+ 2Î±2
t wt
Ï„max
DX
i=1

pt([âˆ‡f(W t)]i +Îµ +
t )2 âˆ’(1âˆ’p t)([âˆ‡f(W t)]i +Îµ âˆ’
t )2
â‰¥ âˆ’ 2Î±tLâˆ¥Wtâˆ¥2
âˆž
Ï„ 2max
âˆ¥Wt âˆ’W âˆ—âˆ¥2 + 2Î±2
t âˆ¥Wtâˆ¥2
âˆž
Ï„ 2max
(âˆ’L2âˆ¥Wt âˆ’W âˆ—âˆ¥2 +Ïƒ 2)
âˆ’ Î±t(wt âˆ’w âˆ—)wtÏƒ
âˆš
D
Ï„max
p
(1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max) + 2Î±2
t L(wt âˆ’w âˆ—)wtÏƒ
âˆš
D
Ï„max
p
(1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max)
=âˆ’2(1 +Î± tL) Î±tLâˆ¥Wtâˆ¥2
âˆž
Ï„ 2max
âˆ¥Wt âˆ’W âˆ—âˆ¥2 + 2Î±2
t âˆ¥Wtâˆ¥2
âˆžÏƒ2
Ï„ 2max
where the first equation uses Wt =w t1, the second equality holds for (Wu et al., 2024, Lemma 4),
which shows that âˆ‡f(W t) +Îµ +
t â‰¥0 and âˆ‡f(W t) +Îµ âˆ’
t â‰¤0 , the last equation holds by setting
Î±t = 1
2L, the third equation holds by simplifying the second term as:
DX
i=1
[âŸ¨wt âˆ’w âˆ—, Î±twt
Ï„max
(pt([âˆ‡f(W t)]i +Îµ +
t )âˆ’(1âˆ’p t)([âˆ‡f(W t)]i +Îµ âˆ’
t ))âŸ©](59)
=
DX
i=1
[âŸ¨wt âˆ’w âˆ—, Î±twt
Ï„max
(pt([âˆ‡f(W t)]i + Ïƒâˆš
D
r1âˆ’p t
pt
)âˆ’(1âˆ’p t)([âˆ‡f(W t)]i âˆ’ Ïƒâˆš
D
r pt
1âˆ’p t
))âŸ©]
=
DX
i=1
[âŸ¨wt âˆ’w âˆ—, Î±twt
Ï„max
(2pt âˆ’1)[âˆ‡f(W t)]i + Î±twtÏƒ
Ï„max
âˆš
D
p
(1âˆ’p t)ptâŸ©]
25

=âŸ¨W t âˆ’W âˆ—,âˆ’ Î±tâˆ¥Wtâˆ¥2
âˆž
Ï„max
âˆ‡f(W t)âŸ©+ Î±t(wt âˆ’w âˆ—)wtÏƒ
âˆš
D
2Ï„max
p
(1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max)
â‰¤ Î±2
t Lâˆ¥Wtâˆ¥2
âˆž
Ï„ 2max
âˆ¥Wt âˆ’W âˆ—âˆ¥2 + Î±t(wt âˆ’w âˆ—)wtÏƒ
âˆš
D
2Ï„max
p
(1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max).
The inequality holds for âŸ¨Wt âˆ’W âˆ—,âˆ’âˆ‡f(W t)âŸ©=âˆ’âŸ¨W t âˆ’W âˆ—,âˆ‡f(W t)âŸ© â‰¤ âˆ¥W t âˆ’W âˆ—âˆ¥ Â·
âˆ¥âˆ‡f(W t)âˆ¥ â‰¤Lâˆ¥W t âˆ’W âˆ—âˆ¥2. Simplifying the second term as:
DX
i=1

pt([âˆ‡f(W t)]i +Îµ +
t )2 âˆ’(1âˆ’p t)([âˆ‡f(W t)]i +Îµ âˆ’
t )2
(60)
=
DX
i=1

pt
 
[âˆ‡f(W t)]2
i + 2[âˆ‡f(Wt)]i
Ïƒâˆš
D
r1âˆ’p t
pt
+ ( Ïƒâˆš
D
r1âˆ’p t
pt
)2
âˆ’(1âˆ’p t)
 
[âˆ‡f(W t)]2
i + 2[âˆ‡f(Wt)]i(âˆ’ Ïƒâˆš
D
r pt
1âˆ’p t
) + (âˆ’ Ïƒâˆš
D
r pt
1âˆ’p t
)2
=
DX
i=1

(1âˆ’2p t)(âˆ’[âˆ‡f(W t)]2
i + Ïƒ2
D ) + [âˆ‡f(Wt)]i
Ïƒâˆš
D
p
(1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max)

=âˆ’ L2âˆ¥Wtâˆ¥2
âˆž
Ï„max
âˆ¥Wt âˆ’W âˆ—âˆ¥2 + âˆ¥Wtâˆ¥âˆžÏƒ2
Ï„max
+LÏƒ
âˆš
D(wt âˆ’w âˆ—)
p
(1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max).
Substituting equation 57 and equation 58 into equation 54, we get:
EÎ¾t,Î¶t[âˆ¥Wt+1 âˆ’W âˆ—âˆ¥2](61)
â‰¥
 
1âˆ’2Î± tL+Î± 2
t L2(1 + âˆ¥Wtâˆ¥2
âˆž
Ï„ 2max
)âˆ’2(1 +Î± tL) Î±tLâˆ¥Wtâˆ¥2
âˆž
Ï„ 2max

âˆ¥Wt âˆ’W âˆ—âˆ¥2
+Î± 2
t Ïƒ2(1 + âˆ¥Wtâˆ¥2
âˆž
Ï„ 2max
) + 2Î±2
t âˆ¥Wtâˆ¥2
âˆžÏƒ2
Ï„ 2max
+ Î˜(Î±tâˆ†wmin).
=
 
1âˆ’2Î± tL(1âˆ’ Î±tL
2 )(1âˆ’ âˆ¥Wtâˆ¥2
âˆž
Ï„ 2max
)

âˆ¥Wt âˆ’W âˆ—âˆ¥2 +Î± 2
t Ïƒ2(1 + 3âˆ¥Wtâˆ¥2
âˆž
Ï„ 2max
) + Î˜(Î±tâˆ†wmin).
Rearranging equation 61 as:
âˆ¥Wt âˆ’W âˆ—âˆ¥2 (62)
â‰¥ âˆ¥Wt âˆ’W âˆ—âˆ¥2 âˆ’E Î¾t,Î¶t[âˆ¥Wt+1 âˆ’W âˆ—âˆ¥2]
2Î±tL(1âˆ’Î± tL/2)(1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max) + (1 + 3âˆ¥Wtâˆ¥2
âˆž/Ï„ 2
max)Î±tÏƒ2
2L(1âˆ’Î± tL/2)(1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max)
+ Î˜(âˆ†wmin)
2L(1âˆ’Î± tL/2)(1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max)
â‰¥ âˆ¥Wtâˆ¥2
âˆž/Ï„ 2
maxÏƒ2
L2(1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max) + 2Î˜(âˆ†wmin)
3L(1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max) .
The inequality holds since Î±t = 1
2L, and âˆ¥Wt âˆ’W âˆ—âˆ¥2 â‰¥E Î¾t,Î¶t[âˆ¥Wt+1 âˆ’W âˆ—âˆ¥2] from (Wu et al.,
2024, Theorem 8). Taking the expectation over all Î¾t, Î¶t and take the average of equation 62 for t
from0toTâˆ’1, we obtain:
1
T
Tâˆ’1X
t=0
E[âˆ¥Wt âˆ’W âˆ—âˆ¥2](63)
â‰¥Ïƒ 2 Â· 1
T
Tâˆ’1X
t=0
âˆ¥Wtâˆ¥2
âˆž/Ï„ 2
max
L2(1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max) + 1
T
Tâˆ’1X
t=0
2Î˜(âˆ†wmin)
3L(1âˆ’ âˆ¥W tâˆ¥2âˆž/Ï„ 2max)
= â„¦(Ïƒ2ST +R T âˆ†wmin).
The proof of Theorem 2 is thus completed.
26

G PROOF OFTHEOREM3ANDCOROLLARY1: CONVERGENCE OFRESIDUAL
LEARNING
This section provides the convergence of residual learning algorithm under Assumptions 1â€“4. To
formalize the analysis, we first clarify the use of tile-specific update indices. In the main text, we
define each gradient update as one training step, denoted by the global counter t. Since each tile
W (n) is updated only once every Tn+1 updates of tile W (n+1). As a result, W (n) is not updated at
every global step, exhibiting an inherently asynchronous update pattern. We introduce a local update
counter tn for each tile W (n), which tracks the number of its own update steps. These local counters
are related to the global countertby the following approximate relation:
tn =
$
t+ 1QN
nâ€²=n+1 Tnâ€²
%
.
As shown in Figure 9, the update schedule exhibits a nested timing hierarchy where inner tiles are
updated less frequently.
tN tNâˆ’1 tNâˆ’2 tNâˆ’3 Â· Â· Â· t0
0 0 0 0 Â· Â· Â· 0
1 1 0 0 Â· Â· Â· 0
2 1 0 0 Â· Â· Â· 0
3 2 1 0 Â· Â· Â· 0
4 2 1 0 Â· Â· Â· 0
5 3 1 0 Â· Â· Â· 0
6 3 1 0 Â· Â· Â· 0
7 4 2 1 Â· Â· Â· 0
time direction
Figure 9: Illustration of local index evolution tn in the cascading residual learning phase, assuming
all inner loop lengthT n = 2. Arrows indicate transfer updates fromW (n+1) toW (n).
G.1 MAIN PROOF
Theorem 6(Convergence of residual learning, long version of Theorem 3).Suppose Assumptions 1â€“4
hold. Let the scaling parameter satisfy Î³âˆˆ(0, H min/
âˆš
6F 2
max], and set the mapping constant as
Îº= (ÏƒL GWmax)
1
2 (Î³Nâˆ†wmin)âˆ’ 1
4 . For all nâˆˆ {0, . . . , Nâˆ’1} , set the learning rate Î²= Î˜(Î³ 2),
and choose the inner loop length Tn â‰¥Î˜
 
Î³âˆ’1
, except for T0 = Î˜(1) . When n=N , set the
learning rateÎ±= Î˜(1), and chooseT N â‰¥Î˜
 
Î³âˆ’N
.Define the Lyapunov sequence as:
Jk :=
NX
n=0
âˆ¥W (n)
tn+kTnâˆ’1 âˆ’P âˆ—
n(W
(n)
tnâˆ’1+k)âˆ¥2.
Since t= QN
n=0 Tnk=O(Î³ âˆ’2N)k is the total number of gradient evaluations, with Ïâˆˆ(0, 2
3), the
Lyapunov functionJ k satisfies:
E[Jk]â‰¤ O((1âˆ’Ï) Î³2N t)E[J0] + Î˜
 
Î³âˆ’ 4N
3 (Ïƒâˆ†wmin)
2
3

.
Proof of Theorem 6. We begin by presenting two lemmas essential for establishing the convergence
proof.
One inner loop contraction.
Lemma 8 establishes that tile W (N) undergoes a descent in expected distance to its local stationary
pointP âˆ—
N(W
(N)
)after one inner loop withT N updates. The update dynamic is defined as:
W (N)
t+1 =W (N)
t âˆ’Î±âˆ‡f( W t;Î¾ t)âŠ™F
 W (N)
t
Îº

âˆ’ |Î±âˆ‡f( W t;Î¾ t)| âŠ™G
 W (N)
t
Îº

+Î¶ t.(64)
Lemma 8(Descent lemma of the main sequence W (N) , long version of Lemma 2).Suppose
Assumptions 1 â€“4 hold, the learning rate satisfies Î±â‰¤ Ck,+
4Î³N(Âµ+L)F 2max
, the mapping constant is set as
27

Îº= (ÏƒL GWmax)
1
2 (Î³Nâˆ†wmin)âˆ’ 1
4 . DenoteE Î¾N ,Î¶N :=E Î¾t:t+TN âˆ’1,Î¶t:t+TN âˆ’1. It holds that:
EÎ¾N ,Î¶N
h
âˆ¥W (N)
t+(k+1)TN âˆ’1 âˆ’P âˆ—
N(W
(N)
tNâˆ’1+k)âˆ¥2
i
(65)
â‰¤

1âˆ’ Î±ÂµLÎ³N
4(Âµ+L)
TN
âˆ¥W (N)
t+kTN
âˆ’P âˆ—
N(W
(N)
tNâˆ’1+k)âˆ¥2 + 8(Âµ+L)Î±
Î³N ÂµL F 2
maxÏƒ2 +Î³ âˆ’ 4N
3 Î˜((Ïƒâˆ†wmin)
2
3 ).
Lemma 9 establishes that a single update of tile W (n) leads to a descent in its expected distance to
the local stationary point P âˆ—
n(W
(n)
) after one inner loop with Tn updates. The update dynamic is
defined as:
W (n)
tn+1 =W (n)
tn +Î²W (n+1)
tn+1+Tn+1âˆ’1 âŠ™F
 W (n)
tn
Îº

âˆ’ |Î²W (n+1)
tn+1+Tn+1âˆ’1| âŠ™G
 W (n)
tn
Îº

+Î¶ tn .(66)
Lemma 9(Descent lemma of lower level sequences W (n), long version of Lemma 3).Following the
same assumptions of Lemma 8, for nâˆˆ {0, . . . , Nâˆ’1} , the learning rate satisfies that Î²â‰¤ F 3
maxÎ³
3Hmin
.
DenoteE Î¶n :=E Î¶tn +kTn :tn +(k+1)Tn âˆ’1. It holds that:
EÎ¶n[âˆ¥W (n)
tn+(k+1)Tnâˆ’1 âˆ’P âˆ—
n(W
(n)
tnâˆ’1+k)âˆ¥2](67)
â‰¤

1âˆ’ Î²Hmin
2Î³Fmax
Tn
âˆ¥W (n)
tn+kTn
âˆ’P âˆ—
n(W
(n)
tnâˆ’1+k)âˆ¥2
+ 6F 4
maxÎ³2
H2
min
âˆ¥W (n+1)
tn+1+(k+1)Tn+1âˆ’1 âˆ’P âˆ—
n+1(W
(n+1)
tn+k )âˆ¥2 + 2FmaxÎ˜(âˆ†wmin)
Hmin
âˆ’( 2Î³2
Hmin
âˆ’ 6Î²Î³Fmax
Hmin
)
P âˆ—
n+1(W
(n+1)
tn+k )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn+k )| âŠ™G
 W (n)
tn
Îº

2
.
The proof of Lemma 8 and 9 are deferred to Section G.2 and G.3. We then proceed to prove the
convergence of the algorithm with the result of Lemma 8 and 9 . Define a Lyapunov function as:
Jk :=
NX
n=0
âˆ¥W (n)
tn+kTnâˆ’1 âˆ’P âˆ—
n(W
(n)
tnâˆ’1+k)âˆ¥2.(68)
Bounding the drifting optimality gap.
To derive the recursion of the Lyapunov function, we require an additional inequality to characterize
thedrift optimality, when nâˆˆ[1, N] . Observe that between one time step increment on tnâˆ’1, only
the component W (nâˆ’1) of the stationary point P âˆ—
n(W
(n)
) =Î³ âˆ’n(W âˆ— âˆ’ W
(n)
) is updated due to
the structure of the inner-loop algorithm we obtain:
EÎ¶tn [âˆ¥P âˆ—
n(W
(n)
tnâˆ’1+k+1)âˆ’P âˆ—
n(W
(n)
tnâˆ’1+k)âˆ¥2](69)
= 1
Î³ EÎ¶tn
hÎ²

W (n)
tn+kTnâˆ’1 âŠ™F
 W (nâˆ’1)
tnâˆ’1+k
Îº

âˆ’ |W (n)
tn+kTnâˆ’1| âŠ™G
 W (nâˆ’1)
tnâˆ’1+k
Îº

+Î¶ tn

2i
â‰¤3Î²2
Î³
P âˆ—
n(W
(n)
tnâˆ’1+k)âŠ™F
 W (nâˆ’1)
tnâˆ’1+k
Îº

âˆ’ |P âˆ—
n(W
(n)
tnâˆ’1+k)| âŠ™G
 W (nâˆ’1)
tnâˆ’1+k
Îº

2
+ 3Î²2
Î³
W (n)
tn+kTnâˆ’1
âŠ™F
 W (nâˆ’1)
tnâˆ’1+k
Îº

âˆ’ |W (n)
tn+kTnâˆ’1| âŠ™G
 W (nâˆ’1)
tnâˆ’1+k
Îº

âˆ’

P âˆ—
n(W
(n)
tnâˆ’1+k)âŠ™F
 W (nâˆ’1)
tnâˆ’1+k
Îº

âˆ’ |P âˆ—
n(W
(n)
tnâˆ’1+k)| âŠ™G
 W (nâˆ’1)
tnâˆ’1+k
Îº

2
+ EÎ¶tn [Î¶2
tn]
Î³
â‰¤ 3Î²2
Î³
P âˆ—
n(W
(n)
tnâˆ’1+k)âŠ™F
 W (nâˆ’1)
tnâˆ’1+k
Îº

âˆ’ |P âˆ—
n(W
(n)
tnâˆ’1+k)| âŠ™G
 W (nâˆ’1)
tnâˆ’1+k
Îº

2
+ 3Î²2
Î³ âˆ¥W (n)
tn+kTnâˆ’1 âˆ’P âˆ—
n(W
(n)
tnâˆ’1+k)âˆ¥2 + 3Î²
Î³ Î˜(âˆ†wmin).
28

Inequality equation 69 is obtained by is bounded by Lemma 1, 5 and Cauchy-Schwarz inequality.
Therefore, thedrift optimalitycan be bounded by substituting equation 69 with âˆ¥U+Vâˆ¥ 2 â‰¤
2âˆ¥Uâˆ¥2 + 2âˆ¥Vâˆ¥ 2:
EÎ¶tn [âˆ¥W (n)
tn+(k+1)Tnâˆ’1 âˆ’P âˆ—
n(W
(n)
tnâˆ’1+k+1)âˆ¥2](70)
â‰¤2âˆ¥W (n)
tn+(k+1)Tnâˆ’1 âˆ’P âˆ—
n(W
(n)
tnâˆ’1+k)âˆ¥2 + 2EÎ¶tn [âˆ¥P âˆ—
n(W
(n)
tnâˆ’1+k+1)âˆ’P âˆ—
n(W
(n)
tnâˆ’1+k)âˆ¥2]
â‰¤(2 + 6Î²2
Î³ )âˆ¥W (n)
tn+(k+1)Tnâˆ’1 âˆ’P âˆ—
n(W
(n)
tnâˆ’1+k)âˆ¥2 + 6Î²2
Î³
P âˆ—
n(W
(n)
tnâˆ’1+k)âŠ™F
 W (nâˆ’1)
tnâˆ’1+k
Îº

âˆ’ |P âˆ—
n(W
(n)
tnâˆ’1+k)| âŠ™G
 W (nâˆ’1)
tnâˆ’1+k
Îº

2
+ 6Î²
Î³ Î˜(âˆ†wmin).
Establishing convergence.
Define Fk as the Ïƒ-algebra generated by all random variables up to time k, including
{W (n)
tn }tâ‰¤k,nâˆˆ[0,N] . We write conditional expectations E[Â· | F k] compactly as Ek[Â·] for brevity.
For notational consistancy, we denote W âˆ— =:P âˆ—
0,tâˆ’1+k for all k. Expanding Jk+1 with equation 70,
equation 65 and equation 67, we get:
Ek[Jk+1]âˆ’J k (71)
=
NX
nâ€²=0
âˆ¥W (nâ€²)
tâ€²n+(k+1)T â€²nâˆ’1 âˆ’P âˆ—
N(W
(nâ€²)
tnâ€²âˆ’1+k+1)âˆ¥2 âˆ’
NX
nâ€²=0
âˆ¥W (nâ€²)
tâ€²n+kT â€²nâˆ’1 âˆ’P âˆ—
nâ€²(W
(nâ€²)
tnâ€² âˆ’1+k)âˆ¥2
â‰¤
NX
nâ€²=1

(2 + 6Î²2
Î³ )âˆ¥W (nâ€²)
tnâ€²+(k+1)T â€²nâˆ’1 âˆ’P âˆ—
nâ€²(W
(nâ€²)
tnâ€²âˆ’1+k)âˆ¥2 + 6Î²2
Î³
P âˆ—
nâ€²(W
(nâ€²)
tnâ€² âˆ’1+k)âŠ™F
 W (nâ€²âˆ’1)
tnâ€² âˆ’1+k
Îº

âˆ’ |P âˆ—
nâ€²(W
(nâ€²)
tnâ€² âˆ’1+k)| âŠ™G
 W (nâ€²âˆ’1)
tnâ€² âˆ’1+k
Îº

2
+ 6Î²
Î³ Î˜(âˆ†wmin)

+âˆ¥W (0)
t0+(k+1)T0âˆ’1 âˆ’P âˆ—
0,tâˆ’1+kâˆ¥2
âˆ’
NX
nâ€²=0
âˆ¥W (nâ€²)
tâ€²n+kT â€²nâˆ’1 âˆ’P âˆ—
nâ€²(W
(nâ€²)
tnâ€² âˆ’1+k)âˆ¥2
â‰¤(2 + 6Î²2
Î³ )
 
1âˆ’ Î±ÂµLÎ³N
4(Âµ+L)
TN
âˆ¥W (N)
t+kTN âˆ’1 âˆ’P âˆ—
N(W
(N)
tNâˆ’1+k)âˆ¥2 + 8(Âµ+L)Î±
Î³N ÂµL F 2
maxÏƒ2 +Î³ âˆ’ 4N
3
Î˜((Ïƒâˆ†wmin)
2
3 )

+ 6Î²2
Î³
P âˆ—
N(W
(N)
tNâˆ’1+k)âŠ™F
 W (Nâˆ’1)
tNâˆ’1+k
Îº

âˆ’ |P âˆ—
N(W
(N)
tNâˆ’1+k)| âŠ™G
 W (Nâˆ’1)
tNâˆ’1+k
Îº

2
+ 6Î²
Î³ Î˜(âˆ†wmin) +
Nâˆ’1X
nâ€²=1
 
2 + 6Î²2
Î³
 
âˆ’ 2Î³2
Hmin
+ 6Î²Î³Fmax
Hmin
P âˆ—
nâ€²(W
(nâ€²)
tnâ€² âˆ’1+k)âŠ™F
 W (nâ€²âˆ’1)
tnâ€² âˆ’1+k
Îº

âˆ’ |P âˆ—
nâ€²(W
(nâ€²)
tnâ€² âˆ’1+k)| âŠ™G
 W (nâ€²âˆ’1)
tnâ€² âˆ’1+k
Îº

2
+
 
1âˆ’ Î²Hmin
2Î³Fmax
Tnâ€²
âˆ¥W (nâ€²)
tnâ€²+kT â€²nâˆ’1 âˆ’P âˆ—
nâ€²(W
(nâ€²)
tnâ€² âˆ’1+k)âˆ¥2
+ 6F 4
maxÎ³2
H2
min
âˆ¥W (nâ€²+1)
tnâ€² +1+kTnâ€²+1âˆ’1 âˆ’P âˆ—
nâ€²(W
(nâ€²+1)
tnâ€²+k )âˆ¥2 + 2FmaxÎ˜(âˆ†wmin)
Hmin

+ 6Î²2
Î³
P âˆ—
nâ€²(W
(nâ€²)
tnâ€² âˆ’1+k)
âŠ™F
 W (nâ€²âˆ’1)
tnâ€²âˆ’1+k
Îº

âˆ’ |P âˆ—
nâ€²(W
(nâ€²)
tnâ€²âˆ’1+k)| âŠ™G
 W (nâ€²âˆ’1)
tnâ€² âˆ’1+k
Îº

2
+ 6Î²
Î³ Î˜(âˆ†wmin)
!
+

1âˆ’ Î²Hmin
2Î³Fmax
T0
âˆ¥W (0)
t0+kT0
âˆ’P âˆ—
0,tâˆ’1+kâˆ¥2 + 6F 4
maxÎ³2
H2
min
âˆ¥W (1)
t1+(k+1)T1âˆ’1 âˆ’P âˆ—
1 (W
(1)
t0+k)âˆ¥2
+ 2FmaxÎ˜(âˆ†wmin)
Hmin
âˆ’
NX
nâ€²=0
âˆ¥W (nâ€²)
tâ€²n+kTnâˆ’1 âˆ’P âˆ—
nâ€²(W
(nâ€²)
tnâ€²âˆ’1+k)âˆ¥2
29

â‰¤
NX
nâ€²=1

(2 + 6Î²2
Î³ )(âˆ’ 2Î³2
Hmin
+ 6Î²Î³Fmax
Hmin
) + 6Î²2
Î³

| {z }
(A)
P âˆ—
nâ€²(W
(nâ€²)
tnâ€²âˆ’1+k)âŠ™F
 W (nâ€²âˆ’1)
tnâ€² âˆ’1+k
Îº

âˆ’ |P âˆ—
nâ€²(W
(nâ€²)
tnâ€²âˆ’1+k)|
âŠ™G
 W (nâ€²âˆ’1)
tnâ€²âˆ’1+k
Îº

2
+
Nâˆ’1X
nâ€²=1

(2 + 6Î²2
Î³ )
 
1âˆ’ Î²Hmin
2Î³Fmax
Tnâ€²
+ 6F 4
maxÎ³2
H2
min
âˆ’1

| {z }
(B)
âˆ¥W (nâ€²)
tnâ€²+kT â€²nâˆ’1 âˆ’P âˆ—
nâ€²(W
(nâ€²)
tnâ€²âˆ’1+k)âˆ¥2
+

(2 + 6Î²2
Î³ )
 
1âˆ’ Î±ÂµLÎ³N
4(Âµ+L)
TN
+ 6F 4
maxÎ³2
H2
min
âˆ’1

| {z }
(C)
âˆ¥W (N)
t+kTN âˆ’1 âˆ’P âˆ—
N(W
(N)
tNâˆ’1+k)âˆ¥2 + (2 + 6Î²2
Î³ )
 8(Âµ+L)Î±
Î³N ÂµL F 2
maxÏƒ2 +Î³ âˆ’ 4N
3 Î˜((Ïƒâˆ†wmin)
2
3 )

+
Nâˆ’1X
nâ€²=0

(2 + 6Î²2
Î³ )2FmaxÎ˜(âˆ†wmin)
Hmin
+ 6Î²
Î³ Î˜(âˆ†wmin)

+
 
1âˆ’ Î²Hmin
2Î³Fmax
T0
âˆ’1

âˆ¥W (0)
t0+kT0âˆ’1 âˆ’P âˆ—
0,tâˆ’1+kâˆ¥2.
The coefficient
 
1âˆ’ Î²Hmin
2Î³Fmax
Tnâ€²
âˆ’1

for the last term is negative when T0 â‰¥1 . To achieve descent
on Lyapunov function, we choose
Î²= Î˜(Î³ 2), Î±= Î˜(1), Î³â‰¤
s
1âˆ’ 3
2 Ï
6
Hmin
F 2max
, T n â‰¥Î˜
 
Î³âˆ’1
, nâˆˆ {1, . . . , Nâˆ’1}, T N â‰¥Î˜
 
Î³âˆ’N
to satisfy the following conditions, whereÏâˆˆ(0, 2
3)is a constant:
A:= (2 + 6Î²2
Î³ )(âˆ’ 2Î³2
Hmin
+ 6Î²Î³Fmax
Hmin
) + 6Î²2
Î³ â‰¤0,(72)
B:= (2 + 6Î²2
Î³ )
 
1âˆ’ Î²Hmin
2Î³Fmax
Tn
+ 6F 4
maxÎ³2
H2
min
âˆ’1â‰¤ âˆ’Ï, nâˆˆ[1, Nâˆ’1],(73)
C:= (2 + 6Î²2
Î³ )
 
1âˆ’ Î±ÂµLÎ³N
4(Âµ+L)
TN
+ 6F 4
maxÎ³2
H2
min
âˆ’1â‰¤ âˆ’Ï.(74)
LetÎ²=c Î²Î³2, the inequality equation 72 becomes:
 
2 + 6c2
Î²Î³3 
âˆ’2Î³2 + 6cÎ²FmaxÎ³3
+ 6c2
Î²Î³3Hmin â‰¤0(75)
which holds when Î³âˆˆ(0, Hminâˆš
6F 2max
] and cÎ² âˆˆ(0, 1
5Fmax
]. For equation 73 and equation 74, we first
give the upper bound of Î³ as Î³â‰¤
âˆš
1âˆ’ 3
2 ÏHminâˆš
6F 2max
in order to satisfy 6F 4
maxÎ³2
H 2
min
âˆ’1â‰¤ âˆ’ 3
2 Ï. We then
bound the inner loops countT n,nâˆˆ {0, . . . , Nâˆ’1}by defining :
Î»1 = Î²Hmin
2Î³Fmax
= cÎ²Hmin
2Fmax
Î³=:c 1Î³= Î˜(Î³), A 1 = 2 + 6Î²2
Î³ = 2 + 6c2
Î²Î³3 =O(1).(76)
Using (1âˆ’Î» 1)Tn â‰¤e âˆ’Î»1Tn, inequality equation 73 must satisfy A1eâˆ’Î»1Tn â‰¤Ï/2 , which yields
Tn â‰¥ 1
Î»1
ln

2A1
Ï

= Î˜
 
Î³âˆ’1
. Similarly, let Î»2 = Î±ÂµLÎ³N
4(Âµ+L) =:c 2Î³N = Î˜(Î³ N), to satisfy
A1eâˆ’Î»2TN â‰¤Ï/2 , we bound TN as TN â‰¥ 1
Î»2
ln

2A1
Ï

= Î˜
 
Î³âˆ’N
. Once inequalities equation 72,
equation 73, and equation 74 are satisfied, the Lyapunov descent inequality equation 71 simplifies to:
Ek[Jk+1]â‰¤(1âˆ’Ï)J k +Î³ âˆ’ 4N
3 Î˜
 
(Ïƒâˆ†wmin)
2
3

.(77)
Taking full expectation overF k on both sides, the recurrence becomes:
E[Jk+1]â‰¤(1âˆ’Ï)E[J k] +Î³ âˆ’ 4N
3 Î˜
 
(Ïƒâˆ†wmin)
2
3

.(78)
Unrolling this inequality overksteps, we get:
E[Jk]â‰¤(1âˆ’Ï) kE[J0] +Î³ âˆ’ 4N
3 Î˜
 
(Ïƒâˆ†wmin)
2
3
 Kâˆ’1X
t=0
(1âˆ’Ï) t (79)
30

â‰¤(1âˆ’Ï) kE[J0] + Î³âˆ’ 4N
3 Î˜
 
(Ïƒâˆ†wmin)
2
3

Ï .
SinceÏâˆˆ(0,1) = Î˜(1), we get:
E[Jk]â‰¤(1âˆ’Ï) kE[J0] + Î˜
 
Î³âˆ’ 4N
3 (Ïƒâˆ†wmin)
2
3

.(80)
Since W (N) dominates the compute cost, one outer iteration (i.e. one update of Jk) consumes
t= QN
n=0 Tnk=O(Î³ âˆ’2N)Â·k gradient evaluations. Therefore the averaged Lyapunov function, as
a function of the total gradient evaluations, obeys:
E[Jk]â‰¤ O((1âˆ’Ï) Î³2N t)E[J0] + Î˜
 
Î³âˆ’ 4N
3 (Ïƒâˆ†wmin)
2
3

which completes the proof.
Corollary 1(Optimality gap of residual learning).Under the same conditions as in Theorem 3, the
limit of the composited weight W t satisfies:
lim sup
tâ†’âˆž
E

âˆ¥W âˆ— âˆ’ W tâˆ¥2
â‰¤Î˜(Î³
2N
3 (Ïƒâˆ†wmin)
2
3 ).
Proof of Corollary 1.From equation 79, taking the limit askâ†’ âˆž, we obtain:
lim sup
kâ†’âˆž
E[Jk]â‰¤Î˜(Î³ âˆ’ 4N
3 (Ïƒâˆ†wmin)
2
3 ).(81)
Once equation 81 holds forJ k , each component ofJ k also satisfies:
lim sup
tnâ†’âˆž
E

âˆ¥W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2
â‰¤Î˜
 
Î³âˆ’ 4N
3 (Ïƒâˆ†wmin)
2
3

.(82)
Substituting P âˆ—
n(W
(n)
) =Î³ âˆ’n(W âˆ— âˆ’ W
(n)
) into equation 82, we derive the bound on the scaled
residual:
lim sup
tnâ†’âˆž
E

âˆ¥W âˆ— âˆ’ W
(n+1)
tn âˆ¥2
â‰¤Î˜
 
Î³2nâˆ’ 4N
3 (Ïƒâˆ†wmin)
2
3

, nâˆˆ[0, N].(83)
In particular, whenn=N, we obtain the desired result as:
lim sup
tâ†’âˆž
E

âˆ¥W âˆ— âˆ’ W tâˆ¥2
â‰¤Î˜
 
Î³
2N
3 (Ïƒâˆ†wmin)
2
3

.(84)
This demonstrates that increasing the number of tiles leads to an error decay rate proportional to Î³
2
3 ,
thereby completing the proof.
G.2 PROOF OFLEMMA8: DESCENT OF THE MAIN SEQUENCEW (N)
t
Lemma 8(Descent lemma of the main sequence W (N) , long version of Lemma 2).Suppose
Assumptions 1 â€“4 hold, the learning rate satisfies Î±â‰¤ Ck,+
4Î³N(Âµ+L)F 2max
, the mapping constant is set as
Îº= (ÏƒL GWmax)
1
2 (Î³Nâˆ†wmin)âˆ’ 1
4 . DenoteE Î¾N ,Î¶N :=E Î¾t:t+TN âˆ’1,Î¶t:t+TN âˆ’1. It holds that:
EÎ¾N ,Î¶N
h
âˆ¥W (N)
t+(k+1)TN âˆ’1 âˆ’P âˆ—
N(W
(N)
tNâˆ’1+k)âˆ¥2
i
(65)
â‰¤

1âˆ’ Î±ÂµLÎ³N
4(Âµ+L)
TN
âˆ¥W (N)
t+kTN
âˆ’P âˆ—
N(W
(N)
tNâˆ’1+k)âˆ¥2 + 8(Âµ+L)Î±
Î³N ÂµL F 2
maxÏƒ2 +Î³ âˆ’ 4N
3 Î˜((Ïƒâˆ†wmin)
2
3 ).
Proof of Lemma 8.The proof begins from manipulating the normâˆ¥W (N)
t+1 âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2
EÎ¾t,Î¶t[âˆ¥W (N)
t+1 âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2](85)
=âˆ¥W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2 + 2EÎ¾t,Î¶t[âŸ¨W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ), W(N)
t+1 âˆ’W (N)
t âŸ©]
+E Î¾t,Î¶t[âˆ¥W (N)
t+1 âˆ’W (N)
t âˆ¥2].
To bound the second term, we first apply the update dynamics given in equation 64 to obtain the
following equality:
2EÎ¾t,Î¶t[âŸ¨W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ), W(N)
t+1 âˆ’W (N)
t âŸ©](86)
31

=âˆ’2E Î¾t,Î¶t
hD
W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ), Î±âˆ‡f(W t;Î¾ t)âŠ™F
 W (N)
t
Îº

+|Î±âˆ‡f( W t;Î¾ t)|
âŠ™G
 W (N)
t
Îº

âˆ’Î¶ t
Ei
=âˆ’2Î±E Î¾t
hD
W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ),âˆ‡f( W t;Î¾ t)âŠ™F
 W (N)
t
Îº
Ei
âˆ’2Î±E Î¾t
hD
W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ),|âˆ‡f( W t;Î¾ t)| âŠ™G
 W (N)
t
Îº
Ei
=âˆ’2Î±
D
W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ),âˆ‡f( W t)âŠ™F
 W (N)
t
Îº
E
+ 2Î±EÎ¾t
hD
W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ),(|âˆ‡f( W t)| âˆ’ |âˆ‡f( W t;Î¾ t)|)âŠ™G
 W (N)
t
Îº
Ei
âˆ’2Î±
D
W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ),|âˆ‡f( W t)| âŠ™G
 W (N)
t
Îº
E
â‰¤ âˆ’2Î±
D
W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ),âˆ‡f( W t)âŠ™F
 W (N)
t
Îº

+|âˆ‡f( W t)| âŠ™G
 W (N)
t
Îº
E
| {z }
(T1)
+ 2Î±E Î¾t
hD
W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ),(|âˆ‡f( W t)| âˆ’ |âˆ‡f( W t;Î¾ t)|)âŠ™G
 W (N)
t
Îº
Ei
| {z }
(T2)
Upper bound of the first term (T1) .With Lemma 7, the second term in the RHS of equation 85
can be bounded by:
âˆ’2Î±
D
W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ),âˆ‡f( W t)âŠ™F
 W (N)
t
Îº

+|âˆ‡f( W t)| âŠ™G
 W (N)
t
Îº
E
(87)
=âˆ’2Î±
D
W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ),âˆ‡f( W t)âŠ™q s
 W (N)
t
Îº
E
â‰¤ âˆ’2Î±C k,+âŸ¨W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ),âˆ‡f( W t)âŸ©+ 2Î±C k,âˆ’âŸ¨|W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )|,|âˆ‡f( W t)|âŸ©
whereC k,+ andC k,âˆ’ are defined as:
Ck,+ :=1
2
 
max
iâˆˆI
{qs([ W (N)
t
Îº ]i)}+ min
iâˆˆI
{qs([ W (N)
t
Îº ]i)}
!
,(88)
Ck,âˆ’ :=1
2
 
max
iâˆˆI
{qs([ W (N)
t
Îº ]i)} âˆ’min
iâˆˆI
{qs([ W (N)
t
Îº ]i)}
!
.(89)
In the inequality above, the first term can be bounded by the strong convexity of f. Let Ï†(W (N)) :=
f( W
(N)
+Î³ N W (N)) which is Î³2N L-smooth and Î³2N Âµ-strongly convex. It can be verified that
Ï†(W (N)
t ) has gradient âˆ‡Ï†(W (N)
t ) =Î³ N âˆ‡f( W
(N)
tNâˆ’1 +Î³ N W (N)
t ) =Î³ N âˆ‡f( W tN ) and optimal
pointP âˆ—(W
(N)
tNâˆ’1 ). Leveraging Theorem 2.1.9 in (Nesterov, 2018), we have:
2Î±Ck,+âŸ¨W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ),âˆ‡f( W t)âŸ©(90)
=2Î±Ck,+
Î³N âŸ¨âˆ‡Ï†(W (N)
t ), W(N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âŸ©
=2Î±Ck,+
Î³N âŸ¨âˆ‡Ï†(W (N)
t )âˆ’ âˆ‡Ï†(P âˆ—
N(W
(N)
tNâˆ’1 )), W(N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âŸ©
â‰¥ 2Î±Ck,+
Î³N
 Î³2N ÂµÂ·Î³ 2N L
Î³2N Âµ+Î³ 2N L âˆ¥W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2 + 1
Î³2N Âµ+Î³ 2N L âˆ¥âˆ‡Ï†(W (N)
t )âˆ¥2

32

= 2Î±Ck,+ÂµLÎ³N
Âµ+L âˆ¥W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2 + 2Î±Ck,+
Î³N(Âµ+L) âˆ¥âˆ‡f( W t)âˆ¥2.
The second term in the RHS of equation 87 can be bounded by the following inequality:
2Î±Ck,âˆ’
D
|W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )|,|âˆ‡f( W t)|
E
(91)
â‰¤
Î±C2
k,âˆ’Î³N(Âµ+L)
Ck,+
âˆ¥W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2 + Î±Ck,+
Î³N(Âµ+L) âˆ¥âˆ‡f( W t)âˆ¥2.
Therefore, equation 87 becomes:
âˆ’2Î±âŸ¨W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ),âˆ‡f( W t)âŠ™F
 W (N)
t
Îº

+|âˆ‡f( W t)| âŠ™G
 W (N)
t
Îº

âŸ©(92)
â‰¤ âˆ’Î³ N
 
2Î±ÂµLCk,+
Âµ+L âˆ’
Î±C2
k,âˆ’(Âµ+L)
Ck,+
!
âˆ¥W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2 âˆ’ Î±Ck,+
Î³N(Âµ+L) âˆ¥âˆ‡f( W t)âˆ¥2.
Upper bound of the second term(T2).Leveraging the Youngâ€™s inequality, we have:
2Î±EÎ¾t
hD
W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ),(|âˆ‡f( W t)| âˆ’ |âˆ‡f( W t;Î¾ t)|)âŠ™G
 W (N)
t
Îº
Ei
(93)
â‰¤ Î±ÂµLCk,+Î³N
(Âµ+L) âˆ¥W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2
+ Î±(Âµ+L)
ÂµLCk,+Î³N EÎ¾t
h(|âˆ‡f( W t)| âˆ’ |âˆ‡f( W t;Î¾ t)|)âŠ™G
 1
Îº W (N)
t

2i
(a)
â‰¤ Î±ÂµLCk,+Î³N
(Âµ+L) âˆ¥W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2
+ Î±(Âµ+L)
ÂµLCk,+Î³N EÎ¾t
h(|âˆ‡f( W t)âˆ’ âˆ‡f( W t;Î¾ t)|)âŠ™G
 W (N)
t
Îº

2i
(b)
= Î±ÂµLCk,+Î³N
(Âµ+L) âˆ¥W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2 + Î±(Âµ+L)Ïƒ 2
ÂµLCk,+Î³N
G
 W (N)
t
Îº

2
âˆž
where (a) applies ||x| âˆ’ |y|| â‰¤ |xâˆ’y| for any x, yâˆˆR , (b) uses the bounded variance assumption
(see Assumption 1). Combining the upper bound of(T1)and(T2), we bound equation 86 by:
2EÎ¾t[âŸ¨W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 ), W(N)
t+1 âˆ’W (N)
t âŸ©](94)
â‰¤ âˆ’Î³ N
 
Î±ÂµLCk,+
Âµ+L âˆ’
Î±C2
k,âˆ’(Âµ+L)
Ck,+
!
âˆ¥W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2 âˆ’ Îº2Î±Ck,+
Î³N(Âµ+L) âˆ¥âˆ‡f( W t)âˆ¥2
+ Î±(Âµ+L)Ïƒ 2
ÂµLCk,+Î³N
G
 W (N)
t
Îº

2
âˆž
â‰¤ âˆ’ Î³N Î±ÂµLCk,+
2(Âµ+L) âˆ¥W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2 âˆ’ Î±Ck,+
Î³N(Âµ+L) âˆ¥âˆ‡f( W t)âˆ¥2 + Î±(Âµ+L)Ïƒ 2
ÂµLCk,+Î³N
G( W (N)
t
Îº )

2
âˆž
where the last inequality holds for Ck,âˆ’ â‰ªC k,+ , which is sufficiently close to 0, and the following
inequality holds:
(Âµ+L)
C2
k,âˆ’
C2
k,+
â‰¤ ÂµL
2(Âµ+L) .(95)
Furthermore, the last term in the RHS of equation 85 can be bounded by the Lipschitz continuity of
analog update (see Lemma 5) and the bounded variance assumption (see Assumption 1) as:
EÎ¾t,Î¶t
hW (N)
t+1 âˆ’W (N)
t âˆ¥2](96)
=E Î¾t,Î¶t[âˆ¥Î±âˆ‡f( W t;Î¾ t)âŠ™F
 W (N)
t
Îº

âˆ’Î±|âˆ‡f( W t;Î¾ t)| âŠ™G
 W (N)
t
Îº

+Î¶ t

2i
33

â‰¤2Î± 2F 2
maxEÎ¾t[âˆ¥âˆ‡f( W t;Î¾ t)âˆ¥2] + 2Î±Î˜(âˆ†wmin)
â‰¤2Î± 2F 2
maxâˆ¥âˆ‡f( W t)âˆ¥2 + 2Î±2F 2
maxÏƒ2 + 2Î±Î˜(âˆ†wmin)
â‰¤ Î±Ck,+
2Î³N(Âµ+L) âˆ¥âˆ‡f( W t)âˆ¥2 + 2Î±2F 2
maxÏƒ2 + 2Î±Î˜(âˆ†wmin)
where the first inequality holds by âˆ¥U+Vâˆ¥ 2 â‰¤2âˆ¥Uâˆ¥ 2 + 2âˆ¥Vâˆ¥ 2 and EÎ¶t[Î¶2
t ] =Î±Î˜(âˆ†w min), the
last inequality holds if Î±â‰¤ Ck,+
4Î³N(Âµ+L)F 2max
. Plugging inequality equation 94 and equation 96 above
into equation 85 yields:
EÎ¾t,Î¶t[âˆ¥W (N)
t+1 âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2](97)
â‰¤

1âˆ’ Î±ÂµLCk,+Î³N
2(Âµ+L)

âˆ¥W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2 âˆ’ Î±Ck,+
2Î³N(Âµ+L) âˆ¥âˆ‡f( W t)âˆ¥2
+ Î±(Âµ+L)Ïƒ 2
ÂµLCk,+Î³N
G
 W (N)
t
Îº

2
âˆž
+ 2Î±2F 2
maxÏƒ2 + 2Î±Î˜(âˆ†wmin).
From the definition of Ck,+, when the saturation degree of W (N)
t is properly limited, we have
Ck,+ â‰¥ 1
2 sinceÎ±Î³ n is sufficiently small. Therefore, we have:
EÎ¾t,Î¶t[âˆ¥W (N)
t+1 âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2](98)
â‰¤

1âˆ’ ÂµLÎ±Î³N
4(Âµ+L)

âˆ¥W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2 âˆ’ Î±
4Î³N(Âµ+L) âˆ¥âˆ‡f( W t)âˆ¥2
+ 2Î±(Âµ+L)Ïƒ 2
ÂµLÎ³N
G
 W (N)
t
Îº

2
âˆž
+ 2Î±2F 2
maxÏƒ2 + 2Î±Î˜(âˆ†wmin).
Under Assumption 4, which indicatesG(0) = 0 and the Lipschitz continuity of the response functions,
we can directly bound the term
G

W (N)
t
Îº

2
âˆž
in equation 97 as:
G
 W (N)
t
Îº

2
âˆž
â‰¤
G
 W (N)
t
Îº

2
=
G
 W (N)
t
Îº

âˆ’G(0)

2
â‰¤ L2
G
Îº2 âˆ¥W (N)
t âˆ¥2
âˆž (99)
where LG â‰¥0 is a Lipschitz constant. Perform TN iterations using the recursive process in
equation 97, and denote the expectation over the noise sequence EÎ¾t:t+TN âˆ’1,Î¶t:t+TN âˆ’1 as EÎ¾N ,Î¶N , we
obtain the following upper bound:
EÎ¾N ,Î¶N
h
âˆ¥W (N)
t+TN âˆ’1 âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2
i
(100)
â‰¤

1âˆ’ Î±ÂµLÎ³N
4(Âµ+L)
TN
âˆ¥W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2 +
TN âˆ’1X
i=0

1âˆ’ Î±ÂµLÎ³N
4(Âµ+L)
i
2Î±2F 2
maxÏƒ2
+ 2Î±(Âµ+L)Ïƒ 2L2
Gâˆ¥W (N)
t âˆ¥2
âˆž
ÂµLÎ³N Îº2 + 2Î±Î˜(âˆ†wmin)

â‰¤

1âˆ’ Î±ÂµLÎ³N
4(Âµ+L)
TN
âˆ¥W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2 + 8(Âµ+L)Î±
Î³N ÂµL F 2
maxÏƒ2 + 8(Âµ+L) 2Ïƒ2L2
GW 2
max
Î³2N Âµ2L2Îº2
+ 8(Âµ+L)Îº
Î³N ÂµL Î˜(âˆ†cmin)
â‰¤

1âˆ’ Î±ÂµLÎ³N
4(Âµ+L)
TN
âˆ¥W (N)
t âˆ’P âˆ—
N(W
(N)
tNâˆ’1 )âˆ¥2 + 8(Âµ+L)Î±
Î³N ÂµL F 2
maxÏƒ2 +Î³ âˆ’ 4N
3 Î˜((Ïƒâˆ†wmin)
2
3 ).
The second inequality holds for PTN âˆ’1
i=0

1âˆ’ Î±ÂµLÎ³N
8(Âµ+L)
i
â‰¤ 8(Âµ+L)
Î±ÂµLÎ³N , and we define Wmax âˆˆ
[âˆ¥W (N)
t âˆ¥âˆž, Ï„max)for allt. The last inequality holds by choosing the mapping constant as:
Îº= (ÏƒL GWmax)
2
3 (Î³Nâˆ†cmin)âˆ’ 1
3 = (ÏƒLGWmax)
2
3 ( Î³Nâˆ†wmin
Îº )âˆ’ 1
3 .(101)
34

The second equality holds by substituting equation 17. Rearranging equation 101, we get:
Îº= (ÏƒL GWmax)
1
2 (Î³Nâˆ†wmin)âˆ’ 1
4 (102)
WhenkÌ¸= 0, equation 100 can be written as the general case:
EÎ¾N ,Î¶N
h
âˆ¥W (N)
t+(k+1)TN âˆ’1 âˆ’P âˆ—
N(W
(N)
tNâˆ’1+k)âˆ¥2
i
(103)
â‰¤

1âˆ’ Î±ÂµLÎ³N
4(Âµ+L)
TN
âˆ¥W (N)
t+kTN
âˆ’P âˆ—
N(W
(N)
tNâˆ’1+k)âˆ¥2 + 8(Âµ+L)Î±
Î³N ÂµL F 2
maxÏƒ2 +Î³ âˆ’ 4N
3 Î˜((Ïƒâˆ†wmin)
2
3 )
which completes the proof.
G.3 PROOF OFLEMMA9: DESCENT OF LOWER LEVEL SEQUENCEW (n)
tn
Lemma 9(Descent lemma of lower level sequences W (n), long version of Lemma 3).Following the
same assumptions of Lemma 8, for nâˆˆ {0, . . . , Nâˆ’1} , the learning rate satisfies that Î²â‰¤ F 3
maxÎ³
3Hmin
.
DenoteE Î¶n :=E Î¶tn +kTn :tn +(k+1)Tn âˆ’1. It holds that:
EÎ¶n[âˆ¥W (n)
tn+(k+1)Tnâˆ’1 âˆ’P âˆ—
n(W
(n)
tnâˆ’1+k)âˆ¥2](67)
â‰¤

1âˆ’ Î²Hmin
2Î³Fmax
Tn
âˆ¥W (n)
tn+kTn
âˆ’P âˆ—
n(W
(n)
tnâˆ’1+k)âˆ¥2
+ 6F 4
maxÎ³2
H2
min
âˆ¥W (n+1)
tn+1+(k+1)Tn+1âˆ’1 âˆ’P âˆ—
n+1(W
(n+1)
tn+k )âˆ¥2 + 2FmaxÎ˜(âˆ†wmin)
Hmin
âˆ’( 2Î³2
Hmin
âˆ’ 6Î²Î³Fmax
Hmin
)
P âˆ—
n+1(W
(n+1)
tn+k )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn+k )| âŠ™G
 W (n)
tn
Îº

2
.
Proof of Lemma 9.The proof begins from manipulating the normâˆ¥W (n)
tn+1 âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2:
EÎ¶tn [âˆ¥W (n)
tn+1 âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2](104)
=âˆ¥W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2 + 2EÎ¶tn [âŸ¨W n
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1), W(n)
tn+1 âˆ’W (n)
tn âŸ©] +E Î¶tn [âˆ¥W (n)
tn+1 âˆ’W (n)
tn âˆ¥2].
Substituting update dynamic equation 66, we bound the second term of equation 104 as following:
2EÎ¶tn [âŸ¨W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1), W(n)
tn+1 âˆ’W (n)
tn âŸ©](105)
= 2EÎ¶tn
hD
W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1), Î²

W (n+1)
tn+1+Tâˆ’1 âŠ™F
 W (n)
tn
Îº

+|W (n+1)
tn+1+Tâˆ’1 | âŠ™G
 W (n)
tn
Îº

+Î¶ tn
Ei
â‰¤2Î²
D
W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1), P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº
E
+ 2Î²EÎ¾t:t+Tn âˆ’1
hD
W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1), W(n+1)
tn+1+Tâˆ’1 âŠ™F
 W (n)
tn
Îº

âˆ’ |W (n+1)
tn+1+Tâˆ’1 | âŠ™G
 W (n)
tn
Îº

âˆ’

P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº
Ei
.
The last inequality holds by Youngâ€™s inequality. The first term in theRHS of equation 105 can be
bounded by:
2Î²
D
W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1), P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº
E
= 2Î²
*
(W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1))âŠ™
s
F
 W (n)
tn
Îº

,
P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº

r
F
 W (n)
tn
Îº

+
(a)
=âˆ’ 2Î²
Î³
*
(W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1))âŠ™
s
F
 W (n)
tn
Îº

,(W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1))âŠ™
s
F
 W (n)
tn
Îº
+
35

+ 2Î²
Î³
*
(W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1))âŠ™
s
F
 W (n)
tn
Îº

,|W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)| âŠ™
G
 W (n)
tn
Îº

r
F
 W (n)
tn
Îº

+
(b)
=âˆ’ Î²
Î³
(W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1))âŠ™
s
F
 W (n)
tn
Îº

2
+ Î²
Î³
|W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)| âŠ™
G
 W (n)
tn
Îº

r
F
 W (n)
tn
Îº


2
âˆ’ Î²
Î³
(W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1))âŠ™
s
F
 W (n)
tn
Îº

+|W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)| âŠ™
G
 W (n)
tn
Îº

r
F
 W (n)
tn
Îº


2
(c)
â‰¤ âˆ’ Î²
Î³Fmax
âˆ¥W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2
H(W (n)
tn )
âˆ’ Î²
Î³
(W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1))âŠ™
s
F
 W (n)
tn
Îº

+|W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)| âŠ™
G
 W (n)
tn
Îº

r
F
 W (n)
tn
Îº


2
(d)
â‰¤ âˆ’ Î²
FmaxÎ³ âˆ¥W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2
H(W (n)
tn )
âˆ’ Î²Î³
Fmax
P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº

2
(106)
where (a) holds by P âˆ—
n+1(W
(n+1)
tn ) =
W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)
Î³ , (b) leverages the equality 2âŸ¨U, VâŸ©=
âˆ¥Uâˆ¥2 +âˆ¥Vâˆ¥ 2 âˆ’ âˆ¥Uâˆ’Vâˆ¥ 2 for any U, VâˆˆR D, (c) is achieved by the saturation vector H(W (n)
tn )âˆˆ
RD defined in equation 40. Thus:
âˆ’ Î²
Î³ âˆ¥(W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1))âŠ™
s
F
 W (n)
tn
Îº

âˆ¥2 + Î²
Î³
|W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)| âŠ™
G
 W (n)
tn
Îº

r
F
 W (n)
tn
Îº


2
=âˆ’ Î²
Î³
X
dâˆˆ[D]
ï£«
ï£¬ï£­[(W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1))]2
d
ï£«
ï£¬ï£­[F
 W (n)
tn
Îº

]d âˆ’
[G
 W (n)
tn
Îº

]2
d
[F
 W (n)
tn
Îº

]d
ï£¶
ï£·ï£¸
ï£¶
ï£·ï£¸
=âˆ’ Î²
Î³
X
dâˆˆ[D]
ï£«
ï£¬ï£­[(W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1))]2
d
ï£«
ï£¬ï£­
[F
 W (n)
tn
Îº

]2
d âˆ’[G
 W (n)
tn
Îº

]2
d
[F
 W (n)
tn
Îº

]d
ï£¶
ï£·ï£¸
ï£¶
ï£·ï£¸
â‰¤ âˆ’ Î²
Î³Fmax
X
dâˆˆ[D]
 
[(W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1))]2
d
 
[F
 W (n)
tn
Îº

]2
d âˆ’[G
 W (n)
tn
Îº

]2
d
!!
=âˆ’ Î²
Î³Fmax
âˆ¥(W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1))âˆ¥2
H(W (n)
tn ).(107)
(d)comes from :
âˆ’ Î²
Î³
(W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1))âŠ™
s
F
 W (n)
tn
Îº

+|W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)| âŠ™
G
 W (n)
tn
Îº

r
F
 W (n)
tn
Îº


2
=âˆ’Î²Î³


F
 W (n)
tn
Îº
(âˆ’ 1
2 )
âŠ™
 W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)
Î³ âŠ™F
 W (n)
tn
Îº

36

+
 W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)
Î³
 âŠ™G
 W (n)
tn
Îº

2
â‰¤ âˆ’ Î²Î³
Fmax
P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº

2
.(108)
The second term in the RHS of equation 105 is bounded by Lemma 5 as:
2EÎ¶tn
hD
W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1), W(n+1)
tn+1+Tâˆ’1 âŠ™F
 W (n)
tn
Îº

âˆ’ |W (n+1)
tn+1+Tâˆ’1 | âŠ™G
 W (n)
tn
Îº

âˆ’

P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº
Ei
(109)
â‰¤ Î²
2FmaxÎ³ âˆ¥W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2
H(W (n)
tn ) + 2Î²FmaxÎ³
W (n+1)
tn+1+Tâˆ’1 âŠ™F
 W (n)
tn
Îº

âˆ’ |W (n+1)
tn+1+Tâˆ’1 |
âŠ™G
 W (n)
tn
Îº

âˆ’

P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº

2
H(W (n)
tn )â€ 
â‰¤ Î²
2FmaxÎ³ âˆ¥W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2
H(W (n)
tn ) + 2Î²F 3
maxÎ³âˆ¥W (n+1)
tn+1+Tâˆ’1 âˆ’P âˆ—(W
(n+1)
tn )âˆ¥2
H(W (n)
tn )â€  .
Plugging inequality equation 106 and equation 109 above into equation 105 yields:
2EÎ¶tn [âŸ¨W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1), W(n)
tn+1 âˆ’W (n)
tn âŸ©](110)
â‰¤2Î²F 3
maxÎ³âˆ¥W (n+1)
tn+1+Tâˆ’1 âˆ’P âˆ—(W
(n+1)
tn )âˆ¥2
H(W (n)
tn )â€  âˆ’ Î²Î³
Fmax
P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº

2
âˆ’ Î²
2Î³Fmax
âˆ¥W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2
H(W (n)
tn ).
We assume there exists a non-zero constant Hmin such that min{H(W (n)
tn )} â‰¥H min for all tn and
n. Under this condition, we have the following inequalities:
âˆ’ Î²
2FmaxÎ³ âˆ¥W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2
H(W (n)
tn ) â‰¤ âˆ’ Î²Hmin
2FmaxÎ³ âˆ¥W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2,(111)
2Î²F 3
maxÎ³
W (n+1)
tn+1+Tâˆ’1 âˆ’P âˆ—(W
(n+1)
tn )

2
H(W (n)
tn )â€ 
â‰¤ 2Î²F 3
maxÎ³
Hmin
W (n+1)
tn+1+Tâˆ’1 âˆ’P âˆ—(W
(n+1)
tn )

2
.
Plugging inequality equation 111 above into equation 110 yields:
2EÎ¶tn [âŸ¨W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1), W(n)
tn+1 âˆ’W (n)
tn âŸ©](112)
â‰¤ âˆ’ Î²Hmin
2Î³Fmax
âˆ¥W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2 + 2Î²F 3
maxÎ³
Hmin
âˆ¥W (n+1)
tn+1+Tâˆ’1 âˆ’P âˆ—(W
(n+1)
tn )âˆ¥2
âˆ’ Î²Î³
Fmax
P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº

2
.
The third term in the RHS of equation 104 is bounded by Lemma 5 as:
EÎ¶tn [âˆ¥W (n)
tn+1 âˆ’W (n)
tn âˆ¥2](113)
=EÎ¶tn
hÎ²

W (n+1)
tn+1+Tâˆ’1 âŠ™F
 W (n)
tn
Îº

âˆ’ |W (n+1)
tn+1+Tâˆ’1 | âŠ™G
 W (n)
tn
Îº

+Î¶ tn

2i
â‰¤3Î² 2
P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº

2
+ 3Î²Î˜(âˆ†wmin)
+ 3Î²2
W (n+1)
tn+1+Tâˆ’1 âŠ™F
 W (n)
tn
Îº

âˆ’ |W (n+1)
tn+1+Tâˆ’1 | âŠ™G
 W (n)
tn
Îº

âˆ’

P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº

2
37

â‰¤3Î² 2
P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº

2
+ 3Î²Î˜(âˆ†wmin)
+ 3Î²2EÎ¾t:t+Tn âˆ’1[âˆ¥W (n+1)
tn+1+Tâˆ’1 âˆ’P âˆ—
n+1(W
(n+1)
tn )âˆ¥2].
The second inequality holds by Cauchy-Schwarz inequality. Plugging inequality equation 112 and
equation 113 above into equation 104 yields:
EÎ¶tn [âˆ¥W (n)
tn+1 âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2](114)
= (1âˆ’ Î²Hmin
2Î³Fmax
)âˆ¥W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2 + 2Î²F 3
maxÎ³
Hmin
âˆ¥W (n+1)
tn+1+Tâˆ’1 âˆ’P âˆ—
n+1(W
(n+1)
tn )âˆ¥2
âˆ’( Î²Î³
Fmax
âˆ’3Î² 2)
P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº

2
+ 3Î²Î˜(âˆ†wmin) + 3Î²2âˆ¥W (n+1)
tn+1+Tâˆ’1 âˆ’P âˆ—
n+1(W
(n+1)
tn )âˆ¥2
â‰¤(1âˆ’ Î²Hmin
2Î³Fmax
)âˆ¥W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2 + 3Î²F 3
maxÎ³
Hmin
âˆ¥W (n+1)
tn+1+Tâˆ’1 âˆ’P âˆ—
n+1(W
(n+1)
tn )âˆ¥2
+Î²Î˜(âˆ†w min)âˆ’( Î²Î³
Fmax
âˆ’3Î² 2)
P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº

2
.
The last inequality holds by setting Î²â‰¤ F 3
maxÎ³
3Hmin
. Executing Tn iterations through equation 114 yields:
EÎ¶n[âˆ¥W n
tn+Tnâˆ’1 âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2](115)
â‰¤

1âˆ’ Î²Hmin
2Î³Fmax
Tn
âˆ¥W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2 +
Tnâˆ’1X
i=0

1âˆ’ Î²Hmin
2Î³Fmax
i
(Î²Î˜(âˆ†wmin)
+ 3Î²F 3
maxÎ³
Hmin
âˆ¥W n+1
tn+1+(i+1)Tn+1âˆ’1 âˆ’P âˆ—
n+1(W
(n+1)
tn+i )âˆ¥2)
â‰¤

1âˆ’ Î²Hmin
2Î³Fmax
Tn
âˆ¥W (n)
tn âˆ’P âˆ—
n(W
(n)
tnâˆ’1)âˆ¥2 + 6F 4
maxÎ³2
H2
min
âˆ¥W (n+1)
tn+1+Tn+1âˆ’1 âˆ’P âˆ—
n+1(W
(n+1)
tn )âˆ¥2
âˆ’( 2Î³2
Hmin
âˆ’ 6Î²Î³Fmax
Hmin
)
P âˆ—
n+1(W
(n+1)
tn )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn )| âŠ™G
 W (n)
tn
Îº

2
+ 2FmaxÎ˜(âˆ†wmin)
Hmin
.
WhenkÌ¸= 0, equation 115 can be written as the general case:
EÎ¶n[âˆ¥W (n)
tn+(k+1)Tnâˆ’1 âˆ’P âˆ—
n(W
(n)
tnâˆ’1+k)âˆ¥2](116)
â‰¤

1âˆ’ Î²Hmin
2Î³Fmax
Tn
âˆ¥W (n)
tn+kTn
âˆ’P âˆ—
n(W
(n)
tnâˆ’1+k)âˆ¥2
+ 6F 4
maxÎ³2
H2
min
âˆ¥W (n+1)
tn+1+(k+1)Tn+1âˆ’1 âˆ’P âˆ—
n+1(W
(n+1)
tn+k )âˆ¥2 + 2FmaxÎ˜(âˆ†wmin)
Hmin
âˆ’( 2Î³2
Hmin
âˆ’ 6Î²Î³Fmax
Hmin
)
P âˆ—
n+1(W
(n+1)
tn+k )âŠ™F
 W (n)
tn
Îº

âˆ’ |P âˆ—
n+1(W
(n+1)
tn+k )| âŠ™G
 W (n)
tn
Îº

2
which completes the proof.
38

H PSEUDOCODE
Algorithm 1Multi-timescale Residual Learning with Warm Start Initialization
1: InitializeW (0) with the weight from digital side, working tilesW (n) â†0forn= 1, . . . , N
2: Initialize tile index counter:t n â†0for alln, and setcurrent update tilekâ†0
3: Initialize inner loop length:T n =Transfer_every_vec[n]
4: Initialize switching flag:trigger_tile_switchâ†False
5: Initialize loss history buffer:L
6:foreach iterationt= 1,2, . . .do
7:W (N)
tN â†W (N)
t âˆ’Î±âˆ‡f( W t;Î¾ t)âŠ™F
 
W (N)
t

âˆ’
Î±âˆ‡f( W t;Î¾ t)
 âŠ™G
 
W (N)
t

+Î¶ t
// Gradient accumulation
8: Appendâ„“ t to loss historyL
9:ifLossPlateau(L, k)andkâ‰¥0then
10:trigger_tile_switchâ†True// Detected plateau: trigger tile switch
11:end if
12:iftrigger_tile_switch=Trueandk < Nthen
13:kâ†k+ 1// Progressive per-tile transfer switch
14:trigger_tile_switchâ†False
15:end if
16:ifk < NandtmodT N = 0then
17:W (k)
tk â†W (k)
tk +Î²W (N)
t+TN âˆ’1 âŠ™F
 
W (k)
tk

âˆ’
Î²W (N)
t+TN âˆ’1
 âŠ™G
 
W (k)
tk

+Î¶ tk
// Transfer update fromW (N) toW (k)
18:end if// Warm start initialization finished
19:ifkâ‰¥Nthen
20:forn=Nâˆ’1to0do
21:ift n+1 modT n+1 = 0then
22:W (n)
tn â†W (n)
tn +Î² ËœW (n+1) âŠ™F
 
W (n)
tn

âˆ’
Î² ËœW (n+1) âŠ™G
 
W (n)
tn

+Î¶ tn
// Transfer update fromW (n+1) toW (n)
23:end if
24:end for
25:end if
26: W t =PN
n=0 Î³nW (n)
tn // Combine all tiles to form effective weight
27:end for
28:Function:LossPlateau(L, k)
29:ifkâ‰¤3:
30:if|L|<2:returnFalse // Not enough history
31:else:returnL[t]>L[tâˆ’1]// Aggressive mode
32:else:
33:if|L|<6:returnFalse
34:else:
35:vâ†0
36:fori=tâˆ’5totâˆ’1do
37:ifL[i+ 1]>L[i]:vâ†v+ 1
38:end for
39:returnvâ‰¥2// mild mode
Algorithm 1 includes an optional warm start phase (lines 1â€“18), which is only used in our experimental
implementation to accelerate convergence and stabilize early training. This warm start is not required
in the general method (Section 3) nor in the theoretical analysis (Section 4). The main results of our
method should focus on the multiscale residual learning process beginning from line 19 onward. The
warm start process in this algorithm uses the gradient accumulated on the tileW (N) to successively
update tiles W (0), W(1), . . . , W(Nâˆ’1) . Initially, only W (0) is initialized with the digital model
weights (line 1), and the current update tile index is set to k= 0 (line 2). During training, W (N)
is updated at every step using the gradient of the current composite weight W t (line 6). Every
TN steps, the content of W (N) is transferred to tile W (k) (line 14). This continues until the loss
plateaus, as determined by the LossPlateau function (lines 7â€“9). When a plateau is detected,
the algorithm increments k (lines 10â€“13), thereby the content of W (N) is transferred to tile W (k+1).
This procedure repeats until k > N , which means that all tiles have been updated, and then the warm
start initialization is complete.
39

Algorithm TT-v2 Analog SGD MP Ours
Digital storage [byte] O(D 2 + 2D) O(2D) O(D 2 + 2DB) O(2D)
Memory ops [bit] O(16D/n s) O(1) O(16D 2/B) O(1)
FP ops O(2D+ 2D/n s) O(2D) O(2D 2 +D) O(2D)
Analog ops [time] (lavg + 1
ns
)tsp + tM
ns
lavgtsp
D
B tsp lavg
tsp ns
nsâˆ’1 + tM
nsâˆ’1
â‰ˆTime est. [ns] 56.3 30.9 3024.5 95.9
Table 5: Comparison of complexity and estimated runtime for per-sample weight update. Here, D
is the vector/matrix dimension and B is the mini-batch size. For the time estimates, we assume
D= 512 , B= 100 , ns = 2 as the transfer period, lavg = 5 is the average number of pulses per
sample, tsp = 5ns is the duration of a single pulse, tM = 40ns is the time for matrix-vector readout
and FP operations compute time is calculated assuming throughput of 0.7 TFLOPS (Jain et al., 2022),
Statistics for TT-v2, Analog SGD, and MP are based on (Rasch et al., 2024).
I ANALOGCIRCUITIMPLEMENTATIONDETAILS
ð‘ð‘– âˆ ð‘¥ð‘–
. . . . . . . . 
 
. . . . . . . . 
 . 
     . 
          . 
               . 
 
ð‘Š(ð‘)
Pulse Coincidence
Gradient Update
ð‘ð‘– âˆ  ð‘Šð‘–,ð‘—
(ð‘›+1)
. . . . . . . . 
 
. . . . . . . . 
 . 
     . 
          . 
               . 
 
ð‘Š(ð‘›)
Transfer Update 
ð‘žð‘— âˆ ð›¿ð‘—
Pulse Coincidence
ð‘žð‘— =1, others 0
Figure 10: Implementation of gradient update and transfer update process.
I.1 CIRCUIT-LEVEL IMPLEMENTATION OF UPDATE PROCESS
Figure 10 illustrates how gradient updates are applied to tile W (N) and how transfer updates are
applied to the remaining tiles W (n). As described in Section 2, stochastic pulse streams whose
probabilities are proportional to the error Î´j and input xi are injected along each row and column of
the crossbar array, realizing gradient updates with expectation âˆ†wji =Î±Î´ jxi = âˆ‚f( W)
âˆ‚wji
. For each
transfer update on W (n), residual learning reads one column from W (n+1), and the column selection
may follow either a cyclic or a sequential schedule. To support the feasibility of implementing the
composite weight structure in Figure 6, we note that similar analog crossbar-based weight composition
and accumulation schemes have been demonstrated in practice (Song et al., 2024). These prior works
focus on inference, where the weights remain static, but this does not affect our in-memory training
scenario because the ADCs are only used during forward and backward passes, which are present in
both training and inference. Moreover, sharing analog peripheral circuits (e.g., ADCs, DACs, and
drivers) across multiple subarrays has been adopted in several recent compute-in-memory designs to
reduce power and area overhead (Xu et al., 2024a;b).
I.2 RUNTIME AND UPDATE COMPLEXITY COMPARISON.
As shown in Section 5 and supplement experiments in Section J, our algorithm achieves superior
performance under a limited-precision setting, consistently outperforming the Tiki-Taka series and
in some cases performing on par with MP. However, this performance advantage sometimes comes
at the cost of using multiple analog tiles (from 3 to 8), in contrast to TT-v1, which employs only 2
tiles, TT-v2, which adds one digital tile to TT-v1, and MP, which uses a single analog tile combined
with a high-precision digital unit. To evaluate the impact of using multiple tiles, we first summarize
the per-sample weight update complexity of different algorithms in Table 5. This table provides a
40

unified metric for comparing the hardware load across methods, including digital storage, memory
operations, floating-point operations, and analog operations. Based on these results, we then present
a more detailed analysis of the specific hardware costs including digital storage, runtime, energy, and
area to highlight the efficiency advantages of our proposed approach.
Digital storage cost.We evaluate the digital storage cost of our proposed method in comparison
with TT-v2, Analog SGD and MP. Here, digital storage refers exclusively to the memory used to
buffer intermediate forward input, backward error, and gradients during training, which reside in
SRAM or DRAM. In analog crossbar-based training, only the input xâˆˆR D and error signal Î´âˆˆR D
are digitized via ADCs and temporarily stored for the backward pass. These two vectors lead to a
digital storage requirement of O(2D) bytes for both Analog SGD and our method. In contrast, TT-v2
requires an additional DÃ—D digital transfer buffer between auxiliary and core arrays, incurring a
total cost of O(2D+D 2). For MP, gradient accumulation is performed in the digital domain over a
batch of sizeB, resulting inO(D 2 + 2DB)digital storage.
To quantify this storage in real scenarios, we extract the analog tile dimensions used in our experiments
in Tables 1 and 9 and sum the corresponding vector and matrix sizes across all analog layers.
Assuming each element occupies 1 byte (i.e., 8 bits of precision), we report total digital storage in
kilobytes (KB). For MP, we incorporate mini-batch accumulation with batch size B= 8 for LeNet-5
andB= 128for ResNet-18.
Model TT-v2 Analog SGD MP Ours
LeNet-5 (KB) 80.2 2.13 94.8 2.13
ResNet-18 (KB) 10,600 50.2 17,000 50.2
Table 6: Digital storage required by different algorithms on LeNet-5 and ResNet-18.
Table 6 demonstrates that on LeNet-5 and ResNet-18 , our method achieves digital storage reductions
of 37Ã—â€“211Ã— compared to TT-v2, and44Ã—â€“339Ã— compared to MP while matching the minimal cost
of Analog SGD. This efficiency stems from the fact that increasing the number of tiles does not incur
additional cost for storing x and Î´, as they are computed collectively across all tiles as illustrated in
Figure 6. Moreover, unlike MP and TT-v2, our method eliminates the need for any digital tile to
store weights or gradients. We believe our algorithm offers a substantial advantage in terms of digital
memory overhead.
Runtime cost.We analyze the runtime cost, which includes both theFP operations timeandanalog
operations time. For the MP baseline, the outer-product Î´xT requires D2 multiplications and D2
additions, resulting in a total of 2D2 floating-point operations per input. Including additional scaling
and preprocessing for x and Î´, the total is O(2D2 +D) FP ops. Dividing by the effective throughput
of 0.175 TFLOPS (assuming 0.7 TFLOPS shared across 4 tiles as in (Rasch et al., 2024)), the FP
operations take 2998.9ns, while the analog operations require D
B tsp = 25.6ns, resulting in a total
estimated latency of 3024.5ns. In contrast, our method maintains the same O(2D) FP operations as
Analog SGD, as it only requires computing the absolute maximum values of x and Î´ to scale the
probabilities used in stochastic pulse updates. For analog operations, we focus on deriving the runtime
expression specific to our method, which includes the pulse update and the MVM-based readout
for weight transfer. For pulse update, when the final tile W (N) is updated once, each preceding tile
W (n) is updated approximately every (1/ns)Nâˆ’n iterations, and the aggregate latency is bounded by
lavg Â·t sp Â·PN
n=0(1/ns)Nâˆ’n , whose upper bound as Nâ†’ âˆž converges to lavgtspns
nsâˆ’1 . Similarly, the
MVM-based readout incurs an additional delay bounded by tM
nsâˆ’1. As a result, our methodâ€™s analog
latency isl avg Â· tspns
nsâˆ’1 + tM
nsâˆ’1, which gives a total estimated latency of95.9ns in Table 5.
We apply the same methodology to estimate runtime on full-model configurations. For both LeNet-5
and ResNet-18, we assume each layer is processed in parallel, and the slowest layer dominates the
total latency. For MP, the largest matrix in LeNet-5 is of size128Ã—512 , resulting in a total latency
of 457.4ns. In the case of ResNet-18, the largest analog matrix is 512Ã—4608 , leading to an FP time
of 13508.0ns and an analog latency of 20.0ns (with batch size B= 128 ), yielding a total latency of
13528.0ns We summarize the runtime across all algorithms and architectures in Table 7 below:
41

Model TT-v2 Analog SGD MP Ours
LeNet-5 (ns) 56.3 30.9 457.4 95.9
ResNet-18 (ns) 126.5 77.7 13528.0 142.7
Table 7: Estimated runtime for different analog training methods on LeNet-5 and ResNet-18.
These results highlight the efficiency of our method: on LeNet-5, MP is 4.8Ã— slower than ours, while
on ResNet-18, it is 94.7Ã— slower. At the same time, our method introduces only modest latency
overhead compared to TT-v2.
Energy cost.We analyze the energy consumption per training sample and compare our method to
the MP baseline. As reported in (Gallo et al., 2018, Table 1), MP consumes 83.2nJ to process a
single training image on a two-layer perceptron (785 inputs, 250 hidden neurons, 10 outputs; total
198,760 synapses). For consistency, we adopt the same model configuration for energy estimation
across methods. For our method, the energy is composed of three parts: pulse update energy,
transfer update energy, and forward/backward propagation energy. To estimate the pulse update
energy , we follow (Gokmen and Vlasov, 2016), which reports a combined power consumption
of 0.7W for op-amps and stochastic translators (STRs) on a 4096Ã—4096 crossbar. We scale this
power by the number of active rows and columns in our perceptron, yielding Pscaled = 0.1107W.
Assuming a worst-case pulse update time of lavgtspns
nsâˆ’1 = 50ns, we obtain the pulse update energy:
Epulse_update =P scaled Â·50nsâ‰ˆ5.53nJ. In addition, we consider the transfer update energy for analog
readout. Since in our architecture each tile is read roughly every ns steps, the aggregate readout
time is upper bounded by the MVM latency of a single tile, tM
nsâˆ’1 = 40ns. The MP work reports a
forward-propagation energy in computational memory of 7.29nJ under similar conditions, which can
be interpreted as the estimated energy cost for a single-tile analog forward pass closely matching the
MVM read time in our design. Therefore, we adopt7.29nJ as an upper-bound estimate for our total
transfer energy: Etrans = 7.29nJ. Hence, the total update energy per sample in our method is the sum:
Eupdate =E pulse_update +E trans â‰ˆ12.82nJ.
For the forward and backward passes, our method distributes the computation across N analog tiles.
Each tile requires the full sequence of operations including data input, PWM generation, read-voltage
regulation, analog computation, ADC conversion and data output. We adopt a conservative estimation
by assuming that these operations are not shared across tiles, so the energy cost of each tile is
independent and must be incurred individually. Following the values reported in (Gallo et al., 2018),
the forward and backward passes consume 7.29nJ and 2.15nJ per tile, respectively. Consequently,
the total propagation energy scales linearly with N as NÂ·(7.29 + 2.15) =NÂ·9.44nJ . Putting all
the components together, we compare the energy consumption per training sample in Table 8:
Component MP (nJ) Ours (nJ)
Weight update 62.03 12.82
Forward/backward pass 21.21 NÂ·9.44
Total 83.2 12.82 +NÂ·9.44
Table 8: Estimated energy consumption per image for MP and our method based on (Gokmen and
Vlasov, 2016; Gallo et al., 2018).
As the table shows, our method becomes less energy-efficient than MP when Nâ‰¥8 . In practice,
however, much of the forward/backward overhead can be shared across tiles. For example, the PWM
counter and comparator logic that generate input vectors into modulated pulses, and the ADCs that
digitize accumulated outputs can all be amortized across multiple tiles rather than duplicated. Such
shared-ADC designs have been demonstrated in recent analog accelerators (Xu et al., 2024a;b; Song
et al., 2024). Only the per-tile operational transconductance amplifiers used for voltage regulation,
along with the intrinsic device conduction energy, scale directly withN. This means that the effective
energy growth with tile count is substantially slower than the conservative upper bound assumed in
Table 8. Combined with the fact that our method achieves higher accuracy than TT baselines with as
few as 3â€“4 tiles, these considerations indicate that our design remains more energy-efficient than MP
even when more than eight tiles are employed, making it a practical and scalable solution.
Area cost.For our methods, since the overall architecture closely resembles that of TT-v1 except for
the increased number of tiles, the corresponding estimates for area and execution time are derived
42

based on models presented in (Gokmen and Haensch, 2020) and (Gokmen and Vlasov, 2016). We
analyze the area overhead of our method using the RPU tile design methodology described in (Gokmen
and Vlasov, 2016), which assumes a realistic CMOS-compatible fabrication stack. Specifically, RPU
arrays are implemented in the back-end-of-line (BEOL) region, with resistive memory devices placed
between intermediate metal layers. Each crossbar array contains DÃ—D devices, and the interconnect
pitch (wire width plus spacing) is set to 400 nm , based on typical dimensions of intermediate BEOL
levels. This yields a physical tile area of ((0.4D)Âµm)2 = (0.16D2)Âµm2. Following (Gokmen and
Vlasov, 2016), we adopt a baseline configuration of D= 4096 , which corresponds to a tile area of
approximately 2.68mm2. In our experimental configurations (e.g., LeNet-5 and ResNet-18), which
use smaller crossbar sizes, the tile area is scaled proportionally under the same pitch assumption; for
instance, a 128 Ã— 512 tile occupies 0.0105mm2 . Based on the actual tile dimensions used in each
layer of Tables 1 and 9, we estimate the total analog area required by our method to be 0.0128mm2
for LeNet-5 and1.69mm 2 for ResNet-18.
To map logical weights to physical devices, each weight W is represented as the difference between
two conductance values: a main conductance Cmain and a reference Cref, i.e., WâˆC main âˆ’C ref. This
implies that both Analog SGD and MP require 2 analog tiles per layer . TT-v1 and TT-v2, which
maintain both core and assistant matrices, require 4 analog tiles per layer . In our method, the number
of physical analog tiles is twice the count reported in Tables 1 and 9, due to our multi-tile residual
structure. However, because these tiles can be vertically stacked using BEOL integration, the actual
die area remains compact. Even without stacking, the total area overhead of our method remains
within practical limits. For example, in the worst-case configuration using 10 analog tiles, our method
incurs approximately 10Ã— the area of MP and 5Ã— that of TT-v2. Yet this level of overhead is still
feasible: modern processors such as IBM Power8 CPUs (Stuecheli, 2013) supports chip areas up
to 600mm2. Such systems are capable of integrating hundreds of analog tiles, indicating that our
method remains scalable and realistic under practical hardware constraints.
In summary, our multi-tile framework provides clear advantages over TT-v2 and MP: it reduces
digital storage by up to two orders of magnitude and achieves substantially lower runtime latency,
benefiting from parallel analog updates even when more tiles are used. While area and energy scale
with tile count, area overhead can be mitigated through BEOL stacking, and energy only exceeds MP
underthe most conservative estimateswhen N >8 , since those estimates assume that all I/O, PWM
logic, and ADC resources are replicated per tile rather than shared, meaning that in practical our
design can tolerate substantially more tiles before its energy surpasses MP. Importantly, our method
consistently delivers higher accuracy than TT baselines with only 3â€“4 tiles, keeping energy well
within practical limits. These results establish our approach as a scalable and efficient solution for
high-precision analog training.
J SUPPLEMENT SIMULATIONS
To further demonstrate the scalability, robustness, and practical relevance of our proposed method,
we conduct a series of supplementary experiments across diverse settings, as supplement simulations
to Section 5. We further explore the case of 80-state ReRAM devices with a larger portion of the
model implemented in analog. This experiment examines whether our approach can still retain its
advantages when the analog model is scaled up, providing insights into its applicability for future
generations of higher-precision memristor devices. To better understand the algorithmic behavior,
we perform an ablation study on the geometric scaling factor and its influence on training dynamics.
Lastly, we extend our method to a Transformer-based natural language modeling task to demonstrate
its applicability beyond vision workloads. Together, these results strengthen the case for our method
as a scalable and general solution for analog training under various model architectures and hardware
regimes.
J.1 CIFAR-10ANDCIFAR-100EXPERIMENTS
We first provide supplementary results on CIFAR-10 with ResNet-18 in Table 9, which were omitted
from the main text due to space constraints. To further validate the effectiveness of our method on
more challenging datasets, we conduct additional experiments on CIFAR-100 using ResNet-18, with
devices limited to 4 conductance states. Given the increased complexity and number of classes in
CIFAR-100, we extend the training schedule to 400 epochs to ensure sufficient convergence.
43

# States TT-v1 TT-v2 MP Ours (4 tiles) Ours (6 tiles) Ours (8 tiles)
4 53.83Â±0.1487.89Â±0.06 92.77Â±0.05 87.35Â±0.0889.79Â±0.1490.45Â±0.09
10 84.18Â±0.0689.17Â±0.11 93.45Â±0.08 90.76Â±0.0691.07Â±0.0690.88Â±0.05
Table 9: Test accuracy on CIFAR10 under 4 and 10 conductance states using analog ResNet-18.
Model TT-v1 TT-v2 MP Ours (4 tiles) Ours (6 tiles) Ours (8 tiles)
ResNet-18 14.97Â±1.9327.91Â±0.6564.08Â±0.44 58.36Â±0.3659.68Â±0.3360.62Â±0.24
Table 10: Test accuracy on CIFAR-100 using 4-state analog devices.
The results summarized in Table 10 demonstrate that our method consistently outperforms TT-v1 and
TT-v2 baselines and approaches the performance of the MP method as6âˆ’8tiles are used.
J.2 EXPERIMENTS ON80-STATERERAMDEVICES WITH INCREASED ANALOG DEPLOYMENT.
We further conduct experiments on 80-state ReRAM devices with increased analog deployment.
Although 10-state devices are often used as an extreme but mature example (as most reported devices
reach tens of states, see Table 3), our algorithm also provides an effective solution for improving
training accuracy on these relatively high-state devices. We observe that as the proportion of analog
layers increases, for example, when further converting layer2 in ResNet-34 to analog, TT-v1 and
TT-v2 degrades severely due to error accumulation across layers even with 80 states. In contrast, our
method maintains higher accuracy, surpassing TT baselines with only 3â€“4 tiles and approaching MP
performance with 8 tiles. We believe this accuracy collapse is a general challenge in scaling analog
training to larger models, as errors from device non-idealities accumulate across more analog tiles,
and our algorithm offers a practical solution without incurring extra latency, energy, or digital storage
cost.
Dataset TT-v1 TT-v2 MP Ours (3 tiles) Ours (5 tiles) Ours (7 tiles)
CIFAR-10 10.04Â±0.0475.65Â±0.1787.32Â±0.10 82.59Â±0.2783.97Â±0.2084.96Â±0.08
CIFAR-100 1.27Â±0.0434.80Â±0.1658.06Â±0.07 42.12Â±0.4745.14Â±0.1350.82Â±0.14
Table 11: Test accuracy on CIFAR-10 and CIFAR-100 using 80-state ReRAM devices with more
layer in ResNet-34 converted to analog.
J.3 SENSITIVITY TO GEOMETRIC SCALING FACTOR
Figure 11: Gamma ablation study on LeNet-5 using different device states with 4-tile and 6-tile
configurations.
The geometric scaling factor Î³ plays a critical role in determining the effectiveness of residual
representation across multiple analog tiles. Intuitively, if each tile has a dynamic range [âˆ’Ï„max, Ï„max],
then Î³ should be chosen such that Î³Â·(2Ï„ max)â‰ˆâˆ†w min to ensure that the representable range of the
next tile fully lies within the resolution of the previous tile. This design ensures that each additional
tile effectively increases the representable precision by a factor equal to the number of conductance
44

states. However, in practice, device non-idealities such as conductance saturation and asymmetric
update dynamics reduce the usable dynamic range of each tile. To account for these effects, we
heuristically choose Î³ slightly larger than âˆ†wmin
(2Ï„max) = 1
nstates
. We show the corresponding ablation
results in Figure 11, where the peak Î³ value is consistent with our hypothesis. These results support
the need for careful selection ofÎ³based on device characteristics.
J.4 EXTENSION TOTRANSFORMER-BASEDNLPTASKS
To further demonstrate the scalability and general applicability of our method, we conducted an
additional experiment on a natural language processing task using a GPT-2-style Transformer ar-
chitecture. Specifically, we trained a 6-layer, 6-head, 768-dimensional model from scratch on the
standardShakespeare character-level language modelingbenchmark. The total number of trainable
parameters is approximately 10.65M, and each iteration processes 16384 tokens. We ran the training
for 5000 iterations using 4-tile analog devices undernon-ideal I/O conditionsto simulate realistic
hardware noise. The analog device used has 4 discrete states. We compare our method against
representative analog training baselines, including TT-v1, TT-v2 and MP.
Method TT-v1 TT-v2 MP Ours (4 tiles)
Loss 3.0336 2.6137 2.7213 2.5971
Table 12: Validation loss on 6-layer GPT-style model.
As shown in Table 12, our method achieves comparable final validation loss, demonstrating both
accuracy and robustness on this standard NLP benchmark. These results confirm that our method
is not limited to vision tasks, but also scales effectively to Transformer-based sequence modeling,
maintaining accuracy and resilience under analog non-idealities.
K SIMULATIONDETAILS
This section provides details about the experiments in Section 5. The analog training algorithms,
including Mixed Precision and Tiki-Taka, are provided by the open-source simulation toolkit AI-
HWKIT, which has an Apache-2.0 license; see https://github.com/IBM/aihwkit. We
use the Softbound device provided by AIHWKIT to simulate the asymmetric linear device. Digital
algorithms (including SGD) and datasets (including MNIST and CIFAR10) used in this paper are pro-
vided by PyTorch, which has a BSD license; see https://github.com/pytorch/pytorch.
Our implementation builds upon the TT-v1 preset in AIHWKIT v0.9.2 , with modifications to
the gradient routing and transfer mechanisms to support our proposed Residual Learning scheme. We
conduct our experiments on an NVIDIA RTX 3090 GPU, which has 24GB memory. The simulation
time ranges from one to three hours, depending on the model size, dataset, and the number of training
epochs. The code is available athttps://anonymous.4open.science/r/Code-CC44/.
K.1 MNISTANDFASHION-MNISTTRAINING WITH ANALOGLENET-5
Data and preprocessing.The MNIST dataset is used with standard normalization and no data
augmentation. The training and testing sets use the default PyTorch torchvision splits (60,000 training
and 10,000 testing samples). In our experiments, we utilize the full training set with a batch size of 8.
The Fashion-MNIST dataset is used with the default PyTorch torchvision splits, consisting of
60,000 training and 10,000 testing samples. No additional data augmentation is applied. A simple
normalization transform is used through ToTensor(), and the full training set is utilized with a
batch size of 16.
Model architecture.We adopt a LeNet-5 model in which all convolutional and fully-connected
layers are implemented using AIHWKitâ€™s analog modules (AnalogConv2d, AnalogLinear).
Digital non-linear operations, such as Tanh activations and MaxPooling, are interleaved and remain
executed in the digital domain.
Optimizer and learning rate.For MNIST, we employ the AnalogSGD optimizer with an initial
global learning rate of 0.05 applied uniformly to all trainable parameters. For Fashion-MNIST,
we use the AnalogSGD optimizer with an initial global learning rate of 0.2 for our method, and
45

0.1 for TT-v1, TT-v2, and MP. A learning rate scheduler based on LambdaLR decays this global
rate by a factor of 0.5 every 30 epochs. In analog layers, for our algorithm, each tile W (n) is
assigned a fixed internal learning rate transfer_lr_vec[n]= 0.1Â·1.2 n. These internal learn-
ing rates remain constant throughout the training and are not affected by the global schedule, as
scale_transfer_lr=False. For TT-v1, we set the auxiliary tile learning rate fast_lr
Î± to 0.01 and the transfer learning rate transfer_lr to 0.1 on both datasets. For TT-v2 we
set Î±= 0.1 and Î²= 1 for MNIST and Î±= 0.05 for Fashion-MNIST. Additionally, we set
scale_transfer_lr=Truefor TT-v1, TT-v2 and MP as default.
Tile parameter configuration.We configure the behavior of each analog tile through the following
parameter vectors, all generated dynamically as a function of the total number of tilesnum_tile:
â€¢ For MNIST:
â€“transfer_every_vec = [2 * (5Ë†n) for n in
range(num_tile)]
â€“gamma_vec = [0.5Ë†(num_tile - 1 - i) for i in
range(num_tile)]
â€¢ For Fashion-MNIST:
â€“transfer_every_vec = [2 * (5Ë†n) for n in
range(num_tile)]
â€“gamma_vec = [0.2Ë†(num_tile - 1 - i) for i in
range(num_tile)]
These vectors control the per-tile transfer schedule, readout scaling, and learning rate, respectively.
The number of tiles num_tile is a configurable parameter that we vary in experiments (e.g.,
Table 1). It is worth noting that in the actual implementation, tile index 0 serves as the fixed
gradient accumulation tile and plays the role of W (N) in the main text. The remaining tiles at indices
1,2, . . . ,num_tileâˆ’1 correspond to W (Nâˆ’1) , W(Nâˆ’2) , . . . , W(0), respectively. While this index
order is opposite to the mathematical notation used in the main text, the transfer logic and learning
behavior are equivalent. The index inversion only affects naming, not the functional correctness or
conclusions of the training algorithm.
I/O configuration.As acknowledged in Section 6, this work assumes idealized I/O settings through-
out all experiments. I/O behavior is configured as nearly ideal, with:
â€¢ Forward path:The input vector x is injected into the crossbar without finite resolution
quantization, amplitude clipping, or additive noise. The resulting output current is integrated
ideally, bypassing any ADC or nonlinear feedback models.
â€¢ Backward path:The backpropagated vector Î´ is encoded and applied in a similarly ideal
manner, ignoring input resolution limits, digital-to-analog conversion noise, or output
quantization during the gradient computation.
â€¢ Transfer path:When using compound devices such as TransferCompound,
the internal transfer of weights between tiles (e.g., during warm start or pe-
riodic updates) also involves analog readout and write operations. Setting
device.transfer_forward.is_perfect = True disables all I/O imperfec-
tions during this internal read phase, ensuring clean accumulation and precise programming
of weights across tiles.
By default (inp_noise=0.0,out_noise=0.0). Unless overridden, the defaults are
io_inp_bits=7,io_out_bits=9.
Tile switching schedule.To avoid early saturation of coarse tiles, the training monitors convergence
plateaus via loss history. Early epochs use an aggressive trigger if training loss does not drop
sufficiently between epochs. After four tile switches, a smoother criterion is used based on the recent
5-step moving window. Upon plateau detection, a C++ flag trigger_tile_switch is activated
via Python binding for each tile.
Training and Evaluation.The network is trained for up to 100 epochs. Classification loss is
computed using nn.NLLLoss() applied to the log-softmax outputs. Evaluation is performed after
each epoch using classification accuracy on the full MNIST test set.
46

K.2 CIFAR-10ANDCIFAR-100TRAINING WITHRESNET
Dataset and augmentation.The CIFAR-10 dataset is used for all ResNet experiments. Following
the default splits provided by torchvision, the dataset consists of 50,000 training samples and
10,000 test samples, selected via the train=True/False flag. For additional experiments on
more fine-grained recognition, we also use the CIFAR-100 dataset, which has the same image size
and train/test splits but with 100 object categories grouped into 20 superclasses. We utilize the entire
training set and set the batch size to 128. All images are normalized to zero mean and unit variance per
channel. During training, strong data augmentation is applied, including random cropping, horizontal
flipping, Cutout regularization and AutoAugment using 25 CIFAR-10-specific sub-policies. No
augmentation is applied to the test set beyond normalization.
Model architecture.In different experiments, we use ResNet-18 and ResNet-34 models, where
layer3, layer4, and the final classifier are mapped to analog tiles, while the remaining layers
remain digital. To further demonstrate the scalability of our method (see Section J.2), we also conduct
experiments on a ResNet-34 variant in which layer2 is additionally mapped to analog tiles. Batch
normalization and residual shortcuts are preserved unless explicitly disabled.
Tile parameter configuration.We configure the behavior of each analog tile through the following
parameter vectors, all generated dynamically as a function of the total number of tilesnum_tile:
â€¢ For 4-state experiments:
â€“transfer_every_vec = [3 * (2Ë†n) for n in
range(num_tile)]
â€“gamma_vec = [0.5Ë†(num_tile - 1 - i) for i in
range(num_tile)]
â€¢ For 16-state experiments:
â€“transfer_every_vec = [3 * (2Ë†n) for n in
range(num_tile)]
â€“gamma_vec = [0.1Ë†(num_tile - 1 - i) for i in
range(num_tile)]
I/O configuration.The I/O configuration is the same as in the MNIST experiments.
Optimizer and Scheduler.All analog parameters are trained using AnalogSGD with an initial
learning rate of 0.1. A StepLR scheduler reduces the learning rate by a factor of 0.1 every 100
epochs. In analog layers, for our algorithm, each tile W (n) is assigned a fixed internal learning rate
transfer_lr_vec[n]= 0.3Â·1.2 n. These internal learning rates remain constant throughout the
training and are not affected by the global schedule, as scale_transfer_lr=False. For both
TT-v1 and TT-v2, we set the auxiliary tile learning ratefast_lrÎ± to 0.1 and the transfer learning
rate transfer_lr to 1. Additionally, we set scale_transfer_lr=True for TT-v1, TT-v2
and MP as default.
Training and Evaluation.The network is trained for 200 epochs for CIFAR-10 and 400 epochs
for CIFAR-100 with a batch size of 128. Classification loss is computed using label-smoothed
cross-entropy, implemented viaLabelSmoothingLosswith a smoothing factor of 0.1.
Tile switching.The tile switching strategy is the same as in the MNIST experiments.
K.3 LEAST SQUARE PROBLEM
Model architecture.We use a scalar analog layerR 1 â†’R1:AnalogLinear(1,1).
Tile parameter configuration.We instantiate a TransferCompound device with num_tile
identical unit cells, each a SoftBoundsDevice with wmin =âˆ’1 , wmax = 1 , and âˆ†wmin =
0.5. Column transfers are enabled and multi-sample updates are treated as mini-batch units
(transfer_columns=True, units_in_mbatch=True). The two key parameter vectors
are generated fromnum_tile:
â€¢transfer_every_vec = [2 * (2^n) for n in range(num_tile)]
47

â€¢gamma_vec = [0.1^(num_tile - 1 - i) for i in
range(num_tile)]
Tile-internal transfer learning rate is fixed to transfer_lr=0.01 with
scale_transfer_lr=False. We also set the pulse update scheme as
update_bl_management=False, update_management=False, as well as
weight scaling scheme digital_bias=False, learn_out_scaling=False,
weight_scaling_columnwise=False, andweight_scaling_omega=0.0.
I/O configuration.The I/O configuration is the same as in the MNIST experiments.
Target generation.Batch size defaults to batch_size=1. The regression target bâˆˆ[âˆ’1,1] is
sampled from a uniform 16-bit quantizer:
b=âˆ’1 +kÂ· 2
216 âˆ’1 , kâˆ¼Uniform{0, . . . ,2 16 âˆ’1}.
Optimizer.All analog parameters are trained using AnalogSGD with an initial learning rate of
0.001. In analog layers, for our algorithm, each tile W (n) is assigned a fixed internal learning rate
transfer_lr= 0.01. These internal learning rates remain constant throughout the training and
are not affected by the global schedule, as scale_transfer_lr=False. We set the auxiliary
tile learning ratefast_lrÎ±to 0.01.
48
